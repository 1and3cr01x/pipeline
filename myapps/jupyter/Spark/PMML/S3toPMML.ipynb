{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Environment Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export AIRFLOW_HOME='/root/airflow'\r\n",
      "export AKKA_VERSION='2.3.11'\r\n",
      "export ALGEBIRD_VERSION='0.11.0'\r\n",
      "export ANKUR_PART_VERSION='0.1'\r\n",
      "export ATLAS_HOME='/root/atlas-1.4.5'\r\n",
      "export ATLAS_VERSION='1.4.5'\r\n",
      "export BAZEL_HOME='/root/bazel-0.3.0'\r\n",
      "export BAZEL_VERSION='0.3.0'\r\n",
      "export BETTER_FILES_VERSION='2.14.0'\r\n",
      "export CASSANDRA_HOME='/root/apache-cassandra-2.2.6'\r\n",
      "export CASSANDRA_VERSION='2.2.6'\r\n",
      "export CLICOLOR='1'\r\n",
      "export CODAHALE_METRICS_VERSION='3.1.2'\r\n",
      "export COMMONS_DAEMON_VERSION='1.0.15'\r\n",
      "export CONFIG_HOME='/root/pipeline/config'\r\n",
      "export CONFLUENT_HOME='/root/confluent-3.0.0'\r\n",
      "export CONFLUENT_VERSION='3.0.0'\r\n",
      "export DATASETS_HOME='/root/pipeline/datasets'\r\n",
      "export DEV_INSTALL_HOME='/root'\r\n",
      "export DYNOMITE_HOME='/root/dynomite'\r\n",
      "export DYNO_VERSION='1.4.6'\r\n",
      "export ELASTICSEARCH_HOME='/root/elasticsearch-2.3.0'\r\n",
      "export ELASTICSEARCH_VERSION='2.3.0'\r\n",
      "export FINAGLE_VERSION='6.34.0'\r\n",
      "export FLINK_HOME='/root/flink-1.0.0'\r\n",
      "export FLINK_VERSION='1.0.0'\r\n",
      "export GENSORT_VERSION='1.5'\r\n",
      "export GIT_PAGER='cat'\r\n",
      "export GRAPHFRAMES_VERSION='0.1.0-spark1.6'\r\n",
      "export GUAVA_VERSION='14.0.1'\r\n",
      "export HADOOP_HOME='/root/hadoop-2.6.0'\r\n",
      "export HADOOP_USER_CLASSPATH_FIRST='true'\r\n",
      "export HADOOP_VERSION='2.6.0'\r\n",
      "export HIVE_HOME='/root/apache-hive-1.2.1-bin'\r\n",
      "export HIVE_VERSION='1.2.1'\r\n",
      "export HOME='/root'\r\n",
      "export HOSTNAME='pipeline-master-v5-ytpc'\r\n",
      "export HTML_HOME='/root/pipeline/myapps/html'\r\n",
      "export HYSTRIX_DASHBOARD_HOME='/root/hystrix-dashboard-1.5.3'\r\n",
      "export HYSTRIX_DASHBOARD_VERSION='1.5.3'\r\n",
      "export HYSTRIX_VERSION='1.5.3'\r\n",
      "export INDEXEDRDD_VERSION='0.3'\r\n",
      "export JANINO_VERSION='2.7.8'\r\n",
      "export JAVA_HOME='/usr/lib/jvm/java-8-oracle'\r\n",
      "export JAVA_OPTS='-Xmx10G -XX:+CMSClassUnloadingEnabled'\r\n",
      "export JBLAS_VERSION='1.2.4'\r\n",
      "export JEDIS_VERSION='2.7.3'\r\n",
      "export JMETER_HOME='/root/apache-jmeter-3.0'\r\n",
      "export JMETER_VERSION='3.0'\r\n",
      "export JPMML_SPARKML_VERSION='1.0.4'\r\n",
      "export JPY_PARENT_PID='2926'\r\n",
      "export JSON4S_VERSION='3.3.0'\r\n",
      "export KAFKA_CLIENT_VERSION='0.10.0.0'\r\n",
      "export KIBANA_HOME='/root/kibana-4.5.0-linux-x64'\r\n",
      "export KIBANA_VERSION='4.5.0'\r\n",
      "export LESSCLOSE='/usr/bin/lesspipe %s %s'\r\n",
      "export LESSOPEN='| /usr/bin/lesspipe %s'\r\n",
      "export LOGSTASH_HOME='/root/logstash-2.3.0'\r\n",
      "export LOGSTASH_VERSION='2.3.0'\r\n",
      "export LOGS_HOME='/root/pipeline/logs'\r\n",
      "export LS_COLORS='rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lz=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.axa=00;36:*.oga=00;36:*.spx=00;36:*.xspf=00;36:'\r\n",
      "export MAXMIND_GEOIP_VERSION='2.5.0'\r\n",
      "export MPLBACKEND='module://ipykernel.pylab.backend_inline'\r\n",
      "export MYAPPS_HOME='/root/pipeline/myapps'\r\n",
      "export MYSQL_CONNECTOR_JAR='/usr/share/java/mysql-connector-java.jar'\r\n",
      "export NIFI_HOME='/root/nifi-0.6.1'\r\n",
      "export NIFI_VERSION='0.6.1'\r\n",
      "export OLD_PYTHONSTARTUP=''\r\n",
      "export PAGER='cat'\r\n",
      "export PATH='/usr/local/bin:/root/pipeline/myapps/serving:/root/pipeline/myapps/serving/prediction:/root/dynomite:/root/apache-jmeter-3.0/bin:/root/titan-1.0.0-hadoop1/bin:/root/presto-server-0.137/bin:/root/airflow/bin:/root/flink-1.0.0/bin:/root/zeppelin-0.6.0/bin:/root/sbt/bin:/root/nifi-0.6.1/bin:/root/webdis:/root/redis-3.0.5/bin:/root/apache-hive-1.2.1-bin/bin:/root/hadoop-2.6.0/bin:/root/kibana-4.5.0-linux-x64/bin:/root/logstash-2.3.0/bin:/root/elasticsearch-2.3.0/bin:/root/confluent-3.0.0/bin:/root/confluent-3.0.0/bin:/root/spark-1.6.1-bin-fluxcapacitor/tachyon/bin:/root/spark-1.6.1-bin-fluxcapacitor/bin:/root/spark-1.6.1-bin-fluxcapacitor/sbin:/root/apache-cassandra-2.2.6/bin:/root/pipeline/bin/cli:/root/pipeline/bin/cluster:/root/pipeline/bin/docker:/root/pipeline/bin/initial:/root/pipeline/bin/kafka:/root/pipeline/bin/rest:/root/pipeline/bin/service:/root/pipeline/bin/util:/root/bazel-0.3.0/bin:/usr/lib/jvm/java-8-oracle/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'\r\n",
      "export PIPELINE_HOME='/root/pipeline'\r\n",
      "export PMML_EVALUATOR_VERSION='1.2.14'\r\n",
      "export PMML_MODEL_METRO_VERSION='1.2.15'\r\n",
      "export PMML_MODEL_VERSION='1.2.15'\r\n",
      "export PRESTO_HOME='/root/presto-server-0.137'\r\n",
      "export PRESTO_VERSION='0.137'\r\n",
      "export PWD='/root/pipeline/myapps/jupyter/Spark/PMML'\r\n",
      "export PYSPARK_DRIVER_PYTHON='jupyter'\r\n",
      "export PYSPARK_DRIVER_PYTHON_OPTS='notebook --config=/root/pipeline/config/jupyter/jupyter_notebook_config.py'\r\n",
      "export PYSPARK_PYTHON='python2.7'\r\n",
      "export PYSPARK_SUBMIT_ARGS='\"--name\" \"PySparkShell\" \"--repositories\" \"http://dl.bintray.com/spark-packages/maven,https://oss.sonatype.org/content/repositories/snapshots,https://repository.apache.org/content/groups/snapshots\" \"--jars\" \"/root/pipeline/myapps/spark/redis/lib/spark-redis_2.10-0.2.0.jar,/usr/share/java/mysql-connector-java.jar,/root/pipeline/myapps/spark/ml/lib/spark-corenlp_2.10-0.1.jar,/root/pipeline/myapps/spark/ml/lib/stanford-corenlp-3.6.0-models.jar,/root/pipeline/myapps/spark/ml/target/scala-2.10/ml_2.10-1.0.jar,/root/pipeline/myapps/spark/sql/target/scala-2.10/sql_2.10-1.0.jar,/root/pipeline/myapps/spark/core/target/scala-2.10/core_2.10-1.0.jar,/root/pipeline/myapps/spark/streaming/target/scala-2.10/streaming_2.10-1.0.jar,/root/pipeline/myapps/serving/spark/target/scala-2.10/spark-serving_2.10-1.0.jar,/root/pipeline/myapps/pmml/spark/1.6.1/lib/jpmml-sparkml-package-1.0-SNAPSHOT.jar\" \"--packages\" \"tjhunter:tensorframes:0.2.2-s_2.10,com.maxmind.geoip2:geoip2:2.5.0,com.netflix.dyno:dyno-jedis:1.4.6,org.json4s:json4s-jackson_2.10:3.3.0,amplab:spark-indexedrdd:0.3,org.apache.spark:spark-streaming-kafka-assembly_2.10:1.6.1,org.elasticsearch:elasticsearch-spark_2.10:2.3.0.BUILD-SNAPSHOT,com.datastax.spark:spark-cassandra-connector_2.10:1.4.0,redis.clients:jedis:2.7.3,com.twitter:algebird-core_2.10:0.11.0,com.databricks:spark-avro_2.10:2.0.1,com.databricks:spark-csv_2.10:1.4.0,org.apache.nifi:nifi-spark-receiver:0.6.1,com.madhukaraphatak:java-sizeof_2.10:0.1,com.databricks:spark-xml_2.10:0.3.1,edu.stanford.nlp:stanford-corenlp:3.6.0,org.jblas:jblas:1.2.4,graphframes:graphframes:0.1.0-spark1.6\" \"--py-files\" \"/root/pipeline/myapps/pmml/spark/1.6.1/lib/jpmml.py\" \"pyspark-shell\"'\r\n",
      "export PYTHONHASHSEED='0'\r\n",
      "export PYTHONPATH='/root/spark-1.6.1-bin-fluxcapacitor/python/lib/py4j-0.9-src.zip:/root/spark-1.6.1-bin-fluxcapacitor/python/:'\r\n",
      "export PYTHONSTARTUP='/root/spark-1.6.1-bin-fluxcapacitor/python/pyspark/shell.py'\r\n",
      "export REDIS_HOME='/root/redis-3.0.5'\r\n",
      "export REDIS_VERSION='3.0.5'\r\n",
      "export SBT_ASSEMBLY_PLUGIN_VERSION='0.14.0'\r\n",
      "export SBT_HOME='/root/sbt'\r\n",
      "export SBT_OPTS='-Xmx10G -XX:+CMSClassUnloadingEnabled'\r\n",
      "export SBT_SPARK_PACKAGES_PLUGIN_VERSION='0.2.3'\r\n",
      "export SBT_VERSION='0.13.9'\r\n",
      "export SCALATEST_VERSION='2.2.4'\r\n",
      "export SCALA_MAJOR_VERSION='2.10'\r\n",
      "export SCALA_VERSION='2.10.5'\r\n",
      "export SCRIPTS_HOME='/root/pipeline/bin'\r\n",
      "export SHLVL='3'\r\n",
      "export SPARK_AVRO_CONNECTOR_VERSION='2.0.1'\r\n",
      "export SPARK_CASSANDRA_CONNECTOR_VERSION='1.4.0'\r\n",
      "export SPARK_CSV_CONNECTOR_VERSION='1.4.0'\r\n",
      "export SPARK_ELASTICSEARCH_CONNECTOR_VERSION='2.3.0.BUILD-SNAPSHOT'\r\n",
      "export SPARK_ENV_LOADED='1'\r\n",
      "export SPARK_EXAMPLES_JAR='/root/spark-1.6.1-bin-fluxcapacitor/lib/spark-examples-1.6.1-hadoop2.6.0.jar'\r\n",
      "export SPARK_HOME='/root/spark-1.6.1-bin-fluxcapacitor'\r\n",
      "export SPARK_LOG_DIR='/root/pipeline/logs/spark'\r\n",
      "export SPARK_NIFI_CONNECTOR_VERSION='0.6.1'\r\n",
      "export SPARK_OTHER_VERSION='2.0.1-SNAPSHOT'\r\n",
      "export SPARK_REDIS_CONNECTOR_VERSION='0.2.0'\r\n",
      "export SPARK_REPOSITORIES='http://dl.bintray.com/spark-packages/maven,https://oss.sonatype.org/content/repositories/snapshots,https://repository.apache.org/content/groups/snapshots'\r\n",
      "export SPARK_SCALA_VERSION='2.10'\r\n",
      "export SPARK_SUBMIT_JARS='/root/pipeline/myapps/spark/redis/lib/spark-redis_2.10-0.2.0.jar,/usr/share/java/mysql-connector-java.jar,/root/pipeline/myapps/spark/ml/lib/spark-corenlp_2.10-0.1.jar,/root/pipeline/myapps/spark/ml/lib/stanford-corenlp-3.6.0-models.jar,/root/pipeline/myapps/spark/ml/target/scala-2.10/ml_2.10-1.0.jar,/root/pipeline/myapps/spark/sql/target/scala-2.10/sql_2.10-1.0.jar,/root/pipeline/myapps/spark/core/target/scala-2.10/core_2.10-1.0.jar,/root/pipeline/myapps/spark/streaming/target/scala-2.10/streaming_2.10-1.0.jar,/root/pipeline/myapps/serving/spark/target/scala-2.10/spark-serving_2.10-1.0.jar'\r\n",
      "export SPARK_SUBMIT_PACKAGES='tjhunter:tensorframes:0.2.2-s_2.10,com.maxmind.geoip2:geoip2:2.5.0,com.netflix.dyno:dyno-jedis:1.4.6,org.json4s:json4s-jackson_2.10:3.3.0,amplab:spark-indexedrdd:0.3,org.apache.spark:spark-streaming-kafka-assembly_2.10:1.6.1,org.elasticsearch:elasticsearch-spark_2.10:2.3.0.BUILD-SNAPSHOT,com.datastax.spark:spark-cassandra-connector_2.10:1.4.0,redis.clients:jedis:2.7.3,com.twitter:algebird-core_2.10:0.11.0,com.databricks:spark-avro_2.10:2.0.1,com.databricks:spark-csv_2.10:1.4.0,org.apache.nifi:nifi-spark-receiver:0.6.1,com.madhukaraphatak:java-sizeof_2.10:0.1,com.databricks:spark-xml_2.10:0.3.1,edu.stanford.nlp:stanford-corenlp:3.6.0,org.jblas:jblas:1.2.4,graphframes:graphframes:0.1.0-spark1.6'\r\n",
      "export SPARK_VERSION='1.6.1'\r\n",
      "export SPARK_XML_VERSION='0.3.1'\r\n",
      "export SPRING_BOOT_VERSION='1.3.5.RELEASE'\r\n",
      "export SPRING_CLOUD_VERSION='1.1.2.RELEASE'\r\n",
      "export SPRING_CORE_VERSION='4.3.0.RELEASE'\r\n",
      "export SPRING_PROFILES_ACTIVE='local'\r\n",
      "export STANFORD_CORENLP_VERSION='3.6.0'\r\n",
      "export TACHYON_HOME='/root/spark-1.6.1-bin-fluxcapacitor/tachyon'\r\n",
      "export TENSORFLOW_HOME='/root/tensorflow'\r\n",
      "export TENSORFLOW_SERVING_HOME='/root/serving'\r\n",
      "export TENSORFLOW_SERVING_VERSION='0.4.1'\r\n",
      "export TENSORFLOW_VERSION='0.10.0'\r\n",
      "export TENSORFRAMES_VERSION='0.2.2'\r\n",
      "export TERM='xterm-color'\r\n",
      "export TITAN_HOME='/root/titan-1.0.0-hadoop1'\r\n",
      "export TITAN_VERSION='1.0.0-hadoop1'\r\n",
      "export WEBDIS_HOME='/root/webdis'\r\n",
      "export WORK_HOME='/root/pipeline/work'\r\n",
      "export ZEPPELIN_HOME='/root/zeppelin-0.6.0'\r\n",
      "export ZEPPELIN_VERSION='0.6.0'\r\n",
      "export ZOOKEEPER_HOME='/root/confluent-3.0.0'\r\n",
      "export _SPARK_ASSEMBLY='/root/spark-1.6.1-bin-fluxcapacitor/lib/spark-assembly-1.6.1-hadoop2.6.0.jar'\r\n",
      "export _SPARK_CMD_USAGE='Usage: ./bin/pyspark [options]'\r\n"
     ]
    }
   ],
   "source": [
    "!export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Spark and SQL Contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x7f0850f142b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sparkContext = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sparkContext)\n",
    "\n",
    "sqlContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup S3 Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hadoopConf = sparkContext._jsc.hadoopConfiguration()\n",
    "# Set your AWS Credentials here\n",
    "myAccessKey = \"\"\n",
    "mySecretKey = \"\"\n",
    "hadoopConf.set(\"fs.s3.impl\", \"org.apache.hadoop.fs.s3native.NativeS3FileSystem\")\n",
    "hadoopConf.set(\"fs.s3.awsAccessKeyId\", myAccessKey)\n",
    "hadoopConf.set(\"fs.s3.awsSecretAccessKey\", mySecretKey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset into Spark Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameReader' object has no attribute 'csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d7978783242b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3://fluxcapacitor.com/datasets/R/wine.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrameReader' object has no attribute 'csv'"
     ]
    }
   ],
   "source": [
    "data = sqlContext.read.csv(\"s3://fluxcapacitor.com/datasets/R/wine.csv\", header=True, inferSchema=True)\n",
    "data.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Decision Tree (Regression) with Spark ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import RFormula\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "formula = RFormula(formula = \"quality ~ .\")\n",
    "regressor = DecisionTreeRegressor()\n",
    "pipeline = Pipeline(stages = [formula, regressor])\n",
    "pipelineModel = pipeline.fit(data)\n",
    "\n",
    "pipelineModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Spark ML Model and Pipeline to PMML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from jpmml import toPMMLBytes\n",
    "\n",
    "pmmlBytes = toPMMLBytes(sparkContext, data, pipelineModel)\n",
    "\n",
    "str(pmmlBytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
