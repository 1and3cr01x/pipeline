FROM fluxcapacitor/package-ubuntu-16.04:master

WORKDIR /root

ENV \
  TERM=xterm

###################
# Setup OpenJDK 1.8
###################
RUN \
  apt-get update \
  && apt-get install -y software-properties-common \
  && add-apt-repository -y ppa:openjdk-r/ppa \
  && apt-get update \
  && apt-get install -y --no-install-recommends openjdk-8-jdk openjdk-8-jre-headless \
  && apt-get install -y apt-transport-https \
  && apt-get install -y wget \
  && apt-get clean \
  && rm -rf /var/lib/apt/lists/*

ENV \
  JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/

ENV \
  SHELL=/bin/bash

RUN \
  rm /bin/sh \
  && ln -s /bin/bash /bin/sh

RUN \
  echo "deb https://dl.bintray.com/sbt/debian /" | tee -a /etc/apt/sources.list.d/sbt.list \
  && apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 2EE0EA64E40A89B84B2DF73499E82A75642AC823 \
  && apt-get update \
  && apt-get install -y sbt

# Install Anaconda with Python3
RUN wget -q https://repo.continuum.io/miniconda/Miniconda3-4.3.21-Linux-x86_64.sh -O /tmp/miniconda.sh  && \
    echo 'c1c15d3baba15bf50293ae963abef853 */tmp/miniconda.sh' | md5sum -c - && \
    bash /tmp/miniconda.sh -f -b -p /opt/conda && \
    /opt/conda/bin/conda install --yes python=3.6 sqlalchemy tornado jinja2 traitlets requests pip && \
    /opt/conda/bin/pip install --upgrade pip && \
    rm /tmp/miniconda.sh

ENV \
  PATH=/opt/conda/bin:$PATH

RUN \
  pip install --upgrade pip

# Anaconda's libgfortran=3.0 is not co-operating, so we use apt-get
RUN \
  apt-get install -y libgfortran3

RUN \
  conda install -c anaconda openblas

RUN \
  apt-get install -y nginx 

RUN \
  service nginx start

COPY config/ config/

RUN \
  mv /etc/nginx/sites-available/default /etc/nginx/sites-available/default.orig \
  && cd /etc/nginx/sites-available/ \
  && ln -s /root/config/nginx/default \
  && cd /etc/nginx/sites-enabled/ \
  && rm default \
  && ln -s /etc/nginx/sites-available/default

ENV \
  PROMETHEUS_VERSION=1.7.1

RUN \
  wget https://github.com/prometheus/prometheus/releases/download/v$PROMETHEUS_VERSION/prometheus-$PROMETHEUS_VERSION.linux-amd64.tar.gz \
  && tar xvfz prometheus-$PROMETHEUS_VERSION.linux-amd64.tar.gz \
  && rm prometheus-$PROMETHEUS_VERSION.linux-amd64.tar.gz

RUN \
  mv /root/prometheus-$PROMETHEUS_VERSION.linux-amd64/prometheus.yml /root/prometheus-$PROMETHEUS_VERSION.linux-amd64/prometheus.yml.orig \
  && cd /root/prometheus-$PROMETHEUS_VERSION.linux-amd64/ \
  && ln -s /root/config/prometheus/prometheus.yml

ENV \
  PATH=/root/prometheus-$PROMETHEUS_VERSION.linux-amd64/:$PATH

ENV \
  GRAFANA_VERSION=4.4.3

RUN \
  wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-$GRAFANA_VERSION.linux-x64.tar.gz \ 
  && tar -zxvf grafana-$GRAFANA_VERSION.linux-x64.tar.gz \
  && rm grafana-$GRAFANA_VERSION.linux-x64.tar.gz

ENV \
  PATH=/root/grafana-$GRAFANA_VERSION/bin:$PATH 

RUN \
  cd /root/grafana-$GRAFANA_VERSION/conf \
  && ln -s /root/config/grafana/custom.ini \
  && ln -s /root/config/grafana/dashboards

RUN \
  mkdir -p /root/logs

ENV \
  LOGS_HOME=/root/logs

COPY sysutils/ sysutils/

ENV \
  PIPELINE_JVM_MODEL_SERVER_PATH=/root/jvm

COPY jvm/ jvm/

RUN \
  cd $PIPELINE_JVM_MODEL_SERVER_PATH && sbt cleanFiles package

ENV \
  CONFLUENT_VERSION=3.3.0 \
  CONFLUENT_MAJOR_VERSION=3.3

ENV \
  CONFLUENT_HOME=/root/confluent-${CONFLUENT_VERSION}

ENV \
  PATH=$CONFLUENT_HOME/bin:$PATH

RUN \
 wget http://packages.confluent.io/archive/${CONFLUENT_MAJOR_VERSION}/confluent-oss-${CONFLUENT_VERSION}-2.11.tar.gz \
 && tar xvzf confluent-oss-${CONFLUENT_VERSION}-2.11.tar.gz \
 && rm confluent-oss-${CONFLUENT_VERSION}-2.11.tar.gz

RUN \
  git clone https://github.com/edenhill/librdkafka.git \
  && cd librdkafka \
  && ./configure \
  && make \
  && make install

RUN \
  pip install --upgrade confluent-kafka

# Must run ths or you will see the following error:
#   ImportError: librdkafka.so.1: cannot open shared object file: No such file or directory
RUN \
  ldconfig

COPY src/ src/

ENV \
  PIPELINE_MODEL_SERVER_PATH=/root/src/main/python/model_server

ENV \
  PIPELINE_MODEL_SERVER_PORT=9876

# Note:  Port 9040 is used in 2 separate contexts:
#        1) separate http server for prometheus running within the python-based model server
#        2) the same port as the main JVM-based model server
ENV \
  PIPELINE_MODEL_SERVER_PROMETHEUS_PORT=9040

ENV \
  PIPELINE_MODEL_SERVER_TENSORFLOW_SERVING_PORT=9000

ENV \
  PIPELINE_MODEL_SERVER_TENSORFLOW_SERVING_REQUEST_BATCHING=true

ENV \
  TF_CPP_MIN_LOG_LEVEL=0

COPY html/ /var/www/html/
COPY run run

ARG model_type
RUN \
  echo $model_type
ENV \
  PIPELINE_MODEL_TYPE=$model_type

ARG model_name
RUN \
  echo $model_name
ENV \
  PIPELINE_MODEL_NAME=$model_name

ARG model_chip
RUN \
  echo $model_chip
ENV \
  PIPELINE_MODEL_CHIP=$model_chip

RUN \
  cd $PIPELINE_JVM_MODEL_SERVER_PATH/lib/jni \
  && ln -s libtensorflow_jni-$PIPELINE_MODEL_CHIP.so libtensorflow_jni.so

ARG model_tag
RUN \
  echo $model_tag

ARG model_path
RUN \
  echo $model_path
ENV \
  PIPELINE_MODEL_PATH=/root/model

RUN \
  pip install awscli

COPY $model_path $PIPELINE_MODEL_PATH
#RUN \
#  if [[ $model_path == "http:"* ]] || [[ $model_path == "https:"* ]]; then \
#    wget -r -e --no-parent -O $PIPELINE_MODEL_PATH $model_path; \
#  fi 

#RUN \
#  if [[ $model_path == "s3:"* ]]; then \
#    aws s3 cp --no-sign-request --recursive \
#      $model_path \
#      $PIPELINE_MODEL_PATH; \
#  fi 

ENV \
  PIPELINE_CONDA_ENV_NAME=pipeline

RUN \
  if [[ $PIPELINE_MODEL_TYPE == "tensorflow" ]]; then \
      echo "" \
      && echo "Installing TensorFlow Serving..." \
      && echo "deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal" | tee /etc/apt/sources.list.d/tensorflow-serving.list \
      && curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add - \
      && apt-get update \
      && apt-get install -y tensorflow-model-server; \ 
  fi

RUN \
  if [[ $PIPELINE_MODEL_TYPE == "python" ]] || \
     [[ $PIPELINE_MODEL_TYPE == "keras" ]] || \
     [[ $PIPELINE_MODEL_TYPE == "scikit" ]] || \
     [[ $PIPELINE_MODEL_TYPE == "tensorflow" ]]; then \
       echo "" \
       && echo "Creating and Activating '$PIPELINE_CONDA_ENV_NAME' Conda Environment with '$PIPELINE_MODEL_TYPE/$PIPELINE_MODEL_NAME' Model Dependencies with '$PIPELINE_MODEL_PATH/pipeline_conda_environment.yml'..." \
       && echo "" \
       && conda env create --name $PIPELINE_CONDA_ENV_NAME \
           --file $PIPELINE_MODEL_PATH/pipeline_conda_environment.yml \
       && echo "" \
       && echo "...Created and Activated!" \
       && echo "" \
       && echo "" \
       && echo "Installing Model Server Dependencies..." \
       && echo "" \
       && conda env update --name $PIPELINE_CONDA_ENV_NAME \ 
           --file $PIPELINE_MODEL_SERVER_PATH/requirements/pipeline_model_server_conda_environment.yml \
       && echo "" \
       && echo "source activate $PIPELINE_CONDA_ENV_NAME" >> ~/.bashrc \
       && echo "...Model Server Dependencies Installed!" \
       && echo ""; \
  fi

# TODO:  Include this in the above if statement 
RUN \
  if [ -e "$PIPELINE_MODEL_PATH/pipeline_install.sh" ]; then \  
     CONDA_ENV_ROOT_PATH=$(conda info --root) \ 
       && echo "Setting Up Conda Environment with '$PIPELINE_MODEL_PATH/pipeline_install.sh'..." \
       && conda info --root \
       && conda env list \
       && echo "" \
       && source activate $PIPELINE_CONDA_ENV_NAME \ 
       && echo "Running '$PIPELINE_MODEL_PATH/pipeline_install.sh':\n" \
       && chmod a+x $PIPELINE_MODEL_PATH/pipeline_install.sh \   
       && $PIPELINE_MODEL_PATH/pipeline_install.sh \
       && export \
       && echo "...Conda Environment Successfully Setup at '$PIPELINE_MODEL_PATH/pipeline_install.sh'!" \
       && echo ""; \
  fi 

ENV SHELL=/bin/bash

# TODO:  Clean up this logic
# TODO:  The pipeline_train.py file is expected to place the saved model in the right directory
# TODO:  If using TensorFlow Serving, ensure that $PIPELINE_MODEL_PATH/versions directory exists after training
RUN \
  if [[ $PIPELINE_MODEL_TYPE == "tensorflow" ]] \
     && [ -f "$PIPELINE_MODEL_PATH/pipeline_train.sh" ]; then \
       echo "PIPELINE_MODEL_PATH=$PIPELINE_MODEL_PATH" \
       && echo "PIPELINE_MODEL_TYPE=$PIPELINE_MODEL_TYPE" \
       && echo "PIPELINE_MODEL_NAME=$PIPELINE_MODEL_NAME" \
       && echo "PIPELINE_MODEL_CHIP=$PIPELINE_MODEL_CHIP" \
       && echo "PIPELINE_MODEL_PATH=$PIPELINE_MODEL_PATH" \
       && echo "" \
       && echo "Starting TensorFlow-based Model Training..." \
       && echo "" \
       && source activate $PIPELINE_CONDA_ENV_NAME \
       && cd $PIPELINE_MODEL_PATH \
       && python pipeline_train.py \
       && cd /root \
       && echo "" \
       && echo "...Training Complete!" \
       && echo ""; \
  fi

RUN \
  if [[ $PIPELINE_MODEL_TYPE == "python" ]] \
     && [ -f "$PIPELINE_MODEL_PATH/pipeline_train.py" ]; then \
       echo "PIPELINE_MODEL_PATH=$PIPELINE_MODEL_PATH" \
       && echo "PIPELINE_MODEL_TYPE=$PIPELINE_MODEL_TYPE" \
       && echo "PIPELINE_MODEL_NAME=$PIPELINE_MODEL_NAME" \
       && echo "PIPELINE_MODEL_CHIP=$PIPELINE_MODEL_CHIP" \
       && echo "PIPELINE_MODEL_PATH=$PIPELINE_MODEL_PATH" \
       && echo "" \
       && echo "Starting Python-based Model Training..." \
       && echo "" \
       && source activate $PIPELINE_CONDA_ENV_NAME \
       && cd $PIPELINE_MODEL_PATH \
       && python pipeline_train.py \
       && cd /root \
       && echo "" \
       && echo "...Training Complete!" \
       && echo ""; \
  fi

RUN \
  pip install git+https://github.com/wintoncode/winton-kafka-streams.git

EXPOSE 6969 9876 9000 9040 9090 3000 9092 8082 8081 2181 5959 
  #10254 6333

CMD ["supervise", "."]
