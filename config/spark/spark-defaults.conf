# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Shell variables don't work here
# While we could hard-code to the value of this variable,
#   we're specifying --jars on the command line instead.
# This maintains the variable nature of this value.
# This needs to be done for anything that uses spark-submit.
#   ie. spark-sql, spark-shell, spark-submit, etc.
#spark.executor.extraClassPath=$MYSQL_CONNECTOR_JAR
#spark.driver.extraClassPath=$MYSQL_CONNECTOR_JAR
spark.master=spark://127.0.0.1:7077
spark.executor.cores=2
spark.executor.memory=2048m
#spark.executor.instances=2
spark.cores.max=2
spark.eventLog.enabled=true
spark.eventLog.dir=/root/pipeline/logs/spark
spark.history.fs.logDirectory=/root/pipeline/logs/spark/spark-events
spark.sql.parquet.filterPushdown=true
spark.sql.parquet.cacheMetadata=true
spark.sql.inMemoryColumnarStorage.partitionPruning=true
spark.sql.codegen=true
spark.sql.unsafe.enabled=true

# Example:
# spark.master                     spark://master:7077
# spark.eventLog.enabled           true
# spark.eventLog.dir               hdfs://namenode:8021/directory
# spark.serializer                 org.apache.spark.serializer.KryoSerializer
# spark.driver.memory              5g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"
