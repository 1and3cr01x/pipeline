{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.session_bundle import exporter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make things wide\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def=None, width=1200, height=800, max_const_size=32, ungroup_gradients=False):\n",
    "    if not graph_def:\n",
    "        graph_def = tf.get_default_graph().as_graph_def()\n",
    "        \n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    data = str(strip_def)\n",
    "    if ungroup_gradients:\n",
    "        data = data.replace('\"gradients/', '\"b_')\n",
    "        #print(data)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(data), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:{}px;height:{}px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(width, height, code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer(\"batch_size\", 10, \"The batch size to train\")\n",
    "flags.DEFINE_integer(\"epoch_number\", 10, \"Number of epochs to run trainer\")\n",
    "flags.DEFINE_integer(\"steps_to_validate\", 1,\n",
    "                     \"Steps to validate and print loss\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", \"./checkpoint/\",\n",
    "                    \"indicates the checkpoint dirctory\")\n",
    "flags.DEFINE_string(\"model_path\", \"./model/\", \"The export path of the model\")\n",
    "flags.DEFINE_integer(\"export_version\", 4, \"The version number of the model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c0bf21f672ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-c0bf21f672ac>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# Define training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "  # Define training data\n",
    "  x = np.ones(FLAGS.batch_size)\n",
    "  y = np.ones(FLAGS.batch_size)\n",
    "\n",
    "  # Define the model\n",
    "  X = tf.placeholder(tf.float32, shape=[None], name=\"X\")\n",
    "  Y = tf.placeholder(tf.float32, shape=[None], name=\"yhat\")\n",
    "  w = tf.Variable(1.0, name=\"weight\")\n",
    "  b = tf.Variable(1.0, name=\"bias\")\n",
    "  loss = tf.square(Y - tf.mul(X, w) - b)\n",
    "  train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "  predict_op  = tf.mul(X, w) + b\n",
    "\n",
    "  saver = tf.train.Saver()\n",
    "  checkpoint_dir = FLAGS.checkpoint_dir\n",
    "  checkpoint_file = checkpoint_dir + \"/checkpoint.ckpt\"\n",
    "  if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "    \n",
    "  # Start the session\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "      print(\"Continue training from the model {}\".format(ckpt.model_checkpoint_path))\n",
    "      saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    saver_def = saver.as_saver_def()\n",
    "    print(saver_def.filename_tensor_name)\n",
    "    print(saver_def.restore_op_name)\n",
    "\n",
    "    # Start training\n",
    "    start_time = time.time()\n",
    "    for epoch in range(FLAGS.epoch_number):\n",
    "      sess.run(train_op, feed_dict={X: x, Y: y})\n",
    "\n",
    "      # Start validating\n",
    "      if epoch % FLAGS.steps_to_validate == 0:\n",
    "        end_time = time.time()\n",
    "        print(\"[{}] Epoch: {}\".format(end_time - start_time, epoch))\n",
    "\n",
    "        saver.save(sess, checkpoint_file)\n",
    "        tf.train.write_graph(sess.graph_def, checkpoint_dir, 'trained_model.pb', as_text=False)\n",
    "        tf.train.write_graph(sess.graph_def, checkpoint_dir, 'trained_model.txt', as_text=True)\n",
    "\n",
    "        start_time = end_time\n",
    "\n",
    "    # Print model variables\n",
    "    w_value, b_value = sess.run([w, b])\n",
    "    print(\"The model of w: {}, b: {}\".format(w_value, b_value))\n",
    "\n",
    "    # Export the model\n",
    "    print(\"Exporting trained model to {}\".format(FLAGS.model_path))\n",
    "    model_exporter = exporter.Exporter(saver)\n",
    "    model_exporter.init(\n",
    "      sess.graph.as_graph_def(),\n",
    "      named_graph_signatures={\n",
    "        'inputs': exporter.generic_signature({\"features\": X}),\n",
    "        'outputs': exporter.generic_signature({\"prediction\": predict_op})\n",
    "      })\n",
    "    model_exporter.export(FLAGS.model_path, tf.constant(FLAGS.export_version), sess)\n",
    "    print('Done exporting!')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Converts checkpoint variables into Const ops in a standalone GraphDef file.\n",
    "\n",
    "This script is designed to take a GraphDef proto, a SaverDef proto, and a set of\n",
    "variable values stored in a checkpoint file, and output a GraphDef with all of\n",
    "the variable ops converted into const ops containing the values of the\n",
    "variables.\n",
    "\n",
    "It's useful to do this when we need to load a single file in C++, especially in\n",
    "environments like mobile or embedded where we may not have access to the\n",
    "RestoreTensor ops and file loading calls that they rely on.\n",
    "\n",
    "An example of command-line usage is:\n",
    "bazel build tensorflow/python/tools:freeze_graph && \\\n",
    "bazel-bin/tensorflow/python/tools/freeze_graph \\\n",
    "--input_graph=some_graph_def.pb \\\n",
    "--input_checkpoint=model.ckpt-8361242 \\\n",
    "--output_graph=/tmp/frozen_graph.pb --output_node_names=softmax\n",
    "\n",
    "You can also look at freeze_graph_test.py for an example of how to use it.\n",
    "\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.protobuf import text_format\n",
    "from tensorflow.python.framework import graph_util\n",
    "\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string(\"input_graph\", \"/root/pipeline/jupyterhub.ml/notebooks/Spark/ML/checkpoint/trained_model.pb\",\n",
    "                           \"\"\"TensorFlow 'GraphDef' file to load.\"\"\")\n",
    "tf.app.flags.DEFINE_string(\"input_saver\", \"\",\n",
    "                           \"\"\"TensorFlow saver file to load.\"\"\")\n",
    "tf.app.flags.DEFINE_string(\"input_checkpoint\", \"\",\n",
    "                           \"\"\"TensorFlow variables file to load.\"\"\")\n",
    "tf.app.flags.DEFINE_string(\"output_graph\", \"\",\n",
    "                           \"\"\"Output 'GraphDef' file name.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean(\"input_binary\", False,\n",
    "                            \"\"\"Whether the input files are in binary format.\"\"\")\n",
    "tf.app.flags.DEFINE_string(\"output_node_names\", \"\",\n",
    "                           \"\"\"The name of the output nodes, comma separated.\"\"\")\n",
    "tf.app.flags.DEFINE_string(\"restore_op_name\", \"save/restore_all\",\n",
    "                           \"\"\"The name of the master restore operator.\"\"\")\n",
    "tf.app.flags.DEFINE_string(\"filename_tensor_name\", \"save/Const:0\",\n",
    "                           \"\"\"The name of the tensor holding the save path.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean(\"clear_devices\", True,\n",
    "                            \"\"\"Whether to remove device specifications.\"\"\")\n",
    "tf.app.flags.DEFINE_string(\"initializer_nodes\", \"\", \"comma separated list of \"\n",
    "                           \"initializer nodes to run before freezing.\")\n",
    "tf.app.flags.DEFINE_string(\"variable_names_blacklist\", \"\", \"comma separated \"\n",
    "                           \"list of variables to skip converting to constants \")\n",
    "\n",
    "\n",
    "def freeze_graph(input_graph, input_saver, input_binary, input_checkpoint,\n",
    "                 output_node_names, restore_op_name, filename_tensor_name,\n",
    "                 output_graph, clear_devices, initializer_nodes):\n",
    "  \"\"\"Converts all variables in a graph and checkpoint into constants.\"\"\"\n",
    "\n",
    "  if not tf.gfile.Exists(input_graph):\n",
    "    print(\"Input graph file '\" + input_graph + \"' does not exist!\")\n",
    "    return -1\n",
    "\n",
    "  if input_saver and not tf.gfile.Exists(input_saver):\n",
    "    print(\"Input saver file '\" + input_saver + \"' does not exist!\")\n",
    "    return -1\n",
    "\n",
    "  # 'input_checkpoint' may be a prefix if we're using Saver V2 format\n",
    "  if not tf.train.checkpoint_exists(input_checkpoint):\n",
    "    print(\"Input checkpoint '\" + input_checkpoint + \"' doesn't exist!\")\n",
    "    return -1\n",
    "\n",
    "  if not output_node_names:\n",
    "    print(\"You need to supply the name of a node to --output_node_names.\")\n",
    "    return -1\n",
    "\n",
    "  input_graph_def = tf.GraphDef()\n",
    "  mode = \"rb\" if input_binary else \"r\"\n",
    "  with tf.gfile.FastGFile(input_graph, mode) as f:\n",
    "    if input_binary:\n",
    "      input_graph_def.ParseFromString(f.read())\n",
    "    else:\n",
    "      text_format.Merge(f.read().decode(\"utf-8\"), input_graph_def)\n",
    "  # Remove all the explicit device specifications for this node. This helps to\n",
    "  # make the graph more portable.\n",
    "  if clear_devices:\n",
    "    for node in input_graph_def.node:\n",
    "      node.device = \"\"\n",
    "  _ = tf.import_graph_def(input_graph_def, name=\"\")\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    if input_saver:\n",
    "      with tf.gfile.FastGFile(input_saver, mode) as f:\n",
    "        saver_def = tf.train.SaverDef()\n",
    "        if input_binary:\n",
    "          saver_def.ParseFromString(f.read())\n",
    "        else:\n",
    "          text_format.Merge(f.read(), saver_def)\n",
    "        saver = tf.train.Saver(saver_def=saver_def)\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "    else:\n",
    "      sess.run([restore_op_name], {filename_tensor_name: input_checkpoint})\n",
    "      if initializer_nodes:\n",
    "        sess.run(initializer_nodes)\n",
    "\n",
    "    variable_names_blacklist = (FLAGS.variable_names_blacklist.split(\",\") if\n",
    "                                FLAGS.variable_names_blacklist else None)\n",
    "    output_graph_def = graph_util.convert_variables_to_constants(\n",
    "        sess, input_graph_def, output_node_names.split(\",\"),\n",
    "        variable_names_blacklist=variable_names_blacklist)\n",
    "\n",
    "  with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
    "    f.write(output_graph_def.SerializeToString())\n",
    "  print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n",
    "\n",
    "\n",
    "def main(unused_args):\n",
    "  freeze_graph(FLAGS.input_graph, FLAGS.input_saver, FLAGS.input_binary,\n",
    "               FLAGS.input_checkpoint, FLAGS.output_node_names,\n",
    "               FLAGS.restore_op_name, FLAGS.filename_tensor_name,\n",
    "               FLAGS.output_graph, FLAGS.clear_devices, FLAGS.initializer_nodes)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pylint: disable=g-bad-file-header\n",
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "r\"\"\"Removes parts of a graph that are only needed for training.\n",
    "\n",
    "There are several common transformations that can be applied to GraphDefs\n",
    "created to train a model, that help reduce the amount of computation needed when\n",
    "the network is used only for inference. These include:\n",
    "\n",
    " - Removing training-only operations like checkpoint saving.\n",
    "\n",
    " - Stripping out parts of the graph that are never reached.\n",
    "\n",
    " - Removing debug operations like CheckNumerics.\n",
    "\n",
    " - Folding batch normalization ops into the pre-calculated weights.\n",
    "\n",
    " - Fusing common operations into unified versions.\n",
    "\n",
    "This script takes either a frozen binary GraphDef file (where the weight\n",
    "variables have been converted into constants by the freeze_graph script), or a\n",
    "text GraphDef proto file (the weight variables are stored in a separate\n",
    "checkpoint file), and outputs a new GraphDef with the optimizations applied.\n",
    "\n",
    "If the input graph is a text graph file, make sure to include the node that\n",
    "restores the variable weights in output_names. That node is usually named\n",
    "\"restore_all\".\n",
    "\n",
    "An example of command-line usage is:\n",
    "\n",
    "bazel build tensorflow/python/tools:optimize_for_inference && \\\n",
    "bazel-bin/tensorflow/python/tools/optimize_for_inference \\\n",
    "--input=frozen_inception_graph.pb \\\n",
    "--output=optimized_inception_graph.pb \\\n",
    "--frozen_graph=True \\\n",
    "--input_names=Mul \\\n",
    "--output_names=softmax\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.protobuf import text_format\n",
    "\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string(\"input\", \"\", \"\"\"TensorFlow 'GraphDef' file to load.\"\"\")\n",
    "flags.DEFINE_string(\"output\", \"\", \"\"\"File to save the output graph to.\"\"\")\n",
    "flags.DEFINE_string(\"input_names\", \"\", \"\"\"Input node names, comma separated.\"\"\")\n",
    "flags.DEFINE_string(\"output_names\", \"\",\n",
    "                    \"\"\"Output node names, comma separated.\"\"\")\n",
    "flags.DEFINE_boolean(\"frozen_graph\", True,\n",
    "                     \"\"\"If true, the input graph is a binary frozen GraphDef\n",
    "                     file; if false, it is a text GraphDef proto file.\"\"\")\n",
    "flags.DEFINE_integer(\"placeholder_type_enum\", tf.float32.as_datatype_enum,\n",
    "                     \"\"\"The AttrValue enum to use for placeholders.\"\"\")\n",
    "\n",
    "\n",
    "def main(unused_args):\n",
    "  if not tf.gfile.Exists(FLAGS.input):\n",
    "    print(\"Input graph file '\" + FLAGS.input + \"' does not exist!\")\n",
    "    return -1\n",
    "\n",
    "  input_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.Open(FLAGS.input, \"r\") as f:\n",
    "    data = f.read()\n",
    "    if FLAGS.frozen_graph:\n",
    "      input_graph_def.ParseFromString(data)\n",
    "    else:\n",
    "      text_format.Merge(data.decode(\"utf-8\"), input_graph_def)\n",
    "\n",
    "  output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "      input_graph_def,\n",
    "      FLAGS.input_names.split(\",\"),\n",
    "      FLAGS.output_names.split(\",\"), FLAGS.placeholder_type_enum)\n",
    "\n",
    "  if FLAGS.frozen_graph:\n",
    "    f = tf.gfile.FastGFile(FLAGS.output, \"w\")\n",
    "    f.write(output_graph_def.SerializeToString())\n",
    "  else:\n",
    "    tf.train.write_graph(output_graph_def,\n",
    "                         os.path.dirname(FLAGS.output),\n",
    "                         os.path.basename(FLAGS.output))\n",
    "  return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"A simple script for inspect checkpoint files.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_string(\"file_name\", \"\", \"Checkpoint filename\")\n",
    "tf.app.flags.DEFINE_string(\"tensor_name\", \"\", \"Name of the tensor to inspect\")\n",
    "tf.app.flags.DEFINE_bool(\"all_tensors\", \"True\",\n",
    "                         \"If True, print the values of all the tensors.\")\n",
    "\n",
    "\n",
    "def print_tensors_in_checkpoint_file(file_name, tensor_name):\n",
    "  \"\"\"Prints tensors in a checkpoint file.\n",
    "\n",
    "  If no `tensor_name` is provided, prints the tensor names and shapes\n",
    "  in the checkpoint file.\n",
    "\n",
    "  If `tensor_name` is provided, prints the content of the tensor.\n",
    "\n",
    "  Args:\n",
    "    file_name: Name of the checkpoint file.\n",
    "    tensor_name: Name of the tensor in the checkpoint file to print.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    reader = tf.train.NewCheckpointReader(file_name)\n",
    "    if FLAGS.all_tensors:\n",
    "      var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "      for key in var_to_shape_map:\n",
    "        print(\"tensor_name: \", key)\n",
    "        print(reader.get_tensor(key))\n",
    "    elif not tensor_name:\n",
    "      print(reader.debug_string().decode(\"utf-8\"))\n",
    "    else:\n",
    "      print(\"tensor_name: \", tensor_name)\n",
    "      print(reader.get_tensor(tensor_name))\n",
    "  except Exception as e:  # pylint: disable=broad-except\n",
    "    print(str(e))\n",
    "    if \"corrupted compressed block contents\" in str(e):\n",
    "      print(\"It's likely that your checkpoint file has been compressed \"\n",
    "            \"with SNAPPY.\")\n",
    "\n",
    "\n",
    "def main(unused_argv):\n",
    "  if not FLAGS.file_name:\n",
    "    print(\"Usage: inspect_checkpoint --file_name=checkpoint_file_name \"\n",
    "          \"[--tensor_name=tensor_to_print]\")\n",
    "    sys.exit(1)\n",
    "  else:\n",
    "    print_tensors_in_checkpoint_file(FLAGS.file_name, FLAGS.tensor_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
