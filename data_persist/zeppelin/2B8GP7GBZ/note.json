{
  "paragraphs": [
    {
      "title": "Load dataset including tags",
      "text": "val itemsDF \u003d sqlContext.read.format(\"com.databricks.spark.csv\")\n  .option(\"header\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .load(\"file:/root/pipeline/datasets/movielens/ml-latest/movies-sm.csv\").toDF(\"id\", \"title\", \"tags\")\n  \nz.show(itemsDF)",
      "dateUpdated": "Jan 16, 2016 5:23:42 AM",
      "config": {
        "tableHide": false,
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452399782070_1501936568",
      "id": "20160110-042302_1441428409",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "id\ttitle\ttags\n1\tToy Story (1995)\tAdventure|Animation|Children|Comedy|Fantasy\n2\tJumanji (1995)\tAdventure|Children|Fantasy\n3\tGrumpier Old Men (1995)\tComedy|Romance\n4\tWaiting to Exhale (1995)\tComedy|Drama|Romance\n5\tFather of the Bride Part II (1995)\tComedy\n6\tHeat (1995)\tAction|Crime|Thriller\n7\tSabrina (1995)\tComedy|Romance\n8\tTom and Huck (1995)\tAdventure|Children\n9\tSudden Death (1995)\tAction\n10\tGoldenEye (1995)\tAction|Adventure|Thriller\n"
      },
      "dateCreated": "Jan 10, 2016 4:23:02 AM",
      "dateStarted": "Jan 16, 2016 5:23:42 AM",
      "dateFinished": "Jan 16, 2016 5:23:42 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Convert CSV-based DataFrame into MinHashTaggedItems",
      "text": "import org.apache.spark.sql.Row\nimport com.advancedspark.ml.MinHashTaggedItem\nimport com.twitter.algebird.{ MinHasher, MinHasher32, MinHashSignature }\n\nval numHashes \u003d 100\nval minApproxLSHSimilarityThreshold \u003d 0.01\nval numBands \u003d MinHasher.pickBands(minApproxLSHSimilarityThreshold, numHashes)\nval minHasher \u003d new MinHasher32(numHashes, numBands)\n\nval itemsRDD \u003d itemsDF.select($\"id\", $\"title\", $\"tags\").map(row \u003d\u003e {\n  val id \u003d row.getInt(0)\n  val title \u003d row.getString(1)\n  val tagSignatures \u003d row.getString(2).trim.split(\"\\\\|\")\n    .map(tag \u003d\u003e minHasher.init(tag))\n  val combinedTagSignature \u003d minHasher.sum(tagSignatures)\n  \n  MinHashTaggedItem(id, title, combinedTagSignature)\n}).cache()\n\nval itemsCount \u003d itemsRDD.count()",
      "dateUpdated": "Jan 16, 2016 5:23:42 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "clusterId",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "items",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "clusterId",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "items",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452399782070_1501936568",
      "id": "20160110-042302_1262573744",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.sql.Row\nimport com.advancedspark.ml.MinHashTaggedItem\nimport com.twitter.algebird.{MinHasher, MinHasher32, MinHashSignature}\nnumHashes: Int \u003d 100\nminApproxLSHSimilarityThreshold: Double \u003d 0.01\nnumBands: Int \u003d 100\nminHasher: com.twitter.algebird.MinHasher32 \u003d com.twitter.algebird.MinHasher32@7400e903\nitemsRDD: org.apache.spark.rdd.RDD[com.advancedspark.ml.MinHashTaggedItem] \u003d MapPartitionsRDD[1060] at map at \u003cconsole\u003e:177\nitemsCount: Long \u003d 10\n"
      },
      "dateCreated": "Jan 10, 2016 4:23:02 AM",
      "dateStarted": "Jan 16, 2016 5:23:42 AM",
      "dateFinished": "Jan 16, 2016 5:23:45 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Group the items into their respective bucket",
      "text": "val bucketItemsRDD \u003d itemsRDD.flatMap(item \u003d\u003e {\n  val buckets \u003d minHasher.buckets(item.combinedTagSignature)\n  buckets.map(bucket \u003d\u003e \n    (bucket, Seq((item))) // Emitting as Seq so we can reduce later\n  )\n}).reduceByKey(_ ++ _).cache()\n\nval bucketCount \u003d bucketItemsRDD.count()\n\nval bucketSizes \u003d bucketItemsRDD.map(bucketItems \u003d\u003e bucketItems._2.size).collect()",
      "dateUpdated": "Jan 16, 2016 5:23:42 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452464653120_1075838869",
      "id": "20160110-222413_543198092",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "bucketItemsRDD: org.apache.spark.rdd.RDD[(Long, Seq[com.advancedspark.ml.MinHashTaggedItem])] \u003d ShuffledRDD[1062] at reduceByKey at \u003cconsole\u003e:183\nbucketCount: Long \u003d 523\nbucketSizes: Array[Int] \u003d Array(2, 1, 5, 3, 5, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 5, 1, 1, 3, 1, 1, 1, 3, 4, 2, 3, 1, 3, 3, 1, 2, 3, 1, 4, 1, 2, 1, 1, 2, 2, 3, 2, 1, 1, 3, 5, 1, 5, 4, 1, 2, 2, 3, 3, 3, 4, 2, 1, 1, 1, 1, 1, 3, 2, 1, 4, 1, 3, 3, 1, 2, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 3, 1, 1, 4, 2, 3, 1, 4, 1, 1, 3, 1, 2, 2, 1, 3, 4, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 3, 2, 1, 4, 1, 5, 2, 1, 1, 1, 1, 2, 2, 1, 4, 3, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 2, 1, 5, 1, 1, 3, 1, 1, 2, 3, 1, 1, 1, 2, 3, 2, 1, 5, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 5, 1, 2, 1, 3, 3, 3, 1, 2, 2, 3, 2, 2, 1, 1, 3, 4, 1, 2, 1, 1, 1, 1, 3, 2, 1, 4, 1, 2, 1, 1, 3, 1, 2, 2, 1, 1, 1, 3, 3, 4, 3, 5, 4, 2, 5, 4, 1, 1, 1, 2, 1, 2, 1, 3, 3, 2, 2, 1, 2, 3, 3, ..."
      },
      "dateCreated": "Jan 10, 2016 10:24:13 PM",
      "dateStarted": "Jan 16, 2016 5:23:43 AM",
      "dateFinished": "Jan 16, 2016 5:23:45 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "All Pairs Similarity Comparison within each bucket (Much Smaller Cartesian)",
      "text": "val similarItemPairsAboveThresholdRDD \u003d bucketItemsRDD.flatMap(bucketItems \u003d\u003e {\n  val allItemsWithinBucket \u003d bucketItems._2\n\n  val allItemPairsWithinBucket \u003d\n    // Cartesian product of a MUCH smaller Set of items (per bucket)\n    for { \n        item1 \u003c- allItemsWithinBucket\n        item2 \u003c- allItemsWithinBucket\n    } yield (item1, item2)\n\n  val similarItemPairsAboveThresholdWithinBucket \u003d allItemPairsWithinBucket\n    // Filter out equal items and duplicate pairs (lower triangle)\n    .filter(itemPair \u003d\u003e (itemPair._1.id \u003c itemPair._2.id)) \n    // Calculate LSH similarity for all pairs within this bucket\n    .map(itemPair \u003d\u003e \n      (itemPair._1, itemPair._2, \n        minHasher.similarity(itemPair._1.combinedTagSignature, itemPair._2.combinedTagSignature)))\n    // Keep only pairs above the given threshold\n    .filter(_._3 \u003e\u003d minApproxLSHSimilarityThreshold) \n    \n  similarItemPairsAboveThresholdWithinBucket\n}).cache()\n\n//z.show(similarItemPairsAboveThresholdRDD.toDF(\"item1\", \"item2\", \"similarity\"))",
      "dateUpdated": "Jan 16, 2016 5:23:42 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452464592186_-1269129056",
      "id": "20160110-222312_1987101632",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "similarItemPairsAboveThresholdRDD: org.apache.spark.rdd.RDD[(com.advancedspark.ml.MinHashTaggedItem, com.advancedspark.ml.MinHashTaggedItem, Double)] \u003d MapPartitionsRDD[1064] at flatMap at \u003cconsole\u003e:180\n"
      },
      "dateCreated": "Jan 10, 2016 10:23:12 PM",
      "dateStarted": "Jan 16, 2016 5:23:45 AM",
      "dateFinished": "Jan 16, 2016 5:23:46 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Prepare Items for clustering",
      "text": "val similarItemPairIdsAboveThresholdRDD \u003d similarItemPairsAboveThresholdRDD.map(itemPair \u003d\u003e \n  (itemPair._1.id, itemPair._2.id, itemPair._3)\n).cache()",
      "dateUpdated": "Jan 16, 2016 5:23:42 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452399782070_1501936568",
      "id": "20160110-042302_1946211878",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "similarItemPairIdsAboveThresholdRDD: org.apache.spark.rdd.RDD[(Long, Long, Double)] \u003d MapPartitionsRDD[1065] at map at \u003cconsole\u003e:182\n"
      },
      "dateCreated": "Jan 10, 2016 4:23:02 AM",
      "dateStarted": "Jan 16, 2016 5:23:46 AM",
      "dateFinished": "Jan 16, 2016 5:23:46 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Cluster Items By Similarity using Power Iteration Clustering",
      "text": "// http://spark.apache.org/docs/latest/mllib-clustering.html#power-iteration-clustering-pic\nimport org.apache.spark.mllib.clustering.{PowerIterationClustering, PowerIterationClusteringModel}\n\nval clustering \u003d new PowerIterationClustering().setK(5).setMaxIterations(10)\n\nval clusteringModel \u003d clustering.run(similarItemPairIdsAboveThresholdRDD)",
      "dateUpdated": "Jan 16, 2016 5:23:42 AM",
      "config": {
        "tableHide": false,
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "clusterId",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "title",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "clusterId",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452399782070_1501936568",
      "id": "20160110-042302_966856494",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.mllib.clustering.{PowerIterationClustering, PowerIterationClusteringModel}\nclustering: org.apache.spark.mllib.clustering.PowerIterationClustering \u003d org.apache.spark.mllib.clustering.PowerIterationClustering@55d27391\nclusteringModel: org.apache.spark.mllib.clustering.PowerIterationClusteringModel \u003d org.apache.spark.mllib.clustering.PowerIterationClusteringModel@7b265f0e\n"
      },
      "dateCreated": "Jan 10, 2016 4:23:02 AM",
      "dateStarted": "Jan 16, 2016 5:23:46 AM",
      "dateFinished": "Jan 16, 2016 5:23:48 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Enrich the cluster assignments",
      "text": "val clusterAssignmentsRDD \u003d clusteringModel.assignments.map { assignment \u003d\u003e\n  (assignment.id, assignment.cluster)\n}\n\nval enrichedClusterAssignmentsDF \u003d clusterAssignmentsRDD.toDF(\"itemId\", \"clusterId\")\n  .join(itemsDF, $\"itemId\" \u003d\u003d\u003d $\"id\")\n  .select($\"clusterId\", $\"itemId\", $\"title\", $\"tags\")\n  .sort($\"clusterId\" desc)\n  \nz.show(enrichedClusterAssignmentsDF)",
      "dateUpdated": "Jan 16, 2016 5:23:42 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "clusterId",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "itemId",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "clusterId",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "itemId",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452399782070_1501936568",
      "id": "20160110-042302_674258510",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "clusterId\titemId\ttitle\ttags\n4\t7\tSabrina (1995)\tComedy|Romance\n4\t3\tGrumpier Old Men (1995)\tComedy|Romance\n3\t2\tJumanji (1995)\tAdventure|Children|Fantasy\n3\t8\tTom and Huck (1995)\tAdventure|Children\n2\t1\tToy Story (1995)\tAdventure|Animation|Children|Comedy|Fantasy\n1\t6\tHeat (1995)\tAction|Crime|Thriller\n1\t10\tGoldenEye (1995)\tAction|Adventure|Thriller\n1\t9\tSudden Death (1995)\tAction\n0\t4\tWaiting to Exhale (1995)\tComedy|Drama|Romance\n0\t5\tFather of the Bride Part II (1995)\tComedy\n"
      },
      "dateCreated": "Jan 10, 2016 4:23:02 AM",
      "dateStarted": "Jan 16, 2016 5:23:47 AM",
      "dateFinished": "Jan 16, 2016 5:23:49 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Show cluster Distributions",
      "text": "val clusterDistributionDF \u003d enrichedClusterAssignmentsDF\n  .select($\"clusterId\", $\"itemId\", $\"tags\")\n  .groupBy($\"clusterId\", $\"tags\")\n  .agg(count($\"itemId\"))\n  .sort($\"clusterId\" desc)\n\nz.show(clusterDistributionDF)",
      "dateUpdated": "Jan 16, 2016 5:23:42 AM",
      "config": {
        "tableHide": false,
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "graph": {
          "mode": "multiBarChart",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "clusterId",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "count(itemId)",
              "index": 2.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "clusterId",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452399782070_1501936568",
      "id": "20160110-042302_831247746",
      "result": {
        "code": "SUCCESS",
        "type": "TABLE",
        "msg": "clusterId\ttags\tcount(itemId)\n4\tComedy|Romance\t2\n3\tAdventure|Children|Fantasy\t1\n3\tAdventure|Children\t1\n2\tAdventure|Animation|Children|Comedy|Fantasy\t1\n1\tAction\t1\n1\tAction|Crime|Thriller\t1\n1\tAction|Adventure|Thriller\t1\n0\tComedy|Drama|Romance\t1\n0\tComedy\t1\n"
      },
      "dateCreated": "Jan 10, 2016 4:23:02 AM",
      "dateStarted": "Jan 16, 2016 5:23:48 AM",
      "dateFinished": "Jan 16, 2016 5:23:50 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "dateUpdated": "Jan 16, 2016 5:23:42 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452399782071_1501551819",
      "id": "20160110-042302_1914776395",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT"
      },
      "dateCreated": "Jan 10, 2016 4:23:02 AM",
      "dateStarted": "Jan 16, 2016 5:23:49 AM",
      "dateFinished": "Jan 16, 2016 5:23:50 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Clustering/02: Approx All Pairs Similarity (LSH + Power Iteration)",
  "id": "2B8GP7GBZ",
  "angularObjects": {
    "2ARR8UZDJ": [],
    "2AS9P7JSA": [],
    "2AR33ZMZJ": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}