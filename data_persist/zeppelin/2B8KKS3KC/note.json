{
  "paragraphs": [
    {
      "text": "import org.apache.spark.ml.feature.CountVectorizer\nimport org.apache.spark.ml.feature.RegexTokenizer\nimport org.apache.spark.ml.feature.StopWordsRemover\nimport org.apache.spark.ml.feature.Word2Vec\nimport org.apache.spark.ml.feature.Word2VecModel\nimport org.apache.spark.ml.feature.HashingTF\nimport org.apache.spark.ml.feature.IDF\nimport org.apache.spark.ml.feature.IDFModel\nimport org.apache.spark.ml.feature.RegexTokenizer\nimport org.apache.spark.ml.feature.OneHotEncoder\nimport org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.ml.feature.StringIndexer\nimport org.apache.spark.ml.feature.StringIndexerModel\nimport org.apache.spark.ml.feature.IndexToString\nimport org.apache.spark.ml.classification.DecisionTreeClassifier\nimport org.apache.spark.ml.classification.DecisionTreeClassificationModel\nimport org.apache.spark.ml.tuning.ParamGridBuilder\nimport org.apache.spark.ml.tuning.CrossValidator\nimport org.apache.spark.ml.tuning.TrainValidationSplit\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nimport org.apache.spark.ml.Pipeline\nimport org.apache.spark.ml.PipelineModel\nimport org.apache.spark.mllib.clustering.LDA\nimport org.apache.spark.mllib.clustering.OnlineLDAOptimizer\nimport org.apache.spark.mllib.linalg.Vector\nimport org.apache.spark.sql.Row\nimport sqlContext.implicits._",
      "dateUpdated": "Jan 8, 2016 2:31:40 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445430869237_746771347",
      "id": "20151021-123429_1735745824",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.ml.feature.CountVectorizer\nimport org.apache.spark.ml.feature.RegexTokenizer\nimport org.apache.spark.ml.feature.StopWordsRemover\nimport org.apache.spark.ml.feature.Word2Vec\nimport org.apache.spark.ml.feature.Word2VecModel\nimport org.apache.spark.ml.feature.HashingTF\nimport org.apache.spark.ml.feature.IDF\nimport org.apache.spark.ml.feature.IDFModel\nimport org.apache.spark.ml.feature.RegexTokenizer\nimport org.apache.spark.ml.feature.OneHotEncoder\nimport org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.ml.feature.StringIndexer\nimport org.apache.spark.ml.feature.StringIndexerModel\nimport org.apache.spark.ml.feature.IndexToString\nimport org.apache.spark.ml.classification.DecisionTreeClassifier\nimport org.apache.spark.ml.classification.DecisionTreeClassificationModel\nimport org.apache.spark.ml.tuning.ParamGridBuilder\nimport org.apache.spark.ml.tuning.CrossValidator\nimport org.apache.spark.ml.tuning.TrainValidationSplit\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nimport org.apache.spark.ml.Pipeline\nimport org.apache.spark.ml.PipelineModel\nimport org.apache.spark.mllib.clustering.LDA\nimport org.apache.spark.mllib.clustering.OnlineLDAOptimizer\nimport org.apache.spark.mllib.linalg.Vector\nimport org.apache.spark.sql.Row\nimport sqlContext.implicits._\n"
      },
      "dateCreated": "Oct 21, 2015 12:34:29 PM",
      "dateStarted": "Jan 8, 2016 2:31:40 AM",
      "dateFinished": "Jan 8, 2016 2:31:44 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val itemsDF \u003d sqlContext.read.format(\"json\")\n  .load(\"file:/root/pipeline/html/advancedspark.com/json/software.json\")\n  .select($\"id\", $\"title\", $\"category\", $\"description\")",
      "dateUpdated": "Jan 8, 2016 1:47:54 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "id",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "title",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "id",
              "index": 0.0,
              "aggr": "sum"
            },
            "yAxis": {
              "name": "title",
              "index": 1.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451704834989_870454693",
      "id": "20160102-032034_619481341",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "itemsDF: org.apache.spark.sql.DataFrame \u003d [id: bigint, title: string, category: string, description: string]\n"
      },
      "dateCreated": "Jan 2, 2016 3:20:34 AM",
      "dateStarted": "Jan 8, 2016 1:47:54 AM",
      "dateFinished": "Jan 8, 2016 1:47:56 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val distinctCategories \u003d itemsDF.select($\"category\").distinct().collect()",
      "dateUpdated": "Jan 8, 2016 2:03:02 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451771827145_-655270163",
      "id": "20160102-215707_46317998",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "res316: Array[org.apache.spark.sql.Row] \u003d Array([Notebook], [Cloud Provider], [Distribution], [Distributed Cache], [UI], [BI], [Cluster Resource Manager], [Cluster Provision], [Message Broker], [Programming Language], [Streaming], [Distributed Coordinator], [Category], [Search Engine], [Data Processing Execution Engine], [Data Import], [Workflow], [File Format], [Library], [File System], [Database])\n"
      },
      "dateCreated": "Jan 2, 2016 9:57:07 PM",
      "dateStarted": "Jan 8, 2016 1:47:56 AM",
      "dateFinished": "Jan 8, 2016 1:47:56 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md ## TODO:  Add Diagram with Pipeline Stages to help Visualize ",
      "dateUpdated": "Jan 8, 2016 1:47:54 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452215933962_1996249260",
      "id": "20160108-011853_334678135",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003ch2\u003eTODO:  Add Diagram with Pipeline Stages to help Visualize\u003c/h2\u003e\n"
      },
      "dateCreated": "Jan 8, 2016 1:18:53 AM",
      "dateStarted": "Jan 8, 2016 1:47:54 AM",
      "dateFinished": "Jan 8, 2016 1:47:54 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Split each document into words\nval tokenizer \u003d new RegexTokenizer()\n  .setInputCol(\"description\")\n  .setOutputCol(\"words\")\n  .setGaps(false)\n  .setPattern(\"\\\\p{L}+\")",
      "dateUpdated": "Jan 8, 2016 1:47:54 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451704551688_-754338267",
      "id": "20160102-031551_2007021723",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "tokenizer: org.apache.spark.ml.feature.RegexTokenizer \u003d regexTok_7f0035ea898c\n"
      },
      "dateCreated": "Jan 2, 2016 3:15:51 AM",
      "dateStarted": "Jan 8, 2016 1:47:56 AM",
      "dateFinished": "Jan 8, 2016 1:47:56 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Filter out stopwords\n// The following list will be used by default if we don\u0027t specify a list:  \n//   http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words\nval stopWordsFilter \u003d new StopWordsRemover()\n  .setInputCol(tokenizer.getOutputCol)\n  .setOutputCol(\"filteredWords\")\n  .setCaseSensitive(false)",
      "dateUpdated": "Jan 8, 2016 1:47:54 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451413520885_1262045843",
      "id": "20151229-182520_534225248",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "stopWordsFilter: org.apache.spark.ml.feature.StopWordsRemover \u003d stopWords_9b525a20a83f\n"
      },
      "dateCreated": "Dec 29, 2015 6:25:20 PM",
      "dateStarted": "Jan 8, 2016 1:47:56 AM",
      "dateFinished": "Jan 8, 2016 1:47:57 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val tf \u003d new HashingTF()\n  .setInputCol(stopWordsFilter.getOutputCol)\n  .setOutputCol(\"tfFeatures\")",
      "dateUpdated": "Jan 8, 2016 1:47:54 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451704581368_-518071794",
      "id": "20160102-031621_1939813047",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "tf: org.apache.spark.ml.feature.HashingTF \u003d hashingTF_3add5d57a1a4\n"
      },
      "dateCreated": "Jan 2, 2016 3:16:21 AM",
      "dateStarted": "Jan 8, 2016 1:47:57 AM",
      "dateFinished": "Jan 8, 2016 1:47:57 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Limit to top `vocabSize` most common words and convert to word count vector features\nval idf \u003d new IDF()\n  .setInputCol(tf.getOutputCol)\n  .setOutputCol(\"idfFeatures\")",
      "dateUpdated": "Jan 8, 2016 1:47:54 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451775771985_-1247745195",
      "id": "20160102-230251_1962189552",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "idf: org.apache.spark.ml.feature.IDF \u003d idf_7aa8534e46b0\n"
      },
      "dateCreated": "Jan 2, 2016 11:02:51 PM",
      "dateStarted": "Jan 8, 2016 1:47:57 AM",
      "dateFinished": "Jan 8, 2016 1:47:57 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val word2Vec \u003d new Word2Vec()\n  .setInputCol(stopWordsFilter.getOutputCol)\n  .setOutputCol(\"word2VecFeatures\")",
      "dateUpdated": "Jan 8, 2016 1:47:54 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451774266280_-1197671999",
      "id": "20160102-223746_818202498",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "word2Vec: org.apache.spark.ml.feature.Word2Vec \u003d w2v_5d5e061afc45\n"
      },
      "dateCreated": "Jan 2, 2016 10:37:46 PM",
      "dateStarted": "Jan 8, 2016 1:47:57 AM",
      "dateFinished": "Jan 8, 2016 1:47:57 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Combine IF, IDF, and Word2Vec\nval featureVectorAssembler \u003d new VectorAssembler()\n  .setInputCols(Array(idf.getOutputCol, word2Vec.getOutputCol))\n  .setOutputCol(\"allFeatures\")",
      "dateUpdated": "Jan 8, 2016 1:47:54 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451774247109_110458938",
      "id": "20160102-223727_1555430952",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "featureVectorAssembler: org.apache.spark.ml.feature.VectorAssembler \u003d vecAssembler_63b4b0169b0a\n"
      },
      "dateCreated": "Jan 2, 2016 10:37:27 PM",
      "dateStarted": "Jan 8, 2016 1:47:57 AM",
      "dateFinished": "Jan 8, 2016 1:47:57 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Assign an Index to Each Category \nval categoryIndexerModel \u003d new StringIndexer()\n  .setInputCol(\"category\")\n  .setOutputCol(\"indexedCategory\")\n  .fit(itemsDF)\n  //.setHandleInvalid(\"skip\")",
      "dateUpdated": "Jan 8, 2016 2:14:50 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451768708398_-1255734024",
      "id": "20160102-210508_277987434",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "categoryIndexerModel: org.apache.spark.ml.feature.StringIndexerModel \u003d strIdx_eb5069e35924\n"
      },
      "dateCreated": "Jan 2, 2016 9:05:08 PM",
      "dateStarted": "Jan 8, 2016 2:14:50 AM",
      "dateFinished": "Jan 8, 2016 2:14:51 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val classifier \u003d new DecisionTreeClassifier()\n  .setFeaturesCol(featureVectorAssembler.getOutputCol)\n  .setLabelCol(categoryIndexerModel.getOutputCol)\n  .setPredictionCol(\"prediction\")\n  .setRawPredictionCol(\"confidence\")\n  .setProbabilityCol(\"probability\")",
      "dateUpdated": "Jan 8, 2016 2:14:57 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451714221599_169436069",
      "id": "20160102-055701_1764018921",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "classifier: org.apache.spark.ml.classification.DecisionTreeClassifier \u003d dtc_cfab70f2f5a4\n"
      },
      "dateCreated": "Jan 2, 2016 5:57:01 AM",
      "dateStarted": "Jan 8, 2016 2:14:57 AM",
      "dateFinished": "Jan 8, 2016 2:14:57 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val categoryReverseIndexer \u003d new IndexToString()\n  .setInputCol(classifier.getPredictionCol)\n  .setOutputCol(\"predictedCategory\")\n  .setLabels(categoryIndexerModel.labels)",
      "dateUpdated": "Jan 8, 2016 2:21:02 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452219659117_711798430",
      "id": "20160108-022059_1281293442",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "categoryReverseIndexer: org.apache.spark.ml.feature.IndexToString \u003d idxToStr_80952b1603e7\n"
      },
      "dateCreated": "Jan 8, 2016 2:20:59 AM",
      "dateStarted": "Jan 8, 2016 2:21:02 AM",
      "dateFinished": "Jan 8, 2016 2:21:02 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val pipeline \u003d new Pipeline()\n  .setStages(Array(tokenizer, stopWordsFilter, tf, idf, word2Vec, featureVectorAssembler, categoryIndexerModel, classifier, categoryReverseIndexer))",
      "dateUpdated": "Jan 8, 2016 2:21:18 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451714366805_831050936",
      "id": "20160102-055926_1532666557",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "pipeline: org.apache.spark.ml.Pipeline \u003d pipeline_12613998ca2c\n"
      },
      "dateCreated": "Jan 2, 2016 5:59:26 AM",
      "dateStarted": "Jan 8, 2016 2:21:18 AM",
      "dateFinished": "Jan 8, 2016 2:21:18 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val metricName \u003d \"f1\"\n\nval modelEvaluator \u003d new MulticlassClassificationEvaluator()\n  .setLabelCol(classifier.getLabelCol)\n  .setPredictionCol(classifier.getPredictionCol)\n  .setMetricName(metricName)",
      "dateUpdated": "Jan 8, 2016 2:21:23 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451769445587_-1118091320",
      "id": "20160102-211725_268797232",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "metricName: String \u003d f1\nmodelEvaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator \u003d mcEval_509ff3f406db\n"
      },
      "dateCreated": "Jan 2, 2016 9:17:25 PM",
      "dateStarted": "Jan 8, 2016 2:21:23 AM",
      "dateFinished": "Jan 8, 2016 2:21:23 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val paramGrid \u003d new ParamGridBuilder()\n  .addGrid(tf.numFeatures, Array(10, 100))\n  .addGrid(idf.minDocFreq, Array(1, 10))\n  .addGrid(word2Vec.vectorSize, Array(200, 300))\n  .addGrid(classifier.maxDepth, Array(3, 5))\n  .build()",
      "dateUpdated": "Jan 8, 2016 2:21:26 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451771035936_440379213",
      "id": "20160102-214355_638942362",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "paramGrid: Array[org.apache.spark.ml.param.ParamMap] \u003d \nArray({\n\tdtc_cfab70f2f5a4-maxDepth: 3,\n\tidf_7aa8534e46b0-minDocFreq: 1,\n\thashingTF_3add5d57a1a4-numFeatures: 10,\n\tw2v_5d5e061afc45-vectorSize: 200\n}, {\n\tdtc_cfab70f2f5a4-maxDepth: 3,\n\tidf_7aa8534e46b0-minDocFreq: 1,\n\thashingTF_3add5d57a1a4-numFeatures: 100,\n\tw2v_5d5e061afc45-vectorSize: 200\n}, {\n\tdtc_cfab70f2f5a4-maxDepth: 3,\n\tidf_7aa8534e46b0-minDocFreq: 10,\n\thashingTF_3add5d57a1a4-numFeatures: 10,\n\tw2v_5d5e061afc45-vectorSize: 200\n}, {\n\tdtc_cfab70f2f5a4-maxDepth: 3,\n\tidf_7aa8534e46b0-minDocFreq: 10,\n\thashingTF_3add5d57a1a4-numFeatures: 100,\n\tw2v_5d5e061afc45-vectorSize: 200\n}, {\n\tdtc_cfab70f2f5a4-maxDepth: 5,\n\tidf_7aa8534e46b0-minDocFreq: 1,\n\thashingTF_3add5d57a1a4-numFeatures: 10,\n\tw2v_5d5e061afc45-vectorSize: 200\n}, {\n\tdtc_cfab..."
      },
      "dateCreated": "Jan 2, 2016 9:43:55 PM",
      "dateStarted": "Jan 8, 2016 2:21:26 AM",
      "dateFinished": "Jan 8, 2016 2:21:26 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// K-Folds Cross Validation Combined With Param Grid \nval numFolds \u003d 3\n\nval modelValidator \u003d new CrossValidator()\n  .setEstimator(pipeline)\n  .setEvaluator(modelEvaluator)\n  .setEstimatorParamMaps(paramGrid)\n  .setNumFolds(numFolds) ",
      "dateUpdated": "Jan 8, 2016 2:21:28 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451770989649_-868764763",
      "id": "20160102-214309_573238279",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "numFolds: Int \u003d 3\nmodelValidator: org.apache.spark.ml.tuning.CrossValidator \u003d cv_f351010042b7\n"
      },
      "dateCreated": "Jan 2, 2016 9:43:09 PM",
      "dateStarted": "Jan 8, 2016 2:21:28 AM",
      "dateFinished": "Jan 8, 2016 2:21:29 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val crossValidatorModel \u003d modelValidator.fit(itemsDF)",
      "dateUpdated": "Jan 8, 2016 2:21:32 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451771239364_977982340",
      "id": "20160102-214719_422404290",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "crossValidatorModel: org.apache.spark.ml.tuning.CrossValidatorModel \u003d cv_f351010042b7\n"
      },
      "dateCreated": "Jan 2, 2016 9:47:19 PM",
      "dateStarted": "Jan 8, 2016 2:21:32 AM",
      "dateFinished": "Jan 8, 2016 2:22:06 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Print out best hyper-parameters for the bestModel\nval bestModel \u003d crossValidatorModel.bestModel.asInstanceOf[PipelineModel]\n\n//val paramGrid \u003d new ParamGridBuilder()\n//  .addGrid(tf.numFeatures, Array(10, 100))\n//  .addGrid(idf.minDocFreq, Array(1, 10))\n//  .addGrid(word2Vec.vectorSize, Array(200, 300))\n//  .addGrid(classifier.maxDepth, Array(3, 5))\n//  .build()\n  \n// Explain params for each stage of the PipelineModel from the CrossValidator and ParamGrid\nval bestHashingTFNumFeatures \u003d bestModel.stages(2).asInstanceOf[HashingTF].explainParams\nval bestIDFMinDocFrequency \u003d bestModel.stages(3).asInstanceOf[IDFModel].explainParams\n//.get(\"minDocFreq\")\nval bestWord2VecVectorSize \u003d bestModel.stages(4).asInstanceOf[Word2VecModel].explainParams\nval bestDecisionTreeDepth \u003d bestModel.stages(7).asInstanceOf[DecisionTreeClassificationModel].explainParams\n\n// TODO: How do I print the numFeatures from the input features?",
      "dateUpdated": "Jan 8, 2016 2:44:15 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451772919906_1239014473",
      "id": "20160102-221519_627091553",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "bestModel: org.apache.spark.ml.PipelineModel \u003d pipeline_5c569e833845\nbestHashingTFNumFeatures: String \u003d \ninputCol: input column name (current: filteredWords)\nnumFeatures: number of features (\u003e 0) (default: 262144, current: 10)\noutputCol: output column name (default: hashingTF_3add5d57a1a4__output, current: tfFeatures)\nbestIDFMinDocFrequency: String \u003d \ninputCol: input column name (current: tfFeatures)\nminDocFreq: minimum of documents in which a term should appear for filtering (default: 0, current: 1)\noutputCol: output column name (default: idf_7aa8534e46b0__output, current: idfFeatures)\nbestWord2VecVectorSize: String \u003d \ninputCol: input column name (current: filteredWords)\nmaxIter: maximum number of iterations (\u003e\u003d 0) (default: 1)\nminCount: the minimum number of times a token must appear to be included in the word2vec model\u0027s vocabulary (default: 5)\nnumPartitions: number of partitions for sentences of words (default: 1)\noutputCol: output column name (default: w2v_5d5e061afc45__output, current: word2VecFeatures)\nseed: random seed (default: -1961189076)\nstepSize: Step size to be used for each iteration of optimization. (default: 0.025)\nvectorSize: the dimension of codes after transforming from words (default: 100, current: 300)\nwindowSize: the window size (context words from [-window, window]) (default: 5)\nbestDecisionTreeDepth: String \u003d \nfeaturesCol: features column name (default: features, current: allFeatures)\nlabelCol: label column name (default: label, current: indexedCategory)\npredictionCol: prediction column name (default: prediction, current: prediction)\nprobabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities (default: probability, current: probability)\nrawPredictionCol: raw prediction (a.k.a. confidence) column name (default: rawPrediction, current: confidence)\nthresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes..."
      },
      "dateCreated": "Jan 2, 2016 10:15:19 PM",
      "dateStarted": "Jan 8, 2016 2:44:15 AM",
      "dateFinished": "Jan 8, 2016 2:44:16 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Create Prediction Pipeline\n//val predictOnDF \u003d itemsDF.select($\"description\")\n\nval predictOnDF \u003d sqlContext.createDataFrame(Seq(\n      (1, \"Stanford University is located in California. It is a great university.\")\n    )).toDF(\"id\", \"description\")\n\nval predictedResultsDF \u003d bestModel.transform(predictOnDF)\n .select(classifier.getPredictionCol, categoryReverseIndexer.getOutputCol, stopWordsFilter.getOutputCol, classifier.getRawPredictionCol, classifier.getProbabilityCol)\n\nz.show(predictedResultsDF)",
      "dateUpdated": "Jan 8, 2016 3:54:50 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [
            {
              "name": "prediction",
              "index": 0.0,
              "aggr": "sum"
            }
          ],
          "values": [
            {
              "name": "predictedCategory",
              "index": 1.0,
              "aggr": "sum"
            }
          ],
          "groups": [],
          "scatter": {
            "xAxis": {
              "name": "prediction",
              "index": 0.0,
              "aggr": "sum"
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451704614990_2073874276",
      "id": "20160102-031654_499992823",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "predictOnDF: org.apache.spark.sql.DataFrame \u003d [id: int, description: string]\n\u003cconsole\u003e:30: error: not found: value bestModel\n       val predictedResultsDF \u003d bestModel.transform(predictOnDF)\n                                ^\n"
      },
      "dateCreated": "Jan 2, 2016 3:16:54 AM",
      "dateStarted": "Jan 8, 2016 3:54:50 AM",
      "dateFinished": "Jan 8, 2016 3:55:04 AM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "dateUpdated": "Jan 8, 2016 2:24:07 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1452217950823_214978392",
      "id": "20160108-015230_770789401",
      "dateCreated": "Jan 8, 2016 1:52:30 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "NLP/02: Text Classification (TF/IDF + Word2Vec, Decision Tree)",
  "id": "2B8KKS3KC",
  "angularObjects": {
    "2ARR8UZDJ": [],
    "2AS9P7JSA": [],
    "2AR33ZMZJ": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}