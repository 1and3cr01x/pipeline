{
  "paragraphs": [
    {
      "text": "%md ![Most Desirable Users](http://advancedspark.com/img/connected-users-with-cost.png)",
      "dateUpdated": "Jan 9, 2016 8:27:38 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451274621785_-2091468050",
      "id": "20151228-035021_708663317",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003e\u003cimg src\u003d\"http://advancedspark.com/img/connected-users-with-cost.png\" alt\u003d\"Most Desirable Users\" /\u003e\u003c/p\u003e\n"
      },
      "dateCreated": "Dec 28, 2015 3:50:21 AM",
      "dateStarted": "Jan 9, 2016 8:27:38 PM",
      "dateFinished": "Jan 9, 2016 8:27:38 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Define Dijkstra\u0027s Shortest Path Algo",
      "text": "import org.apache.spark.graphx._\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.types._\n\n// Shamelessly lifted from GraphX In Action (Great Book!)\ndef dijkstra(graph: Graph[VertexId, Double], srcId: VertexId): Graph[(VertexId, List[Any]), Double] \u003d {\n  // Dijkstra Shortest Path\n  var graph2 \u003d graph.mapVertices((vid,vd) \u003d\u003e \n    (false, if (vid \u003d\u003d srcId) 0 else Double.MaxValue, List[VertexId]()))\n\n  for (i \u003c- 1L to graph.vertices.count-1) {\n    // The fold() below simulates minBy() functionality\n    val currentVertexId \u003d graph2.vertices.filter(!_._2._1)\n      .fold((0L,(false,Double.MaxValue,List[VertexId]())))((a,b) \u003d\u003e\n        if (a._2._2 \u003c b._2._2) a else b)._1\n      \n\n    val newDistances \u003d graph2.aggregateMessages[(Double,List[VertexId])](ctx \u003d\u003e \n      if (ctx.srcId \u003d\u003d currentVertexId) \n        ctx.sendToDst((ctx.srcAttr._2 + ctx.attr, ctx.srcAttr._3 :+ ctx.srcId)),\n          (a,b) \u003d\u003e if (a._1 \u003c b._1) a else b)\n        \n    graph2 \u003d graph2.outerJoinVertices(newDistances)((vid, vd, newSum) \u003d\u003e {\n      val newSumVal \u003d newSum.getOrElse((Double.MaxValue,List[VertexId]()))\n        (vd._1 || vid \u003d\u003d currentVertexId, math.min(vd._2, newSumVal._1),\n          if (vd._2 \u003c newSumVal._1) vd._3 else newSumVal._2)})\n  }\n\n  val shortestPathGraph \u003d graph.outerJoinVertices(graph2.vertices)((vid, vd, dist) \u003d\u003e \n    (vd, dist.getOrElse((false,Double.MaxValue,List[VertexId]()))\n    .productIterator.toList.tail))\n  \n  shortestPathGraph\n}",
      "dateUpdated": "Jan 9, 2016 8:27:38 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true,
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451274773593_-1643373499",
      "id": "20151228-035253_2016855462",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.graphx._\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.types._\ndijkstra: (graph: org.apache.spark.graphx.Graph[org.apache.spark.graphx.VertexId,Double], srcId: org.apache.spark.graphx.VertexId)org.apache.spark.graphx.Graph[(org.apache.spark.graphx.VertexId, List[Any]),Double]\n"
      },
      "dateCreated": "Dec 28, 2015 3:52:53 AM",
      "dateStarted": "Jan 9, 2016 8:27:38 PM",
      "dateFinished": "Jan 9, 2016 8:27:49 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val graphDF \u003d sqlContext.read\n  .format(\"com.databricks.spark.csv\")\n  .option(\"header\", \"false\")\n  .load(\"/root/pipeline/datasets/graph/graph.csv\")\n  .toDF(\"userId1\", \"userId2\", \"cost\")\n  \n// Edges has a cost that we\u0027re trying to minimize\nval connectionEdgesRDD \u003d graphDF.map(row \u003d\u003e {\n  Edge(row(0).toString.toLong, row(1).toString.toLong, row(2).toString.toDouble)\n})\n\nval graph \u003d Graph.fromEdges(connectionEdgesRDD, 0L)\n\nval src \u003d  10002L // Source vertex\nval dest \u003d 90002L // Dest vertex\n\n// Run Dijkstra on the entire graph\nval shortestPathGraph \u003d dijkstra(graph, src)\n\n// Retrieve only the vertices containing the dest vertex that we\u0027re looking for\nval shortestPathFromSrcToDest \u003d shortestPathGraph.vertices.filter(_._1 \u003d\u003d dest).map(_._2).collect()(0)._2\n\n// Example\n//\n// Shortest Path\n//   10002 -5-\u003e 90003 -2-\u003e 10001 -1-\u003e 90001 -3-\u003e 90002\n// Total Cost \u003d 11",
      "dateUpdated": "Jan 9, 2016 8:27:38 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451274763346_-1561452631",
      "id": "20151228-035243_771934602",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "graphDF: org.apache.spark.sql.DataFrame \u003d [userId1: string, userId2: string, cost: string]\nconnectionEdgesRDD: org.apache.spark.rdd.RDD[org.apache.spark.graphx.Edge[Double]] \u003d MapPartitionsRDD[9] at map at \u003cconsole\u003e:40\ngraph: org.apache.spark.graphx.Graph[Long,Double] \u003d org.apache.spark.graphx.impl.GraphImpl@205b16d4\nsrc: Long \u003d 10002\ndest: Long \u003d 90002\nshortestPathGraph: org.apache.spark.graphx.Graph[(org.apache.spark.graphx.VertexId, List[Any]),Double] \u003d org.apache.spark.graphx.impl.GraphImpl@30fcd8d5\nshortestPathFromSrcToDest: List[Any] \u003d List(11.0, List(10002, 90003, 10001, 90001))\n"
      },
      "dateCreated": "Dec 28, 2015 3:52:43 AM",
      "dateStarted": "Jan 9, 2016 8:27:38 PM",
      "dateFinished": "Jan 9, 2016 8:27:57 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "dateUpdated": "Jan 9, 2016 8:27:38 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1451401103924_621545220",
      "id": "20151229-145823_414962899",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT"
      },
      "dateCreated": "Dec 29, 2015 2:58:23 PM",
      "dateStarted": "Jan 9, 2016 8:27:50 PM",
      "dateFinished": "Jan 9, 2016 8:27:57 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Graph/03: Shortest Path (Dijkstra)",
  "id": "2BAFX81J2",
  "angularObjects": {
    "2ARR8UZDJ": [],
    "2AS9P7JSA": [],
    "2AR33ZMZJ": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}