{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model with GPU (and CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import timeline\n",
    "import pylab\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "version = int(datetime.now().strftime(\"%s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.2 Create input data using NumPy. y = x * 0.1 + 0.3 + noise\n",
    "x_train = np.random.rand(num_samples).astype(np.float32)\n",
    "print(x_train)\n",
    "\n",
    "noise = np.random.normal(scale=0.01, size=len(x_train))\n",
    "\n",
    "y_train = x_train * 0.1 + 0.3 + noise\n",
    "print(y_train)\n",
    "\n",
    "# Pplot our input data.\n",
    "pylab.plot(x_train, y_train, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create some fake test/validation data\n",
    "x_test = np.random.rand(len(x_train)).astype(np.float32)\n",
    "print(x_test)\n",
    "\n",
    "noise = np.random.normal(scale=.01, size=len(x_train))\n",
    "\n",
    "y_test = x_test * 0.1 + 0.3 + noise\n",
    "print(y_test)\n",
    "\n",
    "pylab.plot(x_train, y_train, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.3 Build inference graph.\n",
    "# Create Variables W and b that compute y = W * x + b\n",
    "with tf.device(\"/cpu:0\"):\n",
    "  W = tf.get_variable(shape=[], name='weights')\n",
    "  print(W)\n",
    "\n",
    "  b = tf.get_variable(shape=[], name='bias')\n",
    "  print(b)\n",
    "\n",
    "  # Create a placeholder we'll use later to feed x's into the graph for training and test.\n",
    "  # shape=[None] means we can put in any number of examples. \n",
    "  # This is used for minibatch training, and to evaluate a lot of examples at once.\n",
    "  x_observed = tf.placeholder(shape=[None], dtype=tf.float32, name='x_observed')\n",
    "  print(x_observed)\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "#  with jit_scope():\n",
    "    # Same as tf.add(tf.matmul(W, tf.transpose(x)), b)\n",
    "    y_pred = W * x_observed + b\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.4 Build training graph.\n",
    "# Create an operation that calculates loss.\n",
    "\n",
    "# Create a placeholder we'll use later to feed the correct y value into the graph\n",
    "with tf.device(\"/gpu:0\"):\n",
    "#  with jit_scope():\n",
    "    y_observed = tf.placeholder(shape=[None], dtype=tf.float32, name='y_observed')\n",
    "    print(y_observed)\n",
    "\n",
    "    loss_op = tf.reduce_mean(tf.square(y_pred - y_observed))\n",
    "\n",
    "    # Create an optimizer.\n",
    "    optimizer_op = tf.train.GradientDescentOptimizer(0.025)  \n",
    "\n",
    "    # Create an operation that minimizes loss.\n",
    "    train_op = optimizer_op.minimize(loss_op)  \n",
    "\n",
    "    # 'loss', 'optimizer' and 'train' are.\n",
    "    print(\"loss:\", loss_op)\n",
    "    print(\"optimizer:\", optimizer_op)\n",
    "    print(\"train:\", train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an operation to initialize all the variables.\n",
    "with tf.device(\"/cpu:0\"):\n",
    "  init_op = tf.global_variables_initializer()\n",
    "  print(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summary_writer = tf.summary.FileWriter('/root/tensorboard/linear/gpu/%s/train' % version, graph=tf.get_default_graph())\n",
    "\n",
    "test_summary_writer = tf.summary.FileWriter('/root/tensorboard/linear/gpu/%s/test' % version, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto(\n",
    "  log_device_placement=True,\n",
    ")\n",
    "config.gpu_options.allow_growth=True\n",
    "print(config)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "print(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init_op)\n",
    "print(sess.run(W))\n",
    "print(sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the Model Graph In Tensorboard\n",
    "\n",
    "http://[ip-address]:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of Random Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convenience method for evaluating the loss (error)\n",
    "def test(x, y):\n",
    "  return sess.run(loss_op, feed_dict={x_observed: x, y_observed: y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy on the test data using random initial values for y\n",
    "# Note:  This should be relatively far from 0 since we haven't yet trained the model\n",
    "test(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a Summary Operation so we can visualize the loss in TensorBoard\n",
    "loss_summary_scalar_op = tf.summary.scalar('loss', loss_op)\n",
    "loss_summary_merge_all_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_steps = 350\n",
    "\n",
    "run_metadata = tf.RunMetadata()\n",
    "\n",
    "for step in range(max_steps):\n",
    "  # Run the training op; feed the training data into the graph\n",
    "  if (step < max_steps):\n",
    "    test_summary_log, _ = sess.run([loss_summary_merge_all_op, loss_op], feed_dict={x_observed: x_test, y_observed: y_test})\n",
    "    train_summary_log, _ = sess.run([loss_summary_merge_all_op, train_op], feed_dict={x_observed: x_train, y_observed: y_train})\n",
    "  else:  \n",
    "    test_summary_log, _ = sess.run([loss_summary_merge_all_op, loss_op], feed_dict={x_observed: x_test, y_observed: y_test})\n",
    "    train_summary_log, _ = sess.run([loss_summary_merge_all_op, train_op], feed_dict={x_observed: x_train, y_observed: y_train}, options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE), run_metadata=run_metadata)\n",
    "    trace = timeline.Timeline(step_stats=run_metadata.step_stats)    \n",
    "    with open('gpu-timeline.json', 'w') as trace_file:\n",
    "      trace_file.write(trace.generate_chrome_trace_format(show_memory=True))\n",
    "\n",
    "# The following take a relatively long time, so do them at periodic intervals\n",
    "  if step % 5 == 0:\n",
    "    print(step, sess.run([W, b]))\n",
    "    train_summary_writer.add_summary(train_summary_log, step)\n",
    "    train_summary_writer.flush()\n",
    "    test_summary_writer.add_summary(test_summary_log, step)\n",
    "    test_summary_writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the predicted values\n",
    "pylab.plot(x_train, y_train, '.', label=\"target\")\n",
    "pylab.plot(x_train, sess.run(y_pred, feed_dict={x_observed: x_train, y_observed: y_train}), \".\", label=\"predicted\")\n",
    "pylab.legend()\n",
    "pylab.ylim(0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check accuracy on eval data after training\n",
    "# Note:  This should be close to 0!\n",
    "test(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the Train and Test Loss Summary In Tensorboard\n",
    "\n",
    "Navigate to the Scalars tab at this URL:\n",
    "\n",
    "http://[ip-address]:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = \"/root/models/linear/gpu/%s\" % version\n",
    "print(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import signature_def_utils\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "  builder = saved_model_builder.SavedModelBuilder(export_path)\n",
    "\n",
    "prediction_signature =  signature_def_utils.build_signature_def(\n",
    "    inputs = {'x_observed': tensor_info_x_observed}, \n",
    "    outputs = {'y_pred': tensor_info_y_pred}, \n",
    "    method_name = signature_constants.PREDICT_METHOD_NAME)            \n",
    "\n",
    "legacy_init_op = tf.group(tf.initialize_all_tables(), name='legacy_init_op')\n",
    "\n",
    "builder.add_meta_graph_and_variables(sess, \n",
    "  [tag_constants.SERVING],\n",
    "  signature_def_map={'predict':prediction_signature,\n",
    "  signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:prediction_signature}, \n",
    "  legacy_init_op=legacy_init_op)\n",
    "\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Model On Disk\n",
    "\n",
    "You must replace `[version]` with the version number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/linear/gpu/[version]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HACK: Save Model in Previous Format\n",
    "We will use this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import graph_io\n",
    "graph_io.write_graph(sess.graph, \"/root/models/optimize_me/\", \"unoptimized_gpu.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
