{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Graph Transform Tool](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/graph_transforms)\n",
    "Great [Blog Post](https://petewarden.com/2016/12/30/rewriting-tensorflow-graphs-with-the-gtt/) by [Pete Warden](https://www.linkedin.com/in/petewarden) from Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Trained Models for Inference\n",
    "## Types of Optimizations\n",
    "* Remove training-only operations (checkpoint saving, drop out)\n",
    "* Strip out unused nodes\n",
    "* Remove debug operations\n",
    "* Fold batch normalization ops into weights (super cool)\n",
    "* Round weights\n",
    "* Quantize weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Types of Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Model (CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/optimize_me/linear/cpu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "summarize_graph --in_graph=/root/models/optimize_me/linear/cpu/unoptimized_model_cpu.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import re\n",
    "from google.protobuf import text_format\n",
    "from tensorflow.core.framework import graph_pb2\n",
    "\n",
    "def convert_graph_to_dot(input_graph, output_dot, is_input_graph_binary):\n",
    "    graph = graph_pb2.GraphDef()\n",
    "    with open(input_graph, \"rb\") as fh:\n",
    "        if is_input_graph_binary:\n",
    "            graph.ParseFromString(fh.read())\n",
    "        else:\n",
    "            text_format.Merge(fh.read(), graph)\n",
    "    with open(output_dot, \"wt\") as fh:\n",
    "        print(\"digraph graphname {\", file=fh)\n",
    "        for node in graph.node:\n",
    "            output_name = node.name\n",
    "            print(\"  \\\"\" + output_name + \"\\\" [label=\\\"\" + node.op + \"\\\"];\", file=fh)\n",
    "            for input_full_name in node.input:\n",
    "                parts = input_full_name.split(\":\")\n",
    "                input_name = re.sub(r\"^\\^\", \"\", parts[0])\n",
    "                print(\"  \\\"\" + input_name + \"\\\" -> \\\"\" + output_name + \"\\\";\", file=fh)\n",
    "        print(\"}\", file=fh)\n",
    "        print(\"Created dot file '%s' for graph '%s'.\" % (output_dot, input_graph))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_graph='/root/models/optimize_me/linear/cpu/unoptimized_model_cpu.pb'\n",
    "output_dot='/root/notebooks/unoptimized_cpu.dot'\n",
    "convert_graph_to_dot(input_graph=input_graph, output_dot=output_dot, is_input_graph_binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dot -T png /root/notebooks/unoptimized_cpu.dot \\\n",
    "    -o /root/notebooks/unoptimized_cpu.png > /tmp/a.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('/root/notebooks/unoptimized_cpu.png', width=1024, height=768)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "benchmark_model --graph=/root/models/optimize_me/linear/cpu/unoptimized_model_cpu.pb \\\n",
    "    --input_layer=weights,bias,x_observed \\\n",
    "    --input_layer_type=float,float,float \\\n",
    "    --input_layer_shape=:: \\\n",
    "    --output_layer=add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strip Unused Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "transform_graph \\\n",
    "    --in_graph=/root/models/optimize_me/linear/cpu/unoptimized_model_cpu.pb \\\n",
    "    --out_graph=/root/models/optimize_me/linear/cpu/strip_unused_optimized_cpu.pb \\\n",
    "    --inputs='x_observed,weights,bias' \\\n",
    "    --outputs='add' \\\n",
    "    --transforms='\n",
    "strip_unused_nodes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/optimize_me/linear/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "summarize_graph --in_graph=/root/models/optimize_me/linear/cpu/strip_unused_optimized_cpu.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_graph='/root/models/optimize_me/linear/cpu/strip_unused_optimized_cpu.pb'\n",
    "output_dot='/root/notebooks/strip_unused_optimized_cpu.dot'\n",
    "convert_graph_to_dot(input_graph=input_graph, output_dot=output_dot, is_input_graph_binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dot -T png /root/notebooks/strip_unused_optimized_cpu.dot \\\n",
    "    -o /root/notebooks/strip_unused_optimized_cpu.png > /tmp/a.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('/root/notebooks/strip_unused_optimized_cpu.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "benchmark_model --graph=/root/models/optimize_me/linear/cpu/strip_unused_optimized_cpu.pb \\\n",
    "    --input_layer=weights,bias,x_observed \\\n",
    "    --input_layer_type=float,float,float \\\n",
    "    --input_layer_shape=:: \\\n",
    "    --output_layer=add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Nodes\n",
    "Remove pesky `Identity` and `CheckNumerics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "transform_graph \\\n",
    "    --in_graph=/root/models/optimize_me/linear/cpu/strip_unused_optimized_cpu.pb \\\n",
    "    --out_graph=/root/models/optimize_me/linear/cpu/remove_nodes_optimized_cpu.pb \\\n",
    "    --inputs='x_observed,weights,bias' \\\n",
    "    --outputs='add' \\\n",
    "    --transforms='\n",
    "strip_unused_nodes\n",
    "remove_nodes(op=Identity, op=CheckNumerics)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/optimize_me/linear/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "summarize_graph --in_graph=/root/models/optimize_me/linear/cpu/remove_nodes_optimized_cpu.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_graph='/root/models/optimize_me/linear/cpu/remove_nodes_optimized_cpu.pb'\n",
    "output_dot='/root/notebooks/remove_nodes_optimized_cpu.dot'\n",
    "convert_graph_to_dot(input_graph=input_graph, output_dot=output_dot, is_input_graph_binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dot -T png /root/notebooks/remove_nodes_optimized_cpu.dot \\\n",
    "    -o /root/notebooks/remove_nodes_optimized_cpu.png > /tmp/a.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('/root/notebooks/remove_nodes_optimized_cpu.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "benchmark_model --graph=/root/models/optimize_me/linear/cpu/strip_unused_optimized_cpu.pb \\\n",
    "    --input_layer=weights,bias,x_observed \\\n",
    "    --input_layer_type=float,float,float \\\n",
    "    --input_layer_shape=:: \\\n",
    "    --output_layer=add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "transform_graph \\\n",
    "--in_graph=/root/models/optimize_me/linear/cpu/unoptimized_model_cpu.pb \\\n",
    "--out_graph=/root/models/optimize_me/linear/cpu/fold_constants_optimized_cpu.pb \\\n",
    "--inputs='x_observed' \\\n",
    "--outputs='add' \\\n",
    "--transforms='\n",
    "strip_unused_nodes\n",
    "remove_nodes(op=Identity, op=CheckNumerics)\n",
    "fold_constants(ignore_errors=true)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/optimize_me/linear/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "summarize_graph --in_graph=/root/models/optimize_me/linear/cpu/fold_constants_optimized_cpu.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_graph='/root/models/optimize_me/linear/cpu/fold_constants_optimized_cpu.pb'\n",
    "output_dot='/root/notebooks/fold_constants_optimized_cpu.dot'\n",
    "convert_graph_to_dot(input_graph=input_graph, output_dot=output_dot, is_input_graph_binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dot -T png /root/notebooks/fold_constants_optimized_cpu.dot \\\n",
    "    -o /root/notebooks/fold_constants_optimized_cpu.png > /tmp/a.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('/root/notebooks/fold_constants_optimized_cpu.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "benchmark_model --graph=/root/models/optimize_me/linear/cpu/fold_constants_optimized_cpu.pb \\\n",
    "                --input_layer=x_observed,bias,weights \\\n",
    "                --input_layer_type=float,float,float \\\n",
    "                --input_layer_shape=:: \\\n",
    "                --output_layer=add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold Batch Normalizations\n",
    "Prereq: `fold_constants`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "transform_graph \\\n",
    "--in_graph=/root/models/optimize_me/linear/cpu/unoptimized_model_cpu.pb \\\n",
    "--out_graph=/root/models/optimize_me/linear/cpu/fold_batch_norms_optimized_cpu.pb \\\n",
    "--inputs='x_observed' \\\n",
    "--outputs='add' \\\n",
    "--transforms='\n",
    "strip_unused_nodes\n",
    "remove_nodes(op=Identity, op=CheckNumerics)\n",
    "fold_constants(ignore_errors=true)\n",
    "fold_batch_norms\n",
    "fold_old_batch_norms'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/optimize_me/linear/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "summarize_graph --in_graph=/root/models/optimize_me/linear/cpu/fold_batch_norms_optimized_cpu.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_graph='/root/models/optimize_me/linear/cpu/fold_batch_norms_optimized_cpu.pb'\n",
    "output_dot='/root/notebooks/fold_batch_norms_optimized_cpu.dot'\n",
    "convert_graph_to_dot(input_graph=input_graph, output_dot=output_dot, is_input_graph_binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dot -T png /root/notebooks/fold_batch_norms_optimized_cpu.dot \\\n",
    "    -o /root/notebooks/fold_batch_norms_optimized_cpu.png > /tmp/a.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('/root/notebooks/fold_batch_norms_optimized_cpu.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "benchmark_model --graph=/root/models/optimize_me/linear/cpu/fold_batch_norms_optimized_cpu.pb \\\n",
    "                --input_layer=x_observed,bias,weights \\\n",
    "                --input_layer_type=float,float,float \\\n",
    "                --input_layer_shape=:: \\\n",
    "                --output_layer=add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize Weights\n",
    "Prereq: `fold_batch_norms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "transform_graph \\\n",
    "--in_graph=/root/models/optimize_me/linear/cpu/unoptimized_model_cpu.pb \\\n",
    "--out_graph=/root/models/optimize_me/linear/cpu/quantize_weights_optimized_cpu.pb \\\n",
    "--inputs='x_observed' \\\n",
    "--outputs='add' \\\n",
    "--transforms='\n",
    "strip_unused_nodes\n",
    "remove_nodes(op=Identity, op=CheckNumerics)\n",
    "fold_constants(ignore_errors=true)\n",
    "fold_batch_norms\n",
    "fold_old_batch_norms\n",
    "quantize_weights'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/optimize_me/linear/cpu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "summarize_graph --in_graph=/root/models/optimize_me/linear/cpu/quantize_weights_optimized_cpu.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_graph='/root/models/optimize_me/linear/cpu/quantize_weights_optimized_cpu.pb'\n",
    "output_dot='/root/notebooks/quantize_weights_optimized_cpu.dot'\n",
    "convert_graph_to_dot(input_graph=input_graph, output_dot=output_dot, is_input_graph_binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dot -T png /root/notebooks/quantize_weights_optimized_cpu.dot \\\n",
    "    -o /root/notebooks/quantize_weights_optimized_cpu.png > /tmp/a.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('/root/notebooks/quantize_weights_optimized_cpu.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "benchmark_model --graph=/root/models/optimize_me/linear/cpu/quantize_weights_optimized_cpu.pb --input_layer=x_observed,bias,weights --input_layer_type=float,float,float --input_layer_shape=:: --output_layer=add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize Activations\n",
    "Prereq: quantize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "transform_graph \\\n",
    "--in_graph=/root/models/optimize_me/linear/cpu/fold_batch_norms_optimized_cpu.pb \\\n",
    "--out_graph=/root/models/optimize_me/linear/cpu/quantize_nodes_optimized_cpu.pb \\\n",
    "--inputs='x_observed' \\\n",
    "--outputs='add' \\\n",
    "--transforms='\n",
    "strip_unused_nodes\n",
    "remove_nodes(op=Identity, op=CheckNumerics)\n",
    "fold_constants(ignore_errors=true)\n",
    "fold_batch_norms\n",
    "fold_old_batch_norms\n",
    "quantize_weights\n",
    "quantize_nodes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/optimize_me/linear/cpu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "summarize_graph --in_graph=/root/models/optimize_me/linear/cpu/quantize_nodes_optimized_cpu.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_graph='/root/models/optimize_me/linear/cpu/quantize_nodes_optimized_cpu.pb'\n",
    "output_dot='/root/notebooks/quantize_nodes_optimized_cpu.dot'\n",
    "convert_graph_to_dot(input_graph=input_graph, output_dot=output_dot, is_input_graph_binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dot -T png /root/notebooks/quantize_nodes_optimized_cpu.dot \\\n",
    "    -o /root/notebooks/quantize_nodes_optimized_cpu.png > /tmp/a.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('/root/notebooks/quantize_nodes_optimized_cpu.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "benchmark_model --graph=/root/models/optimize_me/linear/cpu/quantize_nodes_optimized_cpu.pb \\\n",
    "                --input_layer=x_observed,bias,weights \\\n",
    "                --input_layer_type=float,float,float \\\n",
    "                --input_layer_shape=:: \\\n",
    "                --output_layer=add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort by Execution Order\n",
    "* aka. Topological Order Sort\n",
    "* Minimize inference overhead \n",
    "* Inputs for a each node are guaranteed to be available on the forward path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "transform_graph \\\n",
    "--in_graph=/root/models/optimize_me/linear/cpu/unoptimized_model_cpu.pb \\\n",
    "--out_graph=/root/models/optimize_me/linear/cpu/sort_by_execution_order_optimized_cpu.pb \\\n",
    "--inputs='x_observed' \\\n",
    "--outputs='add' \\\n",
    "--transforms='\n",
    "strip_unused_nodes\n",
    "remove_nodes(op=Identity, op=CheckNumerics)\n",
    "fold_constants(ignore_errors=true)\n",
    "fold_batch_norms\n",
    "fold_old_batch_norms\n",
    "quantize_weights\n",
    "quantize_nodes\n",
    "sort_by_execution_order'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/optimize_me/linear/cpu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "summarize_graph --in_graph=/root/models/optimize_me/linear/cpu/sort_by_execution_order_optimized_cpu.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_graph='/root/models/optimize_me/linear/cpu/sort_by_execution_order_optimized_cpu.pb'\n",
    "output_dot='/root/notebooks/sort_by_execution_order_optimized_cpu.dot'\n",
    "convert_graph_to_dot(input_graph=input_graph, output_dot=output_dot, is_input_graph_binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dot -T png /root/notebooks/sort_by_execution_order_optimized_cpu.dot \\\n",
    "    -o /root/notebooks/sort_by_execution_order_optimized_cpu.png > /tmp/a.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('/root/notebooks/sort_by_execution_order_optimized_cpu.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "benchmark_model --graph=/root/models/optimize_me/linear/cpu/sort_by_execution_order_optimized_cpu.pb \\\n",
    "    --input_layer=x_observed,bias,weights \\\n",
    "    --input_layer_type=float,float,float \\\n",
    "    --input_layer_shape=:: \\\n",
    "    --output_layer=add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine All Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "transform_graph \\\n",
    "--in_graph=/root/models/optimize_me/linear/cpu/unoptimized_model_cpu.pb \\\n",
    "--out_graph=/root/models/optimize_me/linear/cpu/fully_optimized_cpu.pb \\\n",
    "--inputs='x_observed' \\\n",
    "--outputs='add' \\\n",
    "--transforms='\n",
    "add_default_attributes\n",
    "remove_nodes(op=Identity, op=CheckNumerics)\n",
    "fold_constants(ignore_errors=true)\n",
    "fold_batch_norms\n",
    "fold_old_batch_norms\n",
    "quantize_weights\n",
    "strip_unused_nodes\n",
    "sort_by_execution_order'\n",
    "#quantize_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/optimize_me/linear/cpu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "summarize_graph --in_graph=/root/models/optimize_me/linear/cpu/fully_optimized_cpu.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_graph='/root/models/optimize_me/linear/cpu/fully_optimized_cpu.pb'\n",
    "output_dot='/root/notebooks/fully_optimized_cpu.dot'\n",
    "convert_graph_to_dot(input_graph=input_graph, output_dot=output_dot, is_input_graph_binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dot -T png /root/notebooks/fully_optimized_cpu.dot \\\n",
    "    -o /root/notebooks/fully_optimized_cpu.png > /tmp/a.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('/root/notebooks/fully_optimized_cpu.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "benchmark_model --graph=/root/models/optimize_me/linear/cpu/fully_optimized_cpu.pb \\\n",
    "    --input_layer=weights,x_observed,bias \\\n",
    "    --input_layer_type=float,float,float \\\n",
    "    --input_layer_shape=:: \\\n",
    "    --output_layer=add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obfuscate Names\n",
    "Shorten and mangle internal graph node names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "transform_graph \\\n",
    "--in_graph=/root/models/optimize_me/linear/cpu/fully_optimized_cpu.pb \\\n",
    "--out_graph=/root/models/optimize_me/linear/cpu/obfuscate_names_optimized_cpu.pb \\\n",
    "--inputs='x_observed' \\\n",
    "--outputs='add' \\\n",
    "--transforms='\n",
    "obfuscate_names'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l /root/models/optimize_me/linear/cpu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "summarize_graph --in_graph=/root/models/optimize_me/linear/cpu/obfuscate_names_optimized_cpu.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze Fully Optimized Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import freeze_graph\n",
    "\n",
    "optimize_me_parent_path = '/root/models/optimize_me/linear/cpu'\n",
    "\n",
    "fully_optimized_model_graph_path = '%s/fully_optimized_cpu.pb' % optimize_me_parent_path\n",
    "fully_optimized_frozen_model_graph_path = '%s/fully_optimized_frozen_cpu.pb' % optimize_me_parent_path\n",
    "\n",
    "model_checkpoint_path = '%s/model.ckpt' % optimize_me_parent_path\n",
    "\n",
    "freeze_graph.freeze_graph(input_graph=fully_optimized_model_graph_path, \n",
    "                          input_saver=\"\",\n",
    "                          input_binary=True, \n",
    "                          input_checkpoint='/root/models/optimize_me/linear/cpu/model.ckpt', \n",
    "                          output_node_names=\"add\",\n",
    "                          restore_op_name=\"save/restore_all\", \n",
    "                          filename_tensor_name=\"save/Const:0\",\n",
    "                          output_graph=fully_optimized_frozen_model_graph_path, \n",
    "                          clear_devices=True, \n",
    "                          initializer_nodes=\"\")\n",
    "print(fully_optimized_frozen_model_graph_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset Default Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "graph = tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "version = int(datetime.now().strftime(\"%s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_optimized_saved_model_path = '/root/models/linear_fully_optimized/cpu/%s' % version\n",
    "\n",
    "print(fully_optimized_saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import builder as saved_model_builder\n",
    "from tensorflow.python.saved_model import signature_constants\n",
    "from tensorflow.python.saved_model import signature_def_utils\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.saved_model import utils\n",
    "\n",
    "print(fully_optimized_frozen_model_graph_path)\n",
    "\n",
    "# Load GraphDef created above\n",
    "with tf.gfile.GFile(fully_optimized_frozen_model_graph_path, 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "\n",
    "# Import GraphDef from above into current graph\n",
    "tf.import_graph_def(\n",
    "    graph_def, \n",
    "    input_map=None, \n",
    "    return_elements=None, \n",
    "    name=\"\", \n",
    "    op_dict=None, \n",
    "    producer_op_list=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()\n",
    "\n",
    "for op in graph.get_operations():\n",
    "    print(op.name)\n",
    "\n",
    "x_observed = graph.get_tensor_by_name('x_observed:0')\n",
    "print(x_observed)\n",
    "\n",
    "y_pred = graph.get_tensor_by_name('add:0')\n",
    "print(y_pred)\n",
    "\n",
    "tensor_info_x_observed = utils.build_tensor_info(x_observed)\n",
    "print(tensor_info_x_observed)\n",
    "\n",
    "tensor_info_y_pred = utils.build_tensor_info(y_pred)\n",
    "print(tensor_info_y_pred)\n",
    "\n",
    "builder = saved_model_builder.SavedModelBuilder(fully_optimized_saved_model_path)\n",
    "\n",
    "prediction_signature = signature_def_utils.build_signature_def(inputs = \n",
    "                {'x_observed': tensor_info_x_observed}, \n",
    "                outputs = {'y_pred': tensor_info_y_pred}, \n",
    "                method_name = signature_constants.PREDICT_METHOD_NAME)\n",
    "\n",
    "builder.add_meta_graph_and_variables(sess, [tag_constants.SERVING],\n",
    "                             signature_def_map={'predict':prediction_signature,                                     \n",
    "                                                signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:prediction_signature}, \n",
    "                              clear_devices=True,\n",
    ")\n",
    "\n",
    "builder.save(as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(fully_optimized_saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
