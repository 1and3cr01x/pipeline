{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model with XLA JIT Enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference to All XLA Operations\n",
    "https://www.tensorflow.org/performance/xla/operation_semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Next Cell to Show XLA JIT Training Code\n",
    "Note the following device assignment:\n",
    "```\n",
    "with tf.device('device:XLA_GPU:0')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import tensorflow as tf\r\n",
      "from tensorflow.python.client import timeline\r\n",
      "import numpy as np\r\n",
      "\r\n",
      "tf.reset_default_graph()\r\n",
      "\r\n",
      "num_samples=100000\r\n",
      "\r\n",
      "x_train = np.random.rand(num_samples).astype(np.float32)\r\n",
      "print(x_train)\r\n",
      "\r\n",
      "noise = np.random.normal(scale=0.01, size=len(x_train))\r\n",
      "\r\n",
      "y_train = x_train * 0.1 + 0.3 + noise\r\n",
      "print(y_train)\r\n",
      "\r\n",
      "x_test = np.random.rand(len(x_train)).astype(np.float32)\r\n",
      "print(x_test)\r\n",
      "\r\n",
      "noise = np.random.normal(scale=0.01, size=len(x_train))\r\n",
      "\r\n",
      "y_test = x_test * 0.1 + 0.3 + noise\r\n",
      "print(y_test)\r\n",
      "\r\n",
      "with tf.device(\"/cpu:0\"):\r\n",
      "  W = tf.get_variable(shape=[], name='weights')\r\n",
      "  print(W)\r\n",
      "\r\n",
      "  b = tf.get_variable(shape=[], name='bias')\r\n",
      "  print(b)\r\n",
      "\r\n",
      "  x_observed = tf.placeholder(shape=[None], dtype=tf.float32, name='x_observed')\r\n",
      "  print(x_observed)\r\n",
      "\r\n",
      "with tf.device(\"/job:localhost/replica:0/task:0/device:XLA_GPU:0\"):\r\n",
      "  y_pred = W * x_observed + b\r\n",
      "  print(y_pred)\r\n",
      "\r\n",
      "with tf.device(\"/job:localhost/replica:0/task:0/device:XLA_GPU:0\"):\r\n",
      "  y_observed = tf.placeholder(shape=[None], dtype=tf.float32, name='y_observed')\r\n",
      "  print(y_observed)\r\n",
      "\r\n",
      "  loss_op = tf.reduce_mean(tf.square(y_pred - y_observed))\r\n",
      "\r\n",
      "  # Create an optimizer.\r\n",
      "  optimizer_op = tf.train.GradientDescentOptimizer(0.025)  \r\n",
      "\r\n",
      "  # Create an operation that minimizes loss.\r\n",
      "  train_op = optimizer_op.minimize(loss_op)  \r\n",
      "\r\n",
      "  # 'loss', 'optimizer' and 'train' are.\r\n",
      "  print(\"loss:\", loss_op)\r\n",
      "  print(\"optimizer:\", optimizer_op)\r\n",
      "  print(\"train:\", train_op)\r\n",
      "\r\n",
      "with tf.device(\"/cpu:0\"):\r\n",
      "  init_op = tf.global_variables_initializer()\r\n",
      "  print(init_op)\r\n",
      "\r\n",
      "config = tf.ConfigProto(\r\n",
      "  log_device_placement=True,\r\n",
      ")\r\n",
      "\r\n",
      "config.gpu_options.allow_growth=True\r\n",
      "config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\r\n",
      "\r\n",
      "print(config)\r\n",
      "\r\n",
      "from datetime import datetime\r\n",
      "version = int(datetime.now().strftime(\"%s\"))\r\n",
      "print(version)\r\n",
      "\r\n",
      "train_summary_writer = tf.summary.FileWriter('/root/tensorboard/linear/xla/%s/train' % version, graph=tf.get_default_graph())\r\n",
      "\r\n",
      "test_summary_writer = tf.summary.FileWriter('/root/tensorboard/linear/xla/%s/test' % version, graph=tf.get_default_graph())\r\n",
      "\r\n",
      "sess = tf.Session(config=config)\r\n",
      "sess.run(init_op)\r\n",
      "\r\n",
      "print(sess.run(W))\r\n",
      "print(sess.run(b))\r\n",
      "\r\n",
      "def test(x, y):\r\n",
      "  return sess.run(loss_op, feed_dict={x_observed: x, y_observed: y})\r\n",
      "\r\n",
      "test(x=x_test, y=y_test)\r\n",
      "\r\n",
      "loss_summary_scalar_op = tf.summary.scalar('loss', loss_op)\r\n",
      "loss_summary_merge_all_op = tf.summary.merge_all()\r\n",
      "\r\n",
      "max_steps = 350 \r\n",
      "\r\n",
      "for step in range(max_steps):\r\n",
      "  # Run the training op; feed the training data into the graph\r\n",
      "  if (step < max_steps):\r\n",
      "    train_summary_log, _ = sess.run([loss_summary_merge_all_op, train_op], feed_dict={x_observed: x_train, y_observed: y_train})\r\n",
      "  else:  \r\n",
      "    train_summary_log, _ = sess.run([loss_summary_merge_all_op, train_op], feed_dict={x_observed: x_train, y_observed: y_train})\r\n",
      "\r\n",
      "# The following take a relatively long time, so do them at periodic intervals\r\n",
      "  if step % 5 == 0:\r\n",
      "    print(step, sess.run([W, b]))\r\n",
      "    train_summary_writer.add_summary(train_summary_log, step)\r\n",
      "    train_summary_writer.flush()\r\n",
      "\r\n",
      "test(x=x_test, y=y_test)\r\n"
     ]
    }
   ],
   "source": [
    "cat /root/src/main/python/xla/train_linear_xla.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Next Cell to Train with XLA Enabled\n",
    "Ignore any errors you see.  This is OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "python /root/src/main/python/xla/train_linear_xla.py &> train_linear_xla.log\n",
      "\n",
      "dot -T png /tmp/hlo_graph_1.*.dot -o /root/notebooks/hlo_graph_1.png &>/dev/null \n",
      "\n",
      "dot -T png /tmp/hlo_graph_10.*.dot -o /root/notebooks/hlo_graph_10.png &>/dev/null \n",
      "\n",
      "dot -T png /tmp/hlo_graph_25.*.dot -o /root/notebooks/hlo_graph_25.png &>/dev/null \n",
      "\n",
      "dot -T png /tmp/hlo_graph_50.*.dot -o /root/notebooks/hlo_graph_50.png &>/dev/null\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "cat /root/scripts/train_xla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/scripts/train_xla: line 3:  9436 Aborted                 (core dumped) python /root/src/main/python/xla/train_linear_xla.py &> train_linear_xla.log\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# IGNORE THE Aborted (cored dumped) Error!!\n",
    "train_xla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Model Graph in Tensorboard\n",
    "\n",
    "http://[ip-address]:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View `hlo_graph_*` Files in Left Navigation\n",
    "* `hlo_graph_*` **(JIT Visualizations)** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
