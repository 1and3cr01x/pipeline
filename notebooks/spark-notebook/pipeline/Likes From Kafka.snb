{
  "metadata" : {
    "name" : "Likes From Kafka",
    "user_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "customLocalRepo" : "/root/.ivy2",
    "customRepos" : null,
    "customDeps" : [ "com.datastax.spark:spark-cassandra-connector_2.10:1.5.0-M3", "org.apache.spark:spark-streaming-kafka_2.10:1.4.1", "org.apache.spark % spark-graphx_2.10 % 1.4.1", "- org.apache.spark % spark-core_2.10 % _", "- org.apache.spark % spark-streaming_2.10 % _", "- org.apache.hadoop % _ % _" ],
    "customImports" : null,
    "customSparkConf" : {
      "spark.cassandra.connection.host" : "127.0.0.1",
      "spark.master" : "spark://127.0.0.1:7077",
      "spark.executor.cores" : "2",
      "spark.executor.memory" : "512m",
      "spark.cores.max" : "2",
      "spark.eventLog.enabled" : "true",
      "spark.eventLog.dir" : "logs/spark"
    }
  },
  "cells" : [ {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "## Imports and Create Context"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val sqlContext = new org.apache.spark.sql.SQLContext(sparkContext)\nimport sqlContext.implicits._\nimport org.apache.spark.sql.functions._",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@383d4fec\nimport sqlContext.implicits._\nimport org.apache.spark.sql.functions._\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 1
    } ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "## Visualizations"
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Reactive list of Likes (20 max)"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val list = ul(20)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "list: notebook.front.DataConnectedWidget[String]{implicit val singleCodec: notebook.Codec[play.api.libs.json.JsValue,String]; def data: Seq[String]; def data_=(x$1: Seq[String]): Unit; lazy val toHtml: scala.xml.Elem; def append(s: String): Unit; def appendAll(s: Seq[String]): Unit} = <anon$1 widget>\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<ul data-bind=\"foreach: value\">\n      <li data-bind=\"text: $data\"></li><script data-this=\"{&quot;valueId&quot;:&quot;anon10dab400837705532c6edd302537572c&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId)\n    },\n    this\n  );\n});\n          /*]]>*/</script></ul>"
      },
      "output_type" : "execute_result",
      "execution_count" : 2
    } ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Reactive bar chart"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "var mymap = scala.collection.mutable.Map[Int, Int]()\nval chart = widgets.BarChart(mymap.toList, fields=Some((\"X\", \"Y\")))",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "mymap: scala.collection.mutable.Map[Int,Int] = Map()\nchart: notebook.front.widgets.BarChart[List[(Int, Int)]] = <BarChart widget>\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon2b1189253390356ce306d538a85b0d30&quot;,&quot;dataInit&quot;:[],&quot;genId&quot;:&quot;1597799019&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/barChart'], \n      function(playground, _magicbarChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magicbarChart,\n    \"o\": {\"x\":\"X\",\"y\":\"Y\",\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    </div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 3
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true
    },
    "cell_type" : "code",
    "source" : "",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true
    },
    "cell_type" : "code",
    "source" : "var data = List((1, 1), (2, 4), (3, 5))\nval id = 1\n//mymap.getOrElseUpdate(99, 0).apply(_ + 1)\nmymap(1) = 10\nmymap += (1 -> (mymap(1) + 10))\nmymap += (10001 -> 0)\nmymap.toList\nchart.addAndApply(mymap.toList)\n\n",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "## Kafka Spark Streaming Like Consumer"
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "## Create Domain Object (Case Class)"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "case class Like(fromUserId: Int, toUserId: Int, batchTime: Long) {\n  def toCSV=s\"$fromUserId,$toUserId,$batchTime\"\n}",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "defined class Like\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 4
    } ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "## Start Spark Streaming and Consume Likes \n"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "import org.apache.spark.streaming.kafka.KafkaUtils\nimport org.apache.spark.streaming.Time\nimport kafka.serializer.StringDecoder\nimport org.apache.spark.streaming.Seconds\nimport org.apache.spark.streaming.StreamingContext\nimport org.apache.spark.sql.SaveMode\n\nval ssc = new StreamingContext(sc, Seconds(2))\nval brokers = \"localhost:9092\"\nval topics = Set(\"likes\")\nval kafkaParams = Map[String, String](\"metadata.broker.list\" -> brokers)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.streaming.kafka.KafkaUtils\nimport org.apache.spark.streaming.Time\nimport kafka.serializer.StringDecoder\nimport org.apache.spark.streaming.Seconds\nimport org.apache.spark.streaming.StreamingContext\nimport org.apache.spark.sql.SaveMode\nssc: org.apache.spark.streaming.StreamingContext = org.apache.spark.streaming.StreamingContext@652dd461\nbrokers: String = localhost:9092\ntopics: scala.collection.immutable.Set[String] = Set(likes)\nkafkaParams: scala.collection.immutable.Map[String,String] = Map(metadata.broker.list -> localhost:9092)\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon30cc115fe74f4f99e9a9d7cabf034bef&quot;,&quot;dataInit&quot;:[{&quot;X&quot;:&quot;metadata.broker.list&quot;,&quot;Y&quot;:&quot;localhost:9092&quot;}],&quot;genId&quot;:&quot;2110359956&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tabs'], \n      function(playground, _magictabs) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictabs,\n    \"o\": {}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n        <ul class=\"nav nav-tabs\" id=\"ul2110359956\"><li>\n              <a href=\"#tab2110359956-0\"><i class=\"fa fa-table\"/></a>\n            </li><li>\n              <a href=\"#tab2110359956-1\"><i class=\"fa fa-pie-chart\"/></a>\n            </li></ul>\n\n        <div class=\"tab-content\" id=\"tab2110359956\"><div class=\"tab-pane\" id=\"tab2110359956-0\">\n            <div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon9f34ebffe85aeb1084b3a1a429ae5399&quot;,&quot;dataInit&quot;:[{&quot;X&quot;:&quot;metadata.broker.list&quot;,&quot;Y&quot;:&quot;localhost:9092&quot;}],&quot;genId&quot;:&quot;1211868745&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tableChart'], \n      function(playground, _magictableChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictableChart,\n    \"o\": {\"headers\":[\"X\",\"Y\"],\"nrow\":1,\"shown\":1,\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    </div>\n            </div><div class=\"tab-pane\" id=\"tab2110359956-1\">\n            <div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anone040a68b33df46310a1a2431ea4470d9&quot;,&quot;dataInit&quot;:[{&quot;X&quot;:&quot;metadata.broker.list&quot;,&quot;Y&quot;:&quot;localhost:9092&quot;}],&quot;genId&quot;:&quot;2034731110&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/pieChart'], \n      function(playground, _magicpieChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magicpieChart,\n    \"o\": {\"series\":\"X\",\"p\":\"Y\",\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    </div>\n            </div></div>\n      </div></div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 5
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "// Create Direct Kafka Stream and Listen on `Likes` Topic\nval likesStream = KafkaUtils.createDirectStream[String, String, StringDecoder, StringDecoder](\n  ssc, kafkaParams, topics)\n\nvar likesMap = scala.collection.mutable.Map[Int, Int]()\n\n// Transform the Raw Likes CSV Data into Like\nval messages = likesStream.transform{ \n  (message: RDD[(String, String)], batchTime: Time) => {\n\n    // convert each RDD from the batch into a DataFrame\n    // along the way, update the chart\n    val df = message.map(_._2.split(\",\"))\n      .map{ like =>         \n        //likesMap += (like(1).trim.toInt -> (likesMap(like(1).trim.toInt) + 1))\n              \n        Like(like(0).trim.toInt, like(1).trim.toInt, batchTime.milliseconds)\n      }.toDF(\"fromuserid\", \"touserid\", \"batchtime\")\n\n    \n    // save the DataFrame to Cassandra\n    df.write.format(\"org.apache.spark.sql.cassandra\")\n          .mode(SaveMode.Append)\n          .options(Map(\"keyspace\" -> \"pipeline\", \"table\" -> \"likes\"))\n          .save()\n    \n    df.rdd\n  }\n}\n\n//messages.foreachRDD(rdd => list.appendAll(rdd.take(10).toList.map(_.toString)))\n\n//chart.addAndApply(likesMap.toList)\n\nmessages.foreachRDD{rdd => list.append(\"\"+rdd.count)}\n\n\n//val data = new collection.mutable.ArrayBuffer[(Int, Int)]()\nmessages.foreachRDD{rdd =>\n  mymap ++= Map((1, scala.util.Random.nextInt(10)), (scala.util.Random.nextInt(10), 3))\n  //val ndata = Seq(rdd.map(row => (row(1).asInstanceOf[Int], 10)))\n  chart.addAndApply(mymap.toList)\n}\n",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "warning: there were 1 feature warning(s); re-run with -feature for details\nlikesStream: org.apache.spark.streaming.dstream.InputDStream[(String, String)] = org.apache.spark.streaming.kafka.DirectKafkaInputDStream@140e572c\nlikesMap: scala.collection.mutable.Map[Int,Int] = Map()\nmessages: org.apache.spark.streaming.dstream.DStream[org.apache.spark.sql.Row] = org.apache.spark.streaming.dstream.TransformedDStream@397d13fd\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 6
    } ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "## Start Spark Streaming"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "ssc.start()",
    "outputs" : [ {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 7
    } ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "## Stop Spark Streaming"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true
    },
    "cell_type" : "code",
    "source" : "ssc.stop(false) // commented in case of a Run All ^^",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true
    },
    "cell_type" : "code",
    "source" : "",
    "outputs" : [ ]
  } ],
  "nbformat" : 4
}