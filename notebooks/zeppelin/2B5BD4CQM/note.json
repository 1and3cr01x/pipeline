{
  "paragraphs": [
    {
      "text": "// Databricks notebook source exported at Tue, 27 Oct 2015 09:41:12 UTC\n// MAGIC %md\n// MAGIC # Regression\n// MAGIC  \n// MAGIC This lab covers building regression models using linear regression and decision trees.  Also covered, are regression metrics, bootstrapping, and some traditional model evaluation methods.\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC #### Read in and prepare the data\n// MAGIC  \n// MAGIC First, we\u0027ll load the data from our parquet file.\n\n// COMMAND ----------\n\nval baseDir \u003d \"/mnt/ml-amsterdam/\"\nval irisDense \u003d sqlContext.read.parquet(baseDir + \"irisDense.parquet\")\n \ndisplay(irisDense)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC View the dataset.\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Prepare the data so that we have the sepal width as our target and a dense vector containing sepal length as our features.\n\n// COMMAND ----------\n\nimport org.apache.spark.sql.functions.{udf, lit}\nimport org.apache.spark.mllib.linalg.{Vectors, Vector}\n \nval getElement \u003d udf { (v:Vector, i: Int) \u003d\u003e v(i) }\nval getElementAsVector \u003d udf { (v:Vector, i: Int) \u003d\u003e Vectors.dense(Array(v(i))) }\n \nval irisSepal \u003d irisDense.select(getElement($\"features\", lit(1)).as(\"sepalWidth\"),\n                                 getElementAsVector($\"features\", lit(0)).as(\"features\"))\nirisSepal.cache()\n \ndisplay(irisSepal)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC #### Build a linear regression model\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC First, we\u0027ll sample from our dataset to obtain a [bootstrap sample](https://en.wikipedia.org/wiki/Bootstrapping_%28statistics%29) of our data.\n// MAGIC  \n// MAGIC When using a `DataFrame` we can call `.sample` to return a random sample with or without replacement.  `sample` takes in a boolean for whether to sample with replacement and a fraction for what percentage of the dataset to sample.  Note that if replacement is true we can sample more than 100% of the data.  For example, to choose approximately twice as much data as the original dataset we can set fraction equal to 2.0.\n// MAGIC  \n// MAGIC An explanation of `sample` can be found under `DataFrame` in both the [Python](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.sample) and [Scala](http://spark.apache.org/docs/latest/api/scala/#org.apache.spark.sql.DataFrame) APIs.\n\n// COMMAND ----------\n\nval irisSepalSample \u003d irisSepal.sample(true, 1.0, 1)\ndisplay(irisSepalSample)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Next, let\u0027s create our linear regression object.\n\n// COMMAND ----------\n\nimport org.apache.spark.ml.regression.LinearRegression\n \nval lr \u003d new LinearRegression()\n  .setLabelCol(\"sepalWidth\")\n  .setMaxIter(1000)\nprintln(lr.explainParams)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Next, we\u0027ll create a `Pipeline` that only contains one stage for the linear regression.\n\n// COMMAND ----------\n\nimport org.apache.spark.ml.Pipeline\n \nval pipeline \u003d new Pipeline().setStages(Array(lr))\n \nval pipelineModel \u003d pipeline.fit(irisSepalSample)\nval sepalPredictions \u003d pipelineModel.transform(irisSepalSample)\n \ndisplay(sepalPredictions)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC What does our resulting model look like?\n\n// COMMAND ----------\n\nimport org.apache.spark.ml.regression.LinearRegressionModel\n \nval lrModel \u003d pipelineModel.stages.last.asInstanceOf[LinearRegressionModel]\nprintln(lrModel.getClass)\n \nprintln(s\"\\n${lrModel.intercept} ${lrModel.weights}\")\n \nprintln(f\"\\nsepalWidth \u003d ${lrModel.intercept}%.3f + (${lrModel.weights(0)}%.3f * sepalLength)\")\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC #### Boostrap sampling 100 models\n// MAGIC  \n// MAGIC In order to reason about how stable or models are and whether or not the coefficients are significantly different from zero, we\u0027ll draw 100 samples with replacement and generate a linear model for each of those samples.\n\n// COMMAND ----------\n\nimport org.apache.spark.sql.DataFrame\n \ndef generateModels(df: DataFrame, pipeline: Pipeline, numModels: Int \u003d 100) \u003d {\n  (0 until numModels).map(i \u003d\u003e {\n    val sample \u003d df.sample(true, 1.0, i)\n    val pipelineModel \u003d pipeline.fit(sample)\n    pipelineModel.stages.last.asInstanceOf[LinearRegressionModel]\n  })\n}\n \nval sepalModels \u003d generateModels(irisSepal, pipeline)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Next, we\u0027ll convert our models to a `DataFrame` so we can analyze the different values we obtained for intercept and weight.\n\n// COMMAND ----------\n\nval sepalModelsTuple \u003d sepalModels.map(m \u003d\u003e (m.intercept, m.weights(0)))\nval sepalModelResults \u003d sqlContext.createDataFrame(sepalModelsTuple)\n  .toDF(\"intercept\", \"weight\")\ndisplay(sepalModelResults)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Then we can use `describe` to see the count, mean, and standard deviation of our intercept and weight.  Based on these results it is pretty clear that there isn\u0027t a significant relationship between sepal length and sepal width.\n\n// COMMAND ----------\n\ndisplay(sepalModelResults.describe())\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC #### Petal width vs petal length\n// MAGIC  \n// MAGIC We saw that there wasn\u0027t a significant relationship between sepal width and sepal length.  Let\u0027s repeat the analysis for the petal attributes.\n\n// COMMAND ----------\n\nval irisPetal \u003d irisDense.select(getElement($\"features\", lit(3)).as(\"petalWidth\"),\n                                 getElementAsVector($\"features\", lit(2)).as(\"features\"))\nirisPetal.cache()\ndisplay(irisPetal)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Create the linear regression estimator and pipeline estimator.\n\n// COMMAND ----------\n\nval lrPetal \u003d new LinearRegression()\n  .setLabelCol(\"petalWidth\")\n \nval petalPipeline \u003d new Pipeline().setStages(Array(lrPetal))\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Generate the models.\n\n// COMMAND ----------\n\nval petalModels \u003d generateModels(irisPetal, petalPipeline)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC We\u0027ll repeat the conversion of the model data to a `DataFrame` and then view the statistics on the `DataFrame`.\n\n// COMMAND ----------\n\nval petalModelsTuple \u003d petalModels.map(m \u003d\u003e (m.intercept, m.weights(0)))\nval petalModelResults \u003d sqlContext.createDataFrame(petalModelsTuple)\n  .toDF(\"intercept\", \"weight\")\ndisplay(petalModelResults)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC From these results, we can clearly see that this weight is significantly different from zero.\n\n// COMMAND ----------\n\ndisplay(petalModelResults.describe())\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC #### View and evaluate predictions\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC To start, we\u0027ll generate the predictions by using the first model in `petalModels`.\n\n// COMMAND ----------\n\nval petalPredictions \u003d petalModels(0).transform(irisPetal)\ndisplay(petalPredictions)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Next, we\u0027ll evaluate the model using the `RegressionEvaluator`.\n\n// COMMAND ----------\n\nimport org.apache.spark.ml.evaluation.RegressionEvaluator\nval regEval \u003d new RegressionEvaluator().setLabelCol(\"petalWidth\")\n \nprintln(regEval.explainParams)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC The default value for `RegressionEvaluator` is root mean square error (RMSE).  Let\u0027s view that first.\n\n// COMMAND ----------\n\nprintln(regEval.evaluate(petalPredictions))\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC `RegressionEvaluator` also supports mean square error (MSE), \\\\( r^2 \\\\), and mean absolute error (MAE).  We\u0027ll view the \\\\( r^2 \\\\) metric next.\n\n// COMMAND ----------\n\nimport org.apache.spark.ml.param.ParamMap\n \nprintln(regEval.evaluate(petalPredictions, ParamMap(regEval.metricName -\u003e \"r2\")))\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Let\u0027s evaluate our model on the sepal data as well.\n\n// COMMAND ----------\n\nval sepalPredictions \u003d sepalModels(0).transform(irisSepal)\nprintln(regEval.evaluate(sepalPredictions,\n                         ParamMap(regEval.metricName -\u003e \"r2\", regEval.labelCol -\u003e \"sepalWidth\")))\nprintln(regEval.evaluate(sepalPredictions,\n                         ParamMap(regEval.metricName -\u003e \"rmse\", regEval.labelCol -\u003e \"sepalWidth\")))\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC #### Regression with decision trees\n\n// COMMAND ----------\n\nimport org.apache.spark.ml.regression.DecisionTreeRegressor\n \nval dtr \u003d new DecisionTreeRegressor().setLabelCol(\"petalWidth\")\nprintln(dtr.explainParams)\n\n// COMMAND ----------\n\nval dtrModel \u003d dtr.fit(irisPetal)\nval dtrPredictions \u003d dtrModel.transform(irisPetal)\nprintln(regEval.evaluate(dtrPredictions, ParamMap(regEval.metricName -\u003e \"r2\")))\nprintln(regEval.evaluate(dtrPredictions, ParamMap(regEval.metricName -\u003e \"rmse\")))\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Let\u0027s also build a gradient boosted tree.\n\n// COMMAND ----------\n\nimport org.apache.spark.ml.regression.GBTRegressor\nval gbt \u003d new GBTRegressor().setLabelCol(\"petalWidth\")\nprintln(gbt.explainParams)\n\n// COMMAND ----------\n\nval gbtModel \u003d gbt.fit(irisPetal)\nval gbtPredictions \u003d gbtModel.transform(irisPetal)\nprintln(regEval.evaluate(gbtPredictions, ParamMap(regEval.metricName -\u003e \"r2\")))\nprintln(regEval.evaluate(gbtPredictions, ParamMap(regEval.metricName -\u003e \"rmse\")))\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC We should really test our gradient boosted tree out-of-sample as it is easy to overfit with a GBT model.\n",
      "dateUpdated": "Oct 27, 2015 10:57:56 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445943071139_1484519769",
      "id": "20151027-105111_1876766765",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "baseDir: String \u003d /mnt/ml-amsterdam/\njava.lang.AssertionError: assertion failed: No predefined schema found, and no Parquet data files or summary files found under file:/mnt/ml-amsterdam/irisDense.parquet.\n\tat scala.Predef$.assert(Predef.scala:179)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation$MetadataCache.org$apache$spark$sql$execution$datasources$parquet$ParquetRelation$MetadataCache$$readSchema(ParquetRelation.scala:478)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation$MetadataCache$$anonfun$13.apply(ParquetRelation.scala:404)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation$MetadataCache$$anonfun$13.apply(ParquetRelation.scala:404)\n\tat scala.Option.orElse(Option.scala:257)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation$MetadataCache.refresh(ParquetRelation.scala:404)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation.org$apache$spark$sql$execution$datasources$parquet$ParquetRelation$$metadataCache$lzycompute(ParquetRelation.scala:145)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation.org$apache$spark$sql$execution$datasources$parquet$ParquetRelation$$metadataCache(ParquetRelation.scala:143)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation$$anonfun$6.apply(ParquetRelation.scala:196)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation$$anonfun$6.apply(ParquetRelation.scala:196)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation.dataSchema(ParquetRelation.scala:196)\n\tat org.apache.spark.sql.sources.HadoopFsRelation.schema$lzycompute(interfaces.scala:561)\n\tat org.apache.spark.sql.sources.HadoopFsRelation.schema(interfaces.scala:560)\n\tat org.apache.spark.sql.execution.datasources.LogicalRelation.\u003cinit\u003e(LogicalRelation.scala:31)\n\tat org.apache.spark.sql.SQLContext.baseRelationToDataFrame(SQLContext.scala:395)\n\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:267)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:102)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:107)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:109)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:111)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:113)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:115)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:117)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:119)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:121)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:123)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:125)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:127)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:129)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:131)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:133)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:135)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:137)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:139)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:141)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:143)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:145)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:147)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:149)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:151)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:153)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:155)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:157)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:159)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:161)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:163)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:165)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:167)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:169)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:171)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:173)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:175)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:177)\n\tat $iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:179)\n\tat $iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:181)\n\tat $iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:183)\n\tat $iwC.\u003cinit\u003e(\u003cconsole\u003e:185)\n\tat \u003cinit\u003e(\u003cconsole\u003e:187)\n\tat .\u003cinit\u003e(\u003cconsole\u003e:191)\n\tat .\u003cclinit\u003e(\u003cconsole\u003e)\n\tat .\u003cinit\u003e(\u003cconsole\u003e:7)\n\tat .\u003cclinit\u003e(\u003cconsole\u003e)\n\tat $print(\u003cconsole\u003e)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1340)\n\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpretInput(SparkInterpreter.java:655)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpret(SparkInterpreter.java:620)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpret(SparkInterpreter.java:613)\n\tat org.apache.zeppelin.interpreter.ClassloaderInterpreter.interpret(ClassloaderInterpreter.java:57)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:93)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:276)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:170)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:118)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\n"
      },
      "dateCreated": "Oct 27, 2015 10:51:11 AM",
      "dateStarted": "Oct 27, 2015 10:57:56 AM",
      "dateFinished": "Oct 27, 2015 10:57:57 AM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445943476808_-1927806715",
      "id": "20151027-105756_1961290620",
      "dateCreated": "Oct 27, 2015 10:57:56 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "MLlib/05: Logistic Regression",
  "id": "2B5BD4CQM",
  "angularObjects": {
    "2AR33ZMZJ": [],
    "2AS9P7JSA": [],
    "2ARR8UZDJ": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}