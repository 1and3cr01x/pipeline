{
  "paragraphs": [
    {
      "text": "// Databricks notebook source exported at Tue, 27 Oct 2015 09:46:11 UTC\n// MAGIC %md\n// MAGIC # Wikipedia: Word2Vec\n// MAGIC  \n// MAGIC In this lab, we\u0027ll use `Word2Vec` to create vectors the words found in the Wikipedia dataset.  We\u0027ll use `Word2Vec` by passing in a `DataFrame` containing sentences.  We can pass into `Word2Vec` what length of vector to create, with larger vectors taking more time to build.\n// MAGIC  \n// MAGIC Be able to convert words into vectors provides us with features that can be used in traditional machine learning algorithms.  These vectors can be used to compare word similarity, sentence similarity, or even larger sections of text.\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Load the data.\n\n// COMMAND ----------\n\nval baseDir \u003d \"/mnt/ml-amsterdam/\"\nval dfSmall \u003d sqlContext.read.parquet(baseDir + \"smallwiki.parquet\")\n\n// COMMAND ----------\n\ndfSmall.count\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Filter out unwanted data.\n\n// COMMAND ----------\n\nimport org.apache.spark.sql.{functions \u003d\u003e func}\nimport org.apache.spark.sql.functions.col\n \nval filtered \u003d dfSmall.filter(($\"title\" !\u003d\u003d \"\u003cPARSE ERROR\u003e\") \u0026\u0026\n                              $\"redirect_title\".isNull \u0026\u0026\n                              $\"text\".isNotNull)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Change all text to lower case.\n\n// COMMAND ----------\n\nval lowered \u003d filtered.select($\"*\", func.lower($\"text\").as(\"lowerText\"))\n\n// COMMAND ----------\n\nval parsed \u003d lowered.drop(\"text\").withColumnRenamed(\"lowerText\", \"text\")\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Split the Wikipedia text into sentences.\n\n// COMMAND ----------\n\nval pattern \u003d \"\"\"(\\. |\\n{2,})\"\"\"\n \nval matches \u003d pattern.r.findAllIn(\"Wiki page. *More information*\\n\\n And a line\\n that continues.\")\n \nmatches.toArray\n\n// COMMAND ----------\n\nimport org.apache.spark.ml.feature.RegexTokenizer\n \nval tokenizer \u003d new RegexTokenizer()\n  .setInputCol(\"text\")\n  .setOutputCol(\"sentences\")\n  .setPattern(pattern)\n \nval sentences \u003d tokenizer.transform(parsed).select(\"sentences\")\ndisplay(sentences)\n\n// COMMAND ----------\n\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.types.{StructType, StructField, StringType}\nimport scala.collection.mutable.WrappedArray\n \nval sentenceRDD \u003d sentences\n  .flatMap(x \u003d\u003e x.getAs[WrappedArray[String]](0))\n  .map(Row(_))\n \nval sentenceSchema \u003d StructType(Array(StructField(\"sentence\", StringType)))\nval sentence \u003d sqlContext.createDataFrame(sentenceRDD, sentenceSchema)\n \ndisplay(sentence)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Split the sentences into words.\n\n// COMMAND ----------\n\nval tokenizerWord \u003d new RegexTokenizer()\n  .setInputCol(\"sentence\")\n  .setOutputCol(\"words\")\n  .setPattern(\"\"\"\\W+\"\"\")\n \nval words \u003d tokenizerWord.transform(sentence).select(\"words\")\ndisplay(words)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Use our `removeWords` function that we registered in wiki-eda to clean up stop words.\n\n// COMMAND ----------\n\nsqlContext.sql(\"drop table if exists words\")\nwords.registerTempTable(\"words\")\n\n// COMMAND ----------\n\nval noStopWords \u003d sqlContext.sql(\"select removeWords(words) as words from words\")\ndisplay(noStopWords)\n\n// COMMAND ----------\n\nval wordVecInput \u003d noStopWords.filter(func.size($\"words\") !\u003d\u003d 0)\nwordVecInput.count\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Build the `Word2Vec` model.  This take about a minute with two workers.\n\n// COMMAND ----------\n\nimport org.apache.spark.ml.feature.Word2Vec\nval word2Vec \u003d new Word2Vec()\n  .setVectorSize(150)\n  .setMinCount(50)\n  .setInputCol(\"words\")\n  .setOutputCol(\"result\")\n  .setSeed(0)\nval model \u003d word2Vec.fit(wordVecInput)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Let\u0027s see the model in action.\n\n// COMMAND ----------\n\nmodel\n  .findSynonyms(\"house\", 10)\n  .collect()\n  .foreach(println)\n\n// COMMAND ----------\n\nval synonyms \u003d model.findSynonyms(\"fruit\", 10).collect()\nsynonyms.foreach(println)\n\n// COMMAND ----------\n\nmodel\n  .findSynonyms(\"soccer\", 10)\n  .collect()\n  .foreach(println)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC How can we calculate similarity between vectors and handle creating a vector for multiple words at once?\n\n// COMMAND ----------\n\nval tmpDF \u003d sqlContext.createDataFrame(Seq(Tuple1[Array[String]](Array(\"fruit\")),\n                                           Tuple1[Array[String]](Array(\"flower\")),\n                                           Tuple1[Array[String]](Array(\"fruit\", \"flower\")))).toDF(\"words\")\ndisplay(tmpDF)\n\n// COMMAND ----------\n\nimport org.apache.spark.mllib.linalg.DenseVector\nval vFruit \u003d model.transform(tmpDF).map(r \u003d\u003e r.getAs[DenseVector](r.size - 1)).collect()\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Let\u0027s create a cosine similarity measure.\n\n// COMMAND ----------\n\nimport com.github.fommil.netlib.F2jBLAS\nval f2j \u003d new F2jBLAS\n \ndef dot(x: DenseVector, y: DenseVector) \u003d f2j.ddot(x.size, x.values, 1, y.values, 1)\ndef norm(x: DenseVector) \u003d f2j.dnrm2(x.size, x.values, 1)\ndef similarity(x: DenseVector, y: DenseVector) \u003d dot(x, y) / (norm(x) * norm(y))\n \nval v0 \u003d vFruit(0)\nval v1 \u003d vFruit(1)\nval v2 \u003d vFruit(2)\n \nprintln(similarity(v0, v1))\nprintln(similarity(v1, v2))\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC `Word2Vec` handles multiple words by averaging the vectors.\n\n// COMMAND ----------\n\nimport runtime.ScalaRunTime.stringOf\nprintln(stringOf(v0.toArray.slice(0,6)))\nprintln(stringOf(v1.toArray.slice(0,6)))\nval v0v1 \u003d v0.toArray.zip(v1.toArray).map(x \u003d\u003e (x._1 + x._2) / 2.0)\nprintln(stringOf(v0v1.slice(0,6))) // Averaging the word vectors gives us the vector for both words in a sentence\nprintln(stringOf(v2.toArray.slice(0,6)))\nprintln(\"\\n\\n\")\n\n// COMMAND ----------\n\ndef T1 \u003d Tuple1[Array[String]] _\n \nval tmpDF \u003d sqlContext.createDataFrame(Seq(T1(Array(\"king\")),\n                                           T1(Array(\"man\")),\n                                           T1(Array(\"woman\")),\n                                           T1(Array(\"queen\")))).toDF(\"words\")\nval v1 \u003d model.transform(tmpDF).map(r \u003d\u003e r.getAs[DenseVector](r.size - 1)).collect()\ndisplay(tmpDF)\n\n// COMMAND ----------\n\nimport org.apache.spark.mllib.linalg.Vectors\nval Array(k, m, w, q) \u003d v1\nval kmw \u003d Vectors.dense(k.toArray.zip(m.toArray).map(x \u003d\u003e x._1 - x._2).zip(w.toArray).map(x \u003d\u003e x._1 + x._2))\n  .asInstanceOf[DenseVector]\n \nprintln(similarity(k, q))\nprintln(similarity(k, m))\nprintln(similarity(q, m))\nprintln(similarity(q, w))\nprintln(similarity(q, kmw))\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Load a model trained on more data and view the differences.\n\n// COMMAND ----------\n\nimport org.apache.spark.mllib.feature.Word2VecModel\nval modelOne \u003d Word2VecModel.load(sc, \"/mnt/ml-amsterdam/one.w2v\")\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC How do our two models compare?\n\n// COMMAND ----------\n\ndef compareModels(word:String) \u003d {\n  val mOne \u003d modelOne.findSynonyms(word, 10)\n  val m \u003d model.findSynonyms(word, 10).map(r \u003d\u003e (r.getAs[String](0), r.getAs[Double](1))).collect()\n  mOne.zip(m).foreach(println)\n}\n \ncompareModels(\"soccer\")\n\n// COMMAND ----------\n\ncompareModels(\"fruit\")\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Any guesses on what the top results will be?\n\n// COMMAND ----------\n\ncompareModels(\"apple\")\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC How would find similarities for two words at once?\n\n// COMMAND ----------\n\ndef vAvg(v1: Array[Float], v2: Array[Float]) \u003d\n  v1.zip(v2).map(x \u003d\u003e (x._1 + x._2) / 2.0)\ndef vAdd(v1: Array[Double], v2: Array[Double]) \u003d\n  v1.zip(v2).map(x \u003d\u003e (x._1 + x._2))\ndef vSub(v1: Array[Double], v2: Array[Double]) \u003d\n  v1.zip(v2).map(x \u003d\u003e (x._1 - x._2))\n \nval Array(chinese, river) \u003d Array(\"chinese\", \"river\").map(modelOne.getVectors)\n \nmodelOne.findSynonyms(Vectors.dense(vAvg(chinese, river)), 5).foreach(println)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Note that neither \"chinese\" or \"river\" captures \"Yangtze\" in the first five.\n\n// COMMAND ----------\n\nmodelOne\n  .findSynonyms(\"chinese\", 5)\n  .zip(modelOne.findSynonyms(\"river\", 5))\n  .foreach(println)\n\n// COMMAND ----------\n\n// MAGIC %md\n// MAGIC Let\u0027s try our vector math again.\n\n// COMMAND ----------\n\nimport org.apache.spark.mllib.linalg.{Vectors, DenseVector}\n \nval kmwq \u003d Array(\"king\", \"man\", \"woman\", \"queen\")\n  .map(x \u003d\u003e modelOne.getVectors(x).map(_.toDouble))\n  .map(x \u003d\u003e Vectors.dense(x).asInstanceOf[DenseVector])\n \nval Array(k, m, w, q) \u003d kmwq\nval kmw \u003d Vectors.dense(k.toArray.zip(m.toArray).map(x \u003d\u003e x._1 - x._2).zip(q.toArray).map(x \u003d\u003e x._1 + x._2))\n  .asInstanceOf[DenseVector]\n \nprintln(similarity(k, q))\nprintln(similarity(k, m))\nprintln(similarity(q, m))\nprintln(similarity(q, w))\nprintln(similarity(q, kmw))\n",
      "dateUpdated": "Oct 27, 2015 11:03:04 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445943764744_-844724881",
      "id": "20151027-110244_103236397",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "baseDir: String \u003d /mnt/ml-amsterdam/\njava.lang.AssertionError: assertion failed: No predefined schema found, and no Parquet data files or summary files found under file:/mnt/ml-amsterdam/smallwiki.parquet.\n\tat scala.Predef$.assert(Predef.scala:179)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation$MetadataCache.org$apache$spark$sql$execution$datasources$parquet$ParquetRelation$MetadataCache$$readSchema(ParquetRelation.scala:478)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation$MetadataCache$$anonfun$13.apply(ParquetRelation.scala:404)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation$MetadataCache$$anonfun$13.apply(ParquetRelation.scala:404)\n\tat scala.Option.orElse(Option.scala:257)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation$MetadataCache.refresh(ParquetRelation.scala:404)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation.org$apache$spark$sql$execution$datasources$parquet$ParquetRelation$$metadataCache$lzycompute(ParquetRelation.scala:145)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation.org$apache$spark$sql$execution$datasources$parquet$ParquetRelation$$metadataCache(ParquetRelation.scala:143)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation$$anonfun$6.apply(ParquetRelation.scala:196)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation$$anonfun$6.apply(ParquetRelation.scala:196)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetRelation.dataSchema(ParquetRelation.scala:196)\n\tat org.apache.spark.sql.sources.HadoopFsRelation.schema$lzycompute(interfaces.scala:561)\n\tat org.apache.spark.sql.sources.HadoopFsRelation.schema(interfaces.scala:560)\n\tat org.apache.spark.sql.execution.datasources.LogicalRelation.\u003cinit\u003e(LogicalRelation.scala:31)\n\tat org.apache.spark.sql.SQLContext.baseRelationToDataFrame(SQLContext.scala:395)\n\tat org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:267)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:102)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:107)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:109)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:111)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:113)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:115)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:117)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:119)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:121)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:123)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:125)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:127)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:129)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:131)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:133)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:135)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:137)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:139)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:141)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:143)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:145)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:147)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:149)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:151)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:153)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:155)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:157)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:159)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:161)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:163)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:165)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:167)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:169)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:171)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:173)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:175)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:177)\n\tat $iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:179)\n\tat $iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:181)\n\tat $iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:183)\n\tat $iwC.\u003cinit\u003e(\u003cconsole\u003e:185)\n\tat \u003cinit\u003e(\u003cconsole\u003e:187)\n\tat .\u003cinit\u003e(\u003cconsole\u003e:191)\n\tat .\u003cclinit\u003e(\u003cconsole\u003e)\n\tat .\u003cinit\u003e(\u003cconsole\u003e:7)\n\tat .\u003cclinit\u003e(\u003cconsole\u003e)\n\tat $print(\u003cconsole\u003e)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1340)\n\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpretInput(SparkInterpreter.java:655)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpret(SparkInterpreter.java:620)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpret(SparkInterpreter.java:613)\n\tat org.apache.zeppelin.interpreter.ClassloaderInterpreter.interpret(ClassloaderInterpreter.java:57)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:93)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:276)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:170)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:118)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n\n"
      },
      "dateCreated": "Oct 27, 2015 11:02:44 AM",
      "dateStarted": "Oct 27, 2015 11:03:04 AM",
      "dateFinished": "Oct 27, 2015 11:03:05 AM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445943784591_2054204839",
      "id": "20151027-110304_931195320",
      "dateCreated": "Oct 27, 2015 11:03:04 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Wiki NLP/04: Word2Vec",
  "id": "2B3SX9MJT",
  "angularObjects": {
    "2AR33ZMZJ": [],
    "2AS9P7JSA": [],
    "2ARR8UZDJ": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}