{
  "paragraphs": [
    {
      "text": "%dep\nz.reset()\nz.addRepo(\"maven central\").url(\"search.maven.org\")\nz.load(\"com.datastax.spark:spark-cassandra-connector_2.10:1.4.0\")\nz.load(\"org.elasticsearch:elasticsearch-spark_2.10:2.1.0\")\nz.load(\"com.databricks:spark-csv_2.10:1.2.0\")\nz.load(\"org.apache.spark:spark-streaming-kafka-assembly_2.10:1.5.1\")\nz.load(\"/root/zeppelin-0.6.0-spark-1.5.1-hadoop-2.6.0-fluxcapacitor/lib/mysql-connector-java.jar\")\nz.load(\"/root/pipeline/myapps/datasource/target/scala-2.10/datasource_2.10-1.0.jar\")",
      "dateUpdated": "Oct 30, 2015 9:17:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445081890962_769572236",
      "id": "20151017-113810_697892520",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "res0: org.apache.zeppelin.spark.dep.Dependency \u003d org.apache.zeppelin.spark.dep.Dependency@7539ba59\n"
      },
      "dateCreated": "Oct 17, 2015 11:38:10 AM",
      "dateStarted": "Oct 30, 2015 9:17:44 PM",
      "dateFinished": "Oct 30, 2015 9:17:49 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Populate ActressesAndActorsDF Reference Data",
      "text": "val actressesAndActorsDF \u003d sqlContext.sql(\"SELECT id, name, bio, img FROM actresses_and_actors_perm\")\n\nactressesAndActorsDF.show()",
      "dateUpdated": "Oct 30, 2015 9:17:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445081927425_320383091",
      "id": "20151017-113847_1233175220",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "actressesAndActorsDF: org.apache.spark.sql.DataFrame \u003d [id: bigint, name: string, bio: string, img: string]\n+-----+--------------------+--------------------+--------------------+\n|   id|                name|                 bio|                 img|\n+-----+--------------------+--------------------+--------------------+\n|90001|         Linda Blair|From the age of f...|img/people/90001.jpg|\n|90002|      Shannon Whirry|Shannon Whirry is...|img/people/90002.jpg|\n|90003|      Rosalind Allen|Rosalind Allen (b...|img/people/90003.jpg|\n|90004|     Bobbie Phillips|Brains and beauty...|img/people/90004.jpg|\n|90005|Keshia Knight Pul...|Keshia Knight Pul...|img/people/90005.jpg|\n|90006|         Tatyana Ali|On January 24, 19...|img/people/90006.jpg|\n|90007|      Angell Conwell|Born in the tiny ...|img/people/90007.jpg|\n|90008|  Shannah Laumeister|Shannah Laumeiste...|img/people/90008.jpg|\n|90009|           Pam Grier|Pam Grier was bor...|img/people/90009.jpg|\n|90010|    Tiffani Thiessen|Tiffani-Amber Thi...|img/people/90010.jpg|\n|90011|         Ashley Judd|Ashley Judd was b...|img/people/90011.jpg|\n|90012|         Stacey Dash|Stacey Dash was b...|img/people/90012.jpg|\n|90013|       Sofía Vergara|Sofía Margarita V...|img/people/90013.jpg|\n|90014|        Gail O\u0027Grady|Gail O\u0027Grady was ...|img/people/90014.jpg|\n|90015|       Barbara Niven|Barbara Niven was...|img/people/90015.jpg|\n|10001|   Leonardo DiCaprio|Few actors in the...|img/people/10001.jpg|\n|10002|     Anthony Hopkins|Anthony Hopkins w...|img/people/10002.jpg|\n|10003|           Al Pacino|One of the greate...|img/people/10003.jpg|\n|10004|      Morgan Freeman|With an authorita...|img/people/10004.jpg|\n|10005|    James Gandolfini|James Gandolfini ...|img/people/10005.jpg|\n+-----+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Oct 17, 2015 11:38:47 AM",
      "dateStarted": "Oct 30, 2015 9:17:45 PM",
      "dateFinished": "Oct 30, 2015 9:18:02 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Convert \"bio\" column into Array[String]",
      "text": "import org.apache.spark.ml.feature.Tokenizer\n\nval tokenizerTransformer \u003d new Tokenizer().setInputCol(\"bio\").setOutputCol(\"wordsFeatureVectors\")\n\nval wordsFeatureVectorsDF \u003d tokenizerTransformer.transform(actressesAndActorsDF)\n\nwordsFeatureVectorsDF.select(\"name\", \"bio\", \"wordsFeatureVectors\").show()",
      "dateUpdated": "Oct 30, 2015 9:17:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445102998027_-1055707710",
      "id": "20151017-172958_1780692227",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.ml.feature.Tokenizer\ntokenizerTransformer: org.apache.spark.ml.feature.Tokenizer \u003d tok_69c1e49ddbb5\nwordsFeatureVectorsDF: org.apache.spark.sql.DataFrame \u003d [id: bigint, name: string, bio: string, img: string, wordsFeatureVectors: array\u003cstring\u003e]\n+--------------------+--------------------+--------------------+\n|                name|                 bio| wordsFeatureVectors|\n+--------------------+--------------------+--------------------+\n|         Linda Blair|From the age of f...|[from, the, age, ...|\n|      Shannon Whirry|Shannon Whirry is...|[shannon, whirry,...|\n|      Rosalind Allen|Rosalind Allen (b...|[rosalind, allen,...|\n|     Bobbie Phillips|Brains and beauty...|[brains, and, bea...|\n|Keshia Knight Pul...|Keshia Knight Pul...|[keshia, knight, ...|\n|         Tatyana Ali|On January 24, 19...|[on, january, 24,...|\n|      Angell Conwell|Born in the tiny ...|[born, in, the, t...|\n|  Shannah Laumeister|Shannah Laumeiste...|[shannah, laumeis...|\n|           Pam Grier|Pam Grier was bor...|[pam, grier, was,...|\n|    Tiffani Thiessen|Tiffani-Amber Thi...|[tiffani-amber, t...|\n|         Ashley Judd|Ashley Judd was b...|[ashley, judd, wa...|\n|         Stacey Dash|Stacey Dash was b...|[stacey, dash, wa...|\n|       Sofía Vergara|Sofía Margarita V...|[sofía, margarita...|\n|        Gail O\u0027Grady|Gail O\u0027Grady was ...|[gail, o\u0027grady, w...|\n|       Barbara Niven|Barbara Niven was...|[barbara, niven, ...|\n|   Leonardo DiCaprio|Few actors in the...|[few, actors, in,...|\n|     Anthony Hopkins|Anthony Hopkins w...|[anthony, hopkins...|\n|           Al Pacino|One of the greate...|[one, of, the, gr...|\n|      Morgan Freeman|With an authorita...|[with, an, author...|\n|    James Gandolfini|James Gandolfini ...|[james, gandolfin...|\n+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Oct 17, 2015 5:29:58 PM",
      "dateStarted": "Oct 30, 2015 9:17:50 PM",
      "dateFinished": "Oct 30, 2015 9:18:03 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Filter Out Stop Words",
      "text": "import org.apache.spark.ml.feature.StopWordsRemover\n\nval stopWordRemoverTransformer \u003d new StopWordsRemover().setInputCol(\"wordsFeatureVectors\").setOutputCol(\"filteredWordsFeatureVectors\")\n\nval filteredWordsFeatureVectorsDF \u003d stopWordRemoverTransformer.transform(wordsFeatureVectorsDF)\n\nfilteredWordsFeatureVectorsDF.select(\"name\", \"bio\", \"filteredWordsFeatureVectors\").show()",
      "dateUpdated": "Oct 30, 2015 9:17:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445104905188_1508787084",
      "id": "20151017-180145_1212516680",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.ml.feature.StopWordsRemover\nstopWordRemoverTransformer: org.apache.spark.ml.feature.StopWordsRemover \u003d stopWords_e0b59be3945a\nfilteredWordsFeatureVectorsDF: org.apache.spark.sql.DataFrame \u003d [id: bigint, name: string, bio: string, img: string, wordsFeatureVectors: array\u003cstring\u003e, filteredWordsFeatureVectors: array\u003cstring\u003e]\n+--------------------+--------------------+---------------------------+\n|                name|                 bio|filteredWordsFeatureVectors|\n+--------------------+--------------------+---------------------------+\n|         Linda Blair|From the age of f...|       [age, five,, lind...|\n|      Shannon Whirry|Shannon Whirry is...|       [shannon, whirry,...|\n|      Rosalind Allen|Rosalind Allen (b...|       [rosalind, allen,...|\n|     Bobbie Phillips|Brains and beauty...|       [brains, beauty, ...|\n|Keshia Knight Pul...|Keshia Knight Pul...|       [keshia, knight, ...|\n|         Tatyana Ali|On January 24, 19...|       [january, 24,, 19...|\n|      Angell Conwell|Born in the tiny ...|       [born, tiny, town...|\n|  Shannah Laumeister|Shannah Laumeiste...|       [shannah, laumeis...|\n|           Pam Grier|Pam Grier was bor...|       [pam, grier, born...|\n|    Tiffani Thiessen|Tiffani-Amber Thi...|       [tiffani-amber, t...|\n|         Ashley Judd|Ashley Judd was b...|       [ashley, judd, bo...|\n|         Stacey Dash|Stacey Dash was b...|       [stacey, dash, bo...|\n|       Sofía Vergara|Sofía Margarita V...|       [sofía, margarita...|\n|        Gail O\u0027Grady|Gail O\u0027Grady was ...|       [gail, o\u0027grady, b...|\n|       Barbara Niven|Barbara Niven was...|       [barbara, niven, ...|\n|   Leonardo DiCaprio|Few actors in the...|       [actors, world, c...|\n|     Anthony Hopkins|Anthony Hopkins w...|       [anthony, hopkins...|\n|           Al Pacino|One of the greate...|       [greatest, actors...|\n|      Morgan Freeman|With an authorita...|       [authoritative, v...|\n|    James Gandolfini|James Gandolfini ...|       [james, gandolfin...|\n+--------------------+--------------------+---------------------------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Oct 17, 2015 6:01:45 PM",
      "dateStarted": "Oct 30, 2015 9:18:03 PM",
      "dateFinished": "Oct 30, 2015 9:18:04 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "TF/IDF Featurizer",
      "text": "import org.apache.spark.ml.feature.{HashingTF, IDF, Tokenizer}\n\nval hashingTFTransformer \u003d new HashingTF().setInputCol(\"filteredWordsFeatureVectors\").setOutputCol(\"tfWordsFeatureVectors\").setNumFeatures(1000)\n\nval tfWordsFeatureVectorsDF \u003d hashingTFTransformer.transform(filteredWordsFeatureVectorsDF)\n\nval idfEstimator \u003d new IDF().setInputCol(\"tfWordsFeatureVectors\").setOutputCol(\"tfIdfWordsFeatureVectors\")\n\nval idfModelTransformer \u003d idfEstimator.fit(tfWordsFeatureVectorsDF)\n\nval tfIdfWordsFeatureVectorsDF \u003d idfModelTransformer.transform(tfWordsFeatureVectorsDF)\n\ntfIdfWordsFeatureVectorsDF.select(\"name\", \"bio\", \"tfIdfWordsFeatureVectors\").show()",
      "dateUpdated": "Oct 30, 2015 9:17:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445099320523_1491093045",
      "id": "20151017-162840_1956587375",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.ml.feature.{HashingTF, IDF, Tokenizer}\nhashingTFTransformer: org.apache.spark.ml.feature.HashingTF \u003d hashingTF_1af641794207\ntfWordsFeatureVectorsDF: org.apache.spark.sql.DataFrame \u003d [id: bigint, name: string, bio: string, img: string, wordsFeatureVectors: array\u003cstring\u003e, filteredWordsFeatureVectors: array\u003cstring\u003e, tfWordsFeatureVectors: vector]\nidfEstimator: org.apache.spark.ml.feature.IDF \u003d idf_ca1020a19aed\nidfModelTransformer: org.apache.spark.ml.feature.IDFModel \u003d idf_ca1020a19aed\ntfIdfWordsFeatureVectorsDF: org.apache.spark.sql.DataFrame \u003d [id: bigint, name: string, bio: string, img: string, wordsFeatureVectors: array\u003cstring\u003e, filteredWordsFeatureVectors: array\u003cstring\u003e, tfWordsFeatureVectors: vector, tfIdfWordsFeatureVectors: vector]\n+--------------------+--------------------+------------------------+\n|                name|                 bio|tfIdfWordsFeatureVectors|\n+--------------------+--------------------+------------------------+\n|         Linda Blair|From the age of f...|    (1000,[72,128,153...|\n|      Shannon Whirry|Shannon Whirry is...|    (1000,[43,63,80,9...|\n|      Rosalind Allen|Rosalind Allen (b...|    (1000,[38,45,104,...|\n|     Bobbie Phillips|Brains and beauty...|    (1000,[4,15,53,13...|\n|Keshia Knight Pul...|Keshia Knight Pul...|    (1000,[4,46,54,11...|\n|         Tatyana Ali|On January 24, 19...|    (1000,[57,77,114,...|\n|      Angell Conwell|Born in the tiny ...|    (1000,[6,23,49,53...|\n|  Shannah Laumeister|Shannah Laumeiste...|    (1000,[46,86,115,...|\n|           Pam Grier|Pam Grier was bor...|    (1000,[34,46,125,...|\n|    Tiffani Thiessen|Tiffani-Amber Thi...|    (1000,[7,50,67,11...|\n|         Ashley Judd|Ashley Judd was b...|    (1000,[46,99,117,...|\n|         Stacey Dash|Stacey Dash was b...|    (1000,[44,46,49,5...|\n|       Sofía Vergara|Sofía Margarita V...|    (1000,[74,181,182...|\n|        Gail O\u0027Grady|Gail O\u0027Grady was ...|    (1000,[32,34,53,7...|\n|       Barbara Niven|Barbara Niven was...|    (1000,[4,20,72,99...|\n|   Leonardo DiCaprio|Few actors in the...|    (1000,[6,22,43,18...|\n|     Anthony Hopkins|Anthony Hopkins w...|    (1000,[15,79,100,...|\n|           Al Pacino|One of the greate...|    (1000,[0,3,6,26,3...|\n|      Morgan Freeman|With an authorita...|    (1000,[13,30,32,6...|\n|    James Gandolfini|James Gandolfini ...|    (1000,[17,23,45,4...|\n+--------------------+--------------------+------------------------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Oct 17, 2015 4:28:40 PM",
      "dateStarted": "Oct 30, 2015 9:18:04 PM",
      "dateFinished": "Oct 30, 2015 9:18:06 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "TODO:  You\u0027ll want to normalize otherwise absolute value (magnitude) will affect outcome",
      "text": "",
      "dateUpdated": "Oct 30, 2015 9:17:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445949366628_2065789687",
      "id": "20151027-123606_45737102",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT"
      },
      "dateCreated": "Oct 27, 2015 12:36:06 PM",
      "dateStarted": "Oct 30, 2015 9:18:05 PM",
      "dateFinished": "Oct 30, 2015 9:18:06 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Word2Vec Featurizer",
      "text": "import org.apache.spark.ml.feature.Word2Vec\n\nval word2VecEstimator \u003d new Word2Vec()\n  .setInputCol(\"filteredWordsFeatureVectors\")\n  .setOutputCol(\"word2vecWordsFeatureVectors\")\n  .setMinCount(2)\n\nval word2VecModelTransformer \u003d word2VecEstimator.fit(filteredWordsFeatureVectorsDF)\n\nval word2VecWordFeatureVectorsDF \u003d word2VecModelTransformer.transform(filteredWordsFeatureVectorsDF)\n\nword2VecWordFeatureVectorsDF.select(\"name\", \"bio\", \"word2vecWordsFeatureVectors\").show()",
      "dateUpdated": "Oct 30, 2015 9:17:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445099681901_-853444159",
      "id": "20151017-163441_477395570",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.ml.feature.Word2Vec\nword2VecEstimator: org.apache.spark.ml.feature.Word2Vec \u003d w2v_66b39390cd5e\nword2VecModelTransformer: org.apache.spark.ml.feature.Word2VecModel \u003d w2v_66b39390cd5e\nword2VecWordFeatureVectorsDF: org.apache.spark.sql.DataFrame \u003d [id: bigint, name: string, bio: string, img: string, wordsFeatureVectors: array\u003cstring\u003e, filteredWordsFeatureVectors: array\u003cstring\u003e, word2vecWordsFeatureVectors: vector]\n+--------------------+--------------------+---------------------------+\n|                name|                 bio|word2vecWordsFeatureVectors|\n+--------------------+--------------------+---------------------------+\n|         Linda Blair|From the age of f...|       [-4.6090747566957...|\n|      Shannon Whirry|Shannon Whirry is...|       [-4.6550503586707...|\n|      Rosalind Allen|Rosalind Allen (b...|       [-1.0757597779194...|\n|     Bobbie Phillips|Brains and beauty...|       [-4.5989937994077...|\n|Keshia Knight Pul...|Keshia Knight Pul...|       [5.30538641297343...|\n|         Tatyana Ali|On January 24, 19...|       [-2.6405665812490...|\n|      Angell Conwell|Born in the tiny ...|       [-3.2908980287366...|\n|  Shannah Laumeister|Shannah Laumeiste...|       [-2.0148014882579...|\n|           Pam Grier|Pam Grier was bor...|       [-4.0055314644372...|\n|    Tiffani Thiessen|Tiffani-Amber Thi...|       [-5.2080940539863...|\n|         Ashley Judd|Ashley Judd was b...|       [-2.1748697273088...|\n|         Stacey Dash|Stacey Dash was b...|       [-4.5374684233331...|\n|       Sofía Vergara|Sofía Margarita V...|       [1.72133621727598...|\n|        Gail O\u0027Grady|Gail O\u0027Grady was ...|       [-2.7032762520276...|\n|       Barbara Niven|Barbara Niven was...|       [-6.9077954627573...|\n|   Leonardo DiCaprio|Few actors in the...|       [-2.5081590704050...|\n|     Anthony Hopkins|Anthony Hopkins w...|       [4.56674773689686...|\n|           Al Pacino|One of the greate...|       [8.58004599909431...|\n|      Morgan Freeman|With an authorita...|       [-3.3898770624514...|\n|    James Gandolfini|James Gandolfini ...|       [-2.2593710746150...|\n+--------------------+--------------------+---------------------------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Oct 17, 2015 4:34:41 PM",
      "dateStarted": "Oct 30, 2015 9:18:06 PM",
      "dateFinished": "Oct 30, 2015 9:18:07 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Count Featurizer - Words",
      "text": "import org.apache.spark.ml.feature.{CountVectorizer, CountVectorizerModel}\n\n// fit a CountVectorizerModel from the corpus\nval countWordsVectorizerEstimator \u003d new CountVectorizer()\n  .setInputCol(\"filteredWordsFeatureVectors\")\n  .setOutputCol(\"countWordsFeatureVectors\")\n  .setMinDF(2) // a term must appear in more or equal to 2 documents to be included in the vocabulary\n\nval countWordsVectorizerModelTransformer \u003d countWordsVectorizerEstimator.fit(filteredWordsFeatureVectorsDF)\n\nval countWordsFeatureVectorsDF \u003d countWordsVectorizerModelTransformer.transform(filteredWordsFeatureVectorsDF).select(\"name\", \"bio\", \"filteredWordsFeatureVectors\", \"countWordsFeatureVectors\")\n\ncountWordsFeatureVectorsDF.show()",
      "dateUpdated": "Oct 30, 2015 9:17:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445101913136_1473887137",
      "id": "20151017-171153_871858",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.ml.feature.{CountVectorizer, CountVectorizerModel}\ncountWordsVectorizerEstimator: org.apache.spark.ml.feature.CountVectorizer \u003d cntVec_87f5020341ea\ncountWordsVectorizerModelTransformer: org.apache.spark.ml.feature.CountVectorizerModel \u003d cntVec_87f5020341ea\ncountWordsFeatureVectorsDF: org.apache.spark.sql.DataFrame \u003d [name: string, bio: string, filteredWordsFeatureVectors: array\u003cstring\u003e, countWordsFeatureVectors: vector]\n+--------------------+--------------------+---------------------------+------------------------+\n|                name|                 bio|filteredWordsFeatureVectors|countWordsFeatureVectors|\n+--------------------+--------------------+---------------------------+------------------------+\n|         Linda Blair|From the age of f...|       [age, five,, lind...|    (87,[9,16,53,68,7...|\n|      Shannon Whirry|Shannon Whirry is...|       [shannon, whirry,...|    (87,[0,1,5,6,14,3...|\n|      Rosalind Allen|Rosalind Allen (b...|       [rosalind, allen,...|    (87,[1,15,22,26,4...|\n|     Bobbie Phillips|Brains and beauty...|       [brains, beauty, ...|    (87,[5,14,15,43,4...|\n|Keshia Knight Pul...|Keshia Knight Pul...|       [keshia, knight, ...|    (87,[0,1,2,17,20,...|\n|         Tatyana Ali|On January 24, 19...|       [january, 24,, 19...|    (87,[0,9,34,48,52...|\n|      Angell Conwell|Born in the tiny ...|       [born, tiny, town...|    (87,[0,1,9,13,16,...|\n|  Shannah Laumeister|Shannah Laumeiste...|       [shannah, laumeis...|    (87,[0,2,6,10,19,...|\n|           Pam Grier|Pam Grier was bor...|       [pam, grier, born...|    (87,[0,1,15,35,38...|\n|    Tiffani Thiessen|Tiffani-Amber Thi...|       [tiffani-amber, t...|    (87,[0,10,13,22,3...|\n|         Ashley Judd|Ashley Judd was b...|       [ashley, judd, bo...|    (87,[0,2,6,10,17,...|\n|         Stacey Dash|Stacey Dash was b...|       [stacey, dash, bo...|    (87,[0,1,9,26,29,...|\n|       Sofía Vergara|Sofía Margarita V...|       [sofía, margarita...|    (87,[0,11,23,24],...|\n|        Gail O\u0027Grady|Gail O\u0027Grady was ...|       [gail, o\u0027grady, b...|    (87,[0,2,3,6,8,19...|\n|       Barbara Niven|Barbara Niven was...|       [barbara, niven, ...|    (87,[0,2,6,32,40]...|\n|   Leonardo DiCaprio|Few actors in the...|       [actors, world, c...|    (87,[4,7,15,35,61...|\n|     Anthony Hopkins|Anthony Hopkins w...|       [anthony, hopkins...|    (87,[0,13,37,55,5...|\n|           Al Pacino|One of the greate...|       [greatest, actors...|    (87,[0,1,3,7,12,1...|\n|      Morgan Freeman|With an authorita...|       [authoritative, v...|    (87,[0,3,4,30,51,...|\n|    James Gandolfini|James Gandolfini ...|       [james, gandolfin...|    (87,[0,1,5,13,14,...|\n+--------------------+--------------------+---------------------------+------------------------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Oct 17, 2015 5:11:53 PM",
      "dateStarted": "Oct 30, 2015 9:18:07 PM",
      "dateFinished": "Oct 30, 2015 9:18:08 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "N-Gram Featurizer",
      "text": "import org.apache.spark.ml.feature.NGram\n\nval ngramTransformer \u003d new NGram().setN(2).setInputCol(\"filteredWordsFeatureVectors\").setOutputCol(\"ngramsFeatureVectors\")\n\nval ngramsFeatureVectorsDF \u003d ngramTransformer.transform(filteredWordsFeatureVectorsDF)\n\nngramsFeatureVectorsDF.select(\"name\", \"bio\", \"ngramsFeatureVectors\").show()",
      "dateUpdated": "Oct 30, 2015 9:17:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445102307362_-534718304",
      "id": "20151017-171827_540520315",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.ml.feature.NGram\nngramTransformer: org.apache.spark.ml.feature.NGram \u003d ngram_5f8b76b5f58e\nngramsFeatureVectorsDF: org.apache.spark.sql.DataFrame \u003d [id: bigint, name: string, bio: string, img: string, wordsFeatureVectors: array\u003cstring\u003e, filteredWordsFeatureVectors: array\u003cstring\u003e, ngramsFeatureVectors: array\u003cstring\u003e]\n+--------------------+--------------------+--------------------+\n|                name|                 bio|ngramsFeatureVectors|\n+--------------------+--------------------+--------------------+\n|         Linda Blair|From the age of f...|[age five,, five,...|\n|      Shannon Whirry|Shannon Whirry is...|[shannon whirry, ...|\n|      Rosalind Allen|Rosalind Allen (b...|[rosalind allen, ...|\n|     Bobbie Phillips|Brains and beauty...|[brains beauty, b...|\n|Keshia Knight Pul...|Keshia Knight Pul...|[keshia knight, k...|\n|         Tatyana Ali|On January 24, 19...|[january 24,, 24,...|\n|      Angell Conwell|Born in the tiny ...|[born tiny, tiny ...|\n|  Shannah Laumeister|Shannah Laumeiste...|[shannah laumeist...|\n|           Pam Grier|Pam Grier was bor...|[pam grier, grier...|\n|    Tiffani Thiessen|Tiffani-Amber Thi...|[tiffani-amber th...|\n|         Ashley Judd|Ashley Judd was b...|[ashley judd, jud...|\n|         Stacey Dash|Stacey Dash was b...|[stacey dash, das...|\n|       Sofía Vergara|Sofía Margarita V...|[sofía margarita,...|\n|        Gail O\u0027Grady|Gail O\u0027Grady was ...|[gail o\u0027grady, o\u0027...|\n|       Barbara Niven|Barbara Niven was...|[barbara niven, n...|\n|   Leonardo DiCaprio|Few actors in the...|[actors world, wo...|\n|     Anthony Hopkins|Anthony Hopkins w...|[anthony hopkins,...|\n|           Al Pacino|One of the greate...|[greatest actors,...|\n|      Morgan Freeman|With an authorita...|[authoritative vo...|\n|    James Gandolfini|James Gandolfini ...|[james gandolfini...|\n+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Oct 17, 2015 5:18:27 PM",
      "dateStarted": "Oct 30, 2015 9:18:08 PM",
      "dateFinished": "Oct 30, 2015 9:18:09 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Count Featurizer - N-Grams:  TODO:  Convert ArrayType(false) to ArrayType(true)",
      "text": "import org.apache.spark.ml.feature.{CountVectorizer, CountVectorizerModel}\n\n// fit a CountVectorizerModel from the corpus\nval countNGramsVectorizerEstimator \u003d new CountVectorizer()\n  .setInputCol(\"ngramsFeatureVectors\")\n  .setOutputCol(\"countNGramsFeatureVectors\")\n  .setMinDF(2) // a term must appear in more or equal to 2 documents to be included in the vocabulary\n\nval countNGramsVectorizerModelTransformer \u003d countNGramsVectorizerEstimator.fit(ngramsFeatureVectorsDF)\n\nval countNGramsFeatureVectorsDF \u003d countNGramsVectorizerModelTransformer.transform(ngramsFeatureVectorsDF).select(\"name\", \"bio\", \"countNGramsFeatureVectors\")\n\ncountNGramsFeatureVectorsDF.show()",
      "dateUpdated": "Oct 30, 2015 9:17:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445103941122_-1446492764",
      "id": "20151017-174541_1589950786",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "import org.apache.spark.ml.feature.{CountVectorizer, CountVectorizerModel}\ncountNGramsVectorizerEstimator: org.apache.spark.ml.feature.CountVectorizer \u003d cntVec_955f95a39193\njava.lang.IllegalArgumentException: requirement failed: Column ngramsFeatureVectors must be of type ArrayType(StringType,true) but was actually ArrayType(StringType,false).\n\tat scala.Predef$.require(Predef.scala:233)\n\tat org.apache.spark.ml.util.SchemaUtils$.checkColumnType(SchemaUtils.scala:42)\n\tat org.apache.spark.ml.feature.CountVectorizerParams$class.validateAndTransformSchema(CountVectorizer.scala:71)\n\tat org.apache.spark.ml.feature.CountVectorizer.validateAndTransformSchema(CountVectorizer.scala:107)\n\tat org.apache.spark.ml.feature.CountVectorizer.transformSchema(CountVectorizer.scala:168)\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:62)\n\tat org.apache.spark.ml.feature.CountVectorizer.fit(CountVectorizer.scala:130)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:47)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:52)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:54)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:56)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:58)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:60)\n\tat $iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:62)\n\tat $iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:64)\n\tat $iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:66)\n\tat $iwC.\u003cinit\u003e(\u003cconsole\u003e:68)\n\tat \u003cinit\u003e(\u003cconsole\u003e:70)\n\tat .\u003cinit\u003e(\u003cconsole\u003e:74)\n\tat .\u003cclinit\u003e(\u003cconsole\u003e)\n\tat .\u003cinit\u003e(\u003cconsole\u003e:7)\n\tat .\u003cclinit\u003e(\u003cconsole\u003e)\n\tat $print(\u003cconsole\u003e)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1340)\n\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpretInput(SparkInterpreter.java:655)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpret(SparkInterpreter.java:620)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpret(SparkInterpreter.java:613)\n\tat org.apache.zeppelin.interpreter.ClassloaderInterpreter.interpret(ClassloaderInterpreter.java:57)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:93)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:276)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:170)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:118)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n"
      },
      "dateCreated": "Oct 17, 2015 5:45:41 PM",
      "dateStarted": "Oct 30, 2015 9:18:09 PM",
      "dateFinished": "Oct 30, 2015 9:18:09 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "TODO:  Add categorical Features (Genres?) and One Hot Encode",
      "dateUpdated": "Oct 30, 2015 9:17:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445210443739_1347878706",
      "id": "20151018-232043_2008195623",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT"
      },
      "dateCreated": "Oct 18, 2015 11:20:43 PM",
      "dateStarted": "Oct 30, 2015 9:18:09 PM",
      "dateFinished": "Oct 30, 2015 9:18:09 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Featurize Extended Actresses and Actors Bios  (100 each)",
      "text": "// create the actresses_temp table from the input JSON\nval actresses100BiosDF \u003d sqlContext.read.format(\"json\").load(\"file:/root/pipeline/datasets/hollywood/actresses-100-bios.json\")\nactresses100BiosDF.registerTempTable(\"actresses_100_bios_temp\")\n\n// create the actors_temp table from the input JSON\nval actors100BiosDF \u003d sqlContext.read.format(\"json\").load(\"file:/root/pipeline/datasets/hollywood/actors-100-bios.json\")\nactors100BiosDF.registerTempTable(\"actors_100_bios_temp\")",
      "dateUpdated": "Oct 30, 2015 9:17:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445105724536_-1658776984",
      "id": "20151017-181524_33910338",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "java.io.IOException: No input paths specified in job\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:201)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:207)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:237)\n\tat org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1093)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1091)\n\tat org.apache.spark.sql.execution.datasources.json.InferSchema$.apply(InferSchema.scala:58)\n\tat org.apache.spark.sql.execution.datasources.json.JSONRelation$$anonfun$6.apply(JSONRelation.scala:105)\n\tat org.apache.spark.sql.execution.datasources.json.JSONRelation$$anonfun$6.apply(JSONRelation.scala:100)\n\tat scala.Option.getOrElse(Option.scala:120)\n\tat org.apache.spark.sql.execution.datasources.json.JSONRelation.dataSchema$lzycompute(JSONRelation.scala:100)\n\tat org.apache.spark.sql.execution.datasources.json.JSONRelation.dataSchema(JSONRelation.scala:99)\n\tat org.apache.spark.sql.sources.HadoopFsRelation.schema$lzycompute(interfaces.scala:561)\n\tat org.apache.spark.sql.sources.HadoopFsRelation.schema(interfaces.scala:560)\n\tat org.apache.spark.sql.execution.datasources.LogicalRelation.\u003cinit\u003e(LogicalRelation.scala:31)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:120)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:104)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:31)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:36)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:38)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:40)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:42)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:44)\n\tat $iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:46)\n\tat $iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:48)\n\tat $iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:50)\n\tat $iwC.\u003cinit\u003e(\u003cconsole\u003e:52)\n\tat \u003cinit\u003e(\u003cconsole\u003e:54)\n\tat .\u003cinit\u003e(\u003cconsole\u003e:58)\n\tat .\u003cclinit\u003e(\u003cconsole\u003e)\n\tat .\u003cinit\u003e(\u003cconsole\u003e:7)\n\tat .\u003cclinit\u003e(\u003cconsole\u003e)\n\tat $print(\u003cconsole\u003e)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1340)\n\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpretInput(SparkInterpreter.java:655)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpret(SparkInterpreter.java:620)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpret(SparkInterpreter.java:613)\n\tat org.apache.zeppelin.interpreter.ClassloaderInterpreter.interpret(ClassloaderInterpreter.java:57)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:93)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:276)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:170)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:118)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n"
      },
      "dateCreated": "Oct 17, 2015 6:15:24 PM",
      "dateStarted": "Oct 30, 2015 9:18:09 PM",
      "dateFinished": "Oct 30, 2015 9:18:09 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val actresses100BiosExplodedDF \u003d sqlContext.sql(\"SELECT (90000 + people.index) as id, people.name.text as name, people.bio.text as bio, people.hero.src as img FROM actresses_100_bios_temp LATERAL VIEW explode(results.people) p AS people\")\n\nval actors100BiosExplodedDF \u003d sqlContext.sql(\"SELECT (10000 + people.index) as id, people.name.text as name, people.bio.text as bio, people.hero.src as img FROM actors_100_bios_temp LATERAL VIEW explode(results.people) p AS people\")\n\nval actressesAndActors100BiosDF \u003d actresses100BiosExplodedDF.unionAll(actors100BiosExplodedDF).cache()\nactressesAndAcactressesAndActors100BiosDFtorsDF.show(30)",
      "dateUpdated": "Oct 30, 2015 9:17:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445209766355_1442759564",
      "id": "20151018-230926_166286914",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "org.apache.spark.sql.AnalysisException: no such table actresses_100_bios_temp; line 1 pos 115\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.getTable(Analyzer.scala:260)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$7.applyOrElse(Analyzer.scala:268)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$7.applyOrElse(Analyzer.scala:264)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:57)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:57)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:51)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:56)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:54)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:54)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:249)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:328)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:727)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1157)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1157)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1157)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:279)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:54)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:54)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:54)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:249)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:328)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:727)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1157)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1157)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1157)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:279)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:54)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:264)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:254)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:83)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:80)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:111)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:80)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:72)\n\tat scala.collection.immutable.List.foreach(List.scala:318)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:72)\n\tat org.apache.spark.sql.SQLContext$QueryExecution.analyzed$lzycompute(SQLContext.scala:916)\n\tat org.apache.spark.sql.SQLContext$QueryExecution.analyzed(SQLContext.scala:916)\n\tat org.apache.spark.sql.SQLContext$QueryExecution.assertAnalyzed(SQLContext.scala:914)\n\tat org.apache.spark.sql.DataFrame.\u003cinit\u003e(DataFrame.scala:132)\n\tat org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:51)\n\tat org.apache.spark.sql.SQLContext.sql(SQLContext.scala:725)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:30)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:35)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:37)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:39)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:41)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:43)\n\tat $iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:45)\n\tat $iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:47)\n\tat $iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:49)\n\tat $iwC.\u003cinit\u003e(\u003cconsole\u003e:51)\n\tat \u003cinit\u003e(\u003cconsole\u003e:53)\n\tat .\u003cinit\u003e(\u003cconsole\u003e:57)\n\tat .\u003cclinit\u003e(\u003cconsole\u003e)\n\tat .\u003cinit\u003e(\u003cconsole\u003e:7)\n\tat .\u003cclinit\u003e(\u003cconsole\u003e)\n\tat $print(\u003cconsole\u003e)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1340)\n\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpretInput(SparkInterpreter.java:655)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpret(SparkInterpreter.java:620)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpret(SparkInterpreter.java:613)\n\tat org.apache.zeppelin.interpreter.ClassloaderInterpreter.interpret(ClassloaderInterpreter.java:57)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:93)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:276)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:170)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:118)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n"
      },
      "dateCreated": "Oct 18, 2015 11:09:26 PM",
      "dateStarted": "Oct 30, 2015 9:18:09 PM",
      "dateFinished": "Oct 30, 2015 9:18:09 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "dateUpdated": "Oct 30, 2015 9:17:44 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445209878832_1660663714",
      "id": "20151018-231118_1458525638",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT"
      },
      "dateCreated": "Oct 18, 2015 11:11:18 PM",
      "dateStarted": "Oct 30, 2015 9:18:09 PM",
      "dateFinished": "Oct 30, 2015 9:18:09 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Profile NLP/01: Feature Engineering",
  "id": "2B2SHA7Y8",
  "angularObjects": {
    "2ARR8UZDJ": [],
    "2AS9P7JSA": [],
    "2AR33ZMZJ": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}