{
  "paragraphs": [
    {
      "text": "%dep\nz.reset()\nz.addRepo(\"maven central\").url(\"search.maven.org\")\nz.load(\"com.datastax.spark:spark-cassandra-connector_2.10:1.4.0\")\nz.load(\"org.elasticsearch:elasticsearch-spark_2.10:2.1.2\")\nz.load(\"com.databricks:spark-csv_2.10:1.2.0\")\nz.load(\"org.apache.spark:spark-streaming-kafka-assembly_2.10:1.5.1\")\nz.load(\"redis.clients:jedis:2.7.3\")\nz.load(\"/root/zeppelin-0.6.0-spark-1.5.1-hadoop-2.6.0-fluxcapacitor/lib/mysql-connector-java.jar\")\nz.load(\"/root/pipeline/myapps/datasource/target/scala-2.10/datasource_2.10-1.0.jar\")\nz.load(\"edu.berkeley.cs.amplab:keystoneml_2.10:0.2\")\nz.load(\"edu.stanford.nlp:stanford-corenlp:3.5.2\")\nz.load(\"edu.stanford.nlp:stanford-corenlp-models:3.5.2\")",
      "dateUpdated": "Nov 19, 2015 9:12:55 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445081890962_769572236",
      "id": "20151017-113810_697892520",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "org.sonatype.aether.resolution.DependencyResolutionException: Failed to collect dependencies for edu.berkeley.cs.amplab:keystoneml_2.10:jar:0.2 (compile)"
      },
      "dateCreated": "Oct 17, 2015 11:38:10 AM",
      "dateStarted": "Nov 19, 2015 9:12:57 AM",
      "dateFinished": "Nov 19, 2015 9:14:09 AM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "\nimport java.util.Properties\nimport scala.collection.JavaConversions._\nimport edu.stanford.nlp.pipeline._\nimport edu.stanford.nlp.hcoref.data._\nimport edu.stanford.nlp.dcoref._\nimport edu.stanford.nlp.dcoref.CorefCoreAnnotations\nimport edu.stanford.nlp.dcoref.CorefCoreAnnotations._\nimport edu.stanford.nlp.util._\nimport edu.stanford.nlp.semgraph.SemanticGraph\nimport edu.stanford.nlp.semgraph.SemanticGraphCoreAnnotations\nimport edu.stanford.nlp.semgraph.SemanticGraphCoreAnnotations.CollapsedCCProcessedDependenciesAnnotation\nimport edu.stanford.nlp.ling.CoreAnnotations\nimport edu.stanford.nlp.ling.CoreAnnotations._;\nimport edu.stanford.nlp.trees.TreeCoreAnnotations\nimport edu.stanford.nlp.trees.TreeCoreAnnotations._;\n\n    // creates a StanfordCoreNLP object, with POS tagging, lemmatization, NER, parsing, and coreference resolution\n    val props \u003d new Properties();\n    props.setProperty(\"annotators\", \"tokenize, ssplit, pos, lemma, ner, parse, dcoref\");\n    val pipeline \u003d new StanfordCoreNLP(props);\n\n    // read some text in the text variable\n    val text \u003d \"Stanford University is located in California. It is a great university.\" // Add your text here!\n\n    // create an empty Annotation just with the given text\n    val document \u003d new Annotation(text);\n\n    // run all Annotators on this text\n    pipeline.annotate(document);\n\n    // these are all the sentences in this document\n    // a CoreMap is essentially a Map that uses class objects as keys and has values with custom types\n    val sentences \u003d document.get(new SentencesAnnotation().getClass);\n\n    for(sentence \u003c- sentences) {\n      // traversing the words in the current sentence\n      // a CoreLabel is a CoreMap with additional token-specific methods\n      for (token \u003c- sentence.get(new TokensAnnotation().getClass)) {\n        // this is the text of the token\n        val word \u003d token.get(new TextAnnotation().getClass);\n        // this is the POS tag of the token\n        val pos \u003d token.get(new PartOfSpeechAnnotation().getClass);\n        // this is the NER label of the token\n        val ne \u003d token.get(new NamedEntityTagAnnotation().getClass);\n      }\n\n      // this is the parse tree of the current sentence\n      val tree \u003d sentence.get(new TreeAnnotation().getClass);\n\n      // this is the Stanford dependency graph of the current sentence\n      val dependencies \u003d sentence.get(new CollapsedCCProcessedDependenciesAnnotation().getClass);\n    }\n\n    // This is the coreference link graph\n    // Each chain stores a set of mentions that link to each other,\n    // along with a method for getting the most representative mention\n    // Both sentence and token offsets start at 1!\n    val graph \u003d document.get(new CorefChainAnnotation().getClass);\n    System.out.println(graph)\n  ",
      "dateUpdated": "Nov 19, 2015 9:11:53 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1447924210352_-1354953812",
      "id": "20151119-091010_319366055",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "import java.util.Properties\nimport scala.collection.JavaConversions._\nimport edu.stanford.nlp.pipeline._\nimport edu.stanford.nlp.hcoref.data._\nimport edu.stanford.nlp.dcoref._\nimport edu.stanford.nlp.dcoref.CorefCoreAnnotations\nimport edu.stanford.nlp.dcoref.CorefCoreAnnotations._\nimport edu.stanford.nlp.util._\nimport edu.stanford.nlp.semgraph.SemanticGraph\nimport edu.stanford.nlp.semgraph.SemanticGraphCoreAnnotations\nimport edu.stanford.nlp.semgraph.SemanticGraphCoreAnnotations.CollapsedCCProcessedDependenciesAnnotation\nimport edu.stanford.nlp.ling.CoreAnnotations\nimport edu.stanford.nlp.ling.CoreAnnotations._\nimport edu.stanford.nlp.trees.TreeCoreAnnotations\nimport edu.stanford.nlp.trees.TreeCoreAnnotations._\nprops: java.util.Properties \u003d {}\nres7: Object \u003d null\njava.lang.RuntimeException: edu.stanford.nlp.io.RuntimeIOException: Error while loading a tagger model (probably missing model file)\n\tat edu.stanford.nlp.pipeline.AnnotatorFactories$4.create(AnnotatorFactories.java:292)\n\tat edu.stanford.nlp.pipeline.AnnotatorPool.get(AnnotatorPool.java:85)\n\tat edu.stanford.nlp.pipeline.StanfordCoreNLP.construct(StanfordCoreNLP.java:362)\n\tat edu.stanford.nlp.pipeline.StanfordCoreNLP.\u003cinit\u003e(StanfordCoreNLP.java:135)\n\tat edu.stanford.nlp.pipeline.StanfordCoreNLP.\u003cinit\u003e(StanfordCoreNLP.java:131)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:86)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:91)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:93)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:95)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:97)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:99)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:101)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:103)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:105)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:107)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:109)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:111)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:113)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:115)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:117)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:119)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:121)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:123)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:125)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:127)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:129)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:131)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:133)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:135)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:137)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:139)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:141)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:143)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:145)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:147)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:149)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:151)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:153)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:155)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:157)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:159)\n\tat $iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:161)\n\tat $iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:163)\n\tat $iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:165)\n\tat $iwC.\u003cinit\u003e(\u003cconsole\u003e:167)\n\tat \u003cinit\u003e(\u003cconsole\u003e:169)\n\tat .\u003cinit\u003e(\u003cconsole\u003e:173)\n\tat .\u003cclinit\u003e(\u003cconsole\u003e)\n\tat .\u003cinit\u003e(\u003cconsole\u003e:7)\n\tat .\u003cclinit\u003e(\u003cconsole\u003e)\n\tat $print(\u003cconsole\u003e)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1340)\n\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpretInput(SparkInterpreter.java:655)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpret(SparkInterpreter.java:620)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpret(SparkInterpreter.java:613)\n\tat org.apache.zeppelin.interpreter.ClassloaderInterpreter.interpret(ClassloaderInterpreter.java:57)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:93)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:276)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:170)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:118)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: edu.stanford.nlp.io.RuntimeIOException: Error while loading a tagger model (probably missing model file)\n\tat edu.stanford.nlp.tagger.maxent.MaxentTagger.readModelAndInit(MaxentTagger.java:770)\n\tat edu.stanford.nlp.tagger.maxent.MaxentTagger.\u003cinit\u003e(MaxentTagger.java:298)\n\tat edu.stanford.nlp.tagger.maxent.MaxentTagger.\u003cinit\u003e(MaxentTagger.java:263)\n\tat edu.stanford.nlp.pipeline.POSTaggerAnnotator.loadModel(POSTaggerAnnotator.java:97)\n\tat edu.stanford.nlp.pipeline.POSTaggerAnnotator.\u003cinit\u003e(POSTaggerAnnotator.java:77)\n\tat edu.stanford.nlp.pipeline.AnnotatorImplementations.posTagger(AnnotatorImplementations.java:59)\n\tat edu.stanford.nlp.pipeline.AnnotatorFactories$4.create(AnnotatorFactories.java:290)\n\t... 74 more\nCaused by: java.io.IOException: Unable to open \"edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger\" as class path, filename or URL\n\tat edu.stanford.nlp.io.IOUtils.getInputStreamFromURLOrClasspathOrFileSystem(IOUtils.java:484)\n\tat edu.stanford.nlp.tagger.maxent.MaxentTagger.readModelAndInit(MaxentTagger.java:765)\n\t... 80 more\n\n"
      },
      "dateCreated": "Nov 19, 2015 9:10:10 AM",
      "dateStarted": "Nov 19, 2015 9:11:53 AM",
      "dateFinished": "Nov 19, 2015 9:11:57 AM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "//import com.databricks.spark.corenlp.CoreNLP\n\n// val input \u003d sqlContext.createDataFrame(Seq(\n//   (1, \"\u003cxml\u003eStanford University is located in California. It is a great university.\u003c/xml\u003e\")\n// )).toDF(\"id\", \"text\")\n// val coreNLP \u003d new CoreNLP()\n//   .setInputCol(\"text\")\n//   .setAnnotators(Array(\"tokenize\", \"cleanxml\", \"ssplit\"))\n//   .setFlattenNestedFields(Array(\"sentence_token_word\", \"sentence_characterOffsetBegin\"))\n//   .setOutputCol(\"parsed\")\n// val parsed \u003d coreNLP.transform(input)\n//   .select(\"parsed.sentence_token_word\", \"parsed.sentence_characterOffsetBegin\")\n// println(parsed.first())\n",
      "dateUpdated": "Nov 19, 2015 9:10:38 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1447909357405_-1529711515",
      "id": "20151119-050237_1902761270",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "import com.databricks.spark.corenlp.CoreNLP\ninput: org.apache.spark.sql.DataFrame \u003d [id: int, text: string]\ncoreNLP: com.databricks.spark.corenlp.CoreNLP \u003d corenlp_d398201dd4cb\nparsed: org.apache.spark.sql.DataFrame \u003d [sentence_token_word: array\u003cstring\u003e, sentence_characterOffsetBegin: array\u003cint\u003e]\njava.lang.NoSuchMethodError: com.google.protobuf.LazyStringList.getUnmodifiableView()Lcom/google/protobuf/LazyStringList;\n\tat edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.buildPartial(CoreNLPProtos.java:12038)\n\tat edu.stanford.nlp.pipeline.CoreNLPProtos$Token$Builder.build(CoreNLPProtos.java:11940)\n\tat edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProto(ProtobufAnnotationSerializer.java:237)\n\tat edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProtoBuilder(ProtobufAnnotationSerializer.java:383)\n\tat edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProto(ProtobufAnnotationSerializer.java:344)\n\tat edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProtoBuilder(ProtobufAnnotationSerializer.java:493)\n\tat edu.stanford.nlp.pipeline.ProtobufAnnotationSerializer.toProto(ProtobufAnnotationSerializer.java:455)\n\tat com.databricks.spark.corenlp.CoreNLP$$anonfun$1.apply(CoreNLP.scala:77)\n\tat com.databricks.spark.corenlp.CoreNLP$$anonfun$1.apply(CoreNLP.scala:73)\n\tat org.apache.spark.sql.catalyst.expressions.ScalaUDF$$anonfun$2.apply(ScalaUDF.scala:75)\n\tat org.apache.spark.sql.catalyst.expressions.ScalaUDF$$anonfun$2.apply(ScalaUDF.scala:74)\n\tat org.apache.spark.sql.catalyst.expressions.ScalaUDF.eval(ScalaUDF.scala:964)\n\tat org.apache.spark.sql.catalyst.expressions.UnaryExpression.eval(Expression.scala:247)\n\tat org.apache.spark.sql.catalyst.expressions.Alias.eval(namedExpressions.scala:121)\n\tat org.apache.spark.sql.catalyst.expressions.InterpretedProjection.apply(Projection.scala:46)\n\tat org.apache.spark.sql.catalyst.expressions.InterpretedProjection.apply(Projection.scala:30)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)\n\tat scala.collection.immutable.List.foreach(List.scala:318)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:244)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:105)\n\tat org.apache.spark.sql.catalyst.optimizer.ConvertToLocalRelation$$anonfun$apply$23.applyOrElse(Optimizer.scala:834)\n\tat org.apache.spark.sql.catalyst.optimizer.ConvertToLocalRelation$$anonfun$apply$23.applyOrElse(Optimizer.scala:831)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:227)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:227)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:51)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:226)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:232)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:232)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:249)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:328)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:727)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1157)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:103)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:47)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1157)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:265)\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1157)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:252)\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1157)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:279)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:232)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:217)\n\tat org.apache.spark.sql.catalyst.optimizer.ConvertToLocalRelation$.apply(Optimizer.scala:831)\n\tat org.apache.spark.sql.catalyst.optimizer.ConvertToLocalRelation$.apply(Optimizer.scala:830)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:83)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:80)\n\tat scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:51)\n\tat scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:60)\n\tat scala.collection.mutable.WrappedArray.foldLeft(WrappedArray.scala:34)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:80)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:72)\n\tat scala.collection.immutable.List.foreach(List.scala:318)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:72)\n\tat org.apache.spark.sql.SQLContext$QueryExecution.optimizedPlan$lzycompute(SQLContext.scala:921)\n\tat org.apache.spark.sql.SQLContext$QueryExecution.optimizedPlan(SQLContext.scala:921)\n\tat org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan$lzycompute(SQLContext.scala:926)\n\tat org.apache.spark.sql.SQLContext$QueryExecution.sparkPlan(SQLContext.scala:924)\n\tat org.apache.spark.sql.SQLContext$QueryExecution.executedPlan$lzycompute(SQLContext.scala:930)\n\tat org.apache.spark.sql.SQLContext$QueryExecution.executedPlan(SQLContext.scala:930)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:53)\n\tat org.apache.spark.sql.DataFrame.withNewExecutionId(DataFrame.scala:1903)\n\tat org.apache.spark.sql.DataFrame.collect(DataFrame.scala:1384)\n\tat org.apache.spark.sql.DataFrame.head(DataFrame.scala:1314)\n\tat org.apache.spark.sql.DataFrame.head(DataFrame.scala:1321)\n\tat org.apache.spark.sql.DataFrame.first(DataFrame.scala:1328)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:29)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:34)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:36)\n\tat $iwC$$iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:38)\n\tat $iwC$$iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:40)\n\tat $iwC$$iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:42)\n\tat $iwC$$iwC.\u003cinit\u003e(\u003cconsole\u003e:44)\n\tat $iwC.\u003cinit\u003e(\u003cconsole\u003e:46)\n\tat \u003cinit\u003e(\u003cconsole\u003e:48)\n\tat .\u003cinit\u003e(\u003cconsole\u003e:52)\n\tat .\u003cclinit\u003e(\u003cconsole\u003e)\n\tat .\u003cinit\u003e(\u003cconsole\u003e:7)\n\tat .\u003cclinit\u003e(\u003cconsole\u003e)\n\tat $print(\u003cconsole\u003e)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n\tat org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1340)\n\tat org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n\tat org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpretInput(SparkInterpreter.java:655)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpret(SparkInterpreter.java:620)\n\tat org.apache.zeppelin.spark.SparkInterpreter.interpret(SparkInterpreter.java:613)\n\tat org.apache.zeppelin.interpreter.ClassloaderInterpreter.interpret(ClassloaderInterpreter.java:57)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:93)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:276)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:170)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:118)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\n"
      },
      "dateCreated": "Nov 19, 2015 5:02:37 AM",
      "dateStarted": "Nov 19, 2015 6:37:26 AM",
      "dateFinished": "Nov 19, 2015 6:37:38 AM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Populate ActressesAndActorsDF Reference Data",
      "text": "val actressesAndActorsDF \u003d sqlContext.sql(\"SELECT id, name, bio, img FROM actresses_and_actors_perm\")\n\nactressesAndActorsDF.show()",
      "dateUpdated": "Nov 19, 2015 5:02:17 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445081927425_320383091",
      "id": "20151017-113847_1233175220",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "actressesAndActorsDF: org.apache.spark.sql.DataFrame \u003d [id: bigint, name: string, bio: string, img: string]\n+-----+--------------------+--------------------+--------------------+\n|   id|                name|                 bio|                 img|\n+-----+--------------------+--------------------+--------------------+\n|90001|         Linda Blair|From the age of f...|img/people/90001.jpg|\n|90002|      Shannon Whirry|Shannon Whirry is...|img/people/90002.jpg|\n|90003|      Rosalind Allen|Rosalind Allen (b...|img/people/90003.jpg|\n|90004|     Bobbie Phillips|Brains and beauty...|img/people/90004.jpg|\n|90005|Keshia Knight Pul...|Keshia Knight Pul...|img/people/90005.jpg|\n|90006|         Tatyana Ali|On January 24, 19...|img/people/90006.jpg|\n|90007|      Angell Conwell|Born in the tiny ...|img/people/90007.jpg|\n|90008|  Shannah Laumeister|Shannah Laumeiste...|img/people/90008.jpg|\n|90009|           Pam Grier|Pam Grier was bor...|img/people/90009.jpg|\n|90010|    Tiffani Thiessen|Tiffani-Amber Thi...|img/people/90010.jpg|\n|90011|         Ashley Judd|Ashley Judd was b...|img/people/90011.jpg|\n|90012|         Stacey Dash|Stacey Dash was b...|img/people/90012.jpg|\n|90013|       Sofía Vergara|Sofía Margarita V...|img/people/90013.jpg|\n|90014|        Gail O\u0027Grady|Gail O\u0027Grady was ...|img/people/90014.jpg|\n|90015|       Barbara Niven|Barbara Niven was...|img/people/90015.jpg|\n|10001|   Leonardo DiCaprio|Few actors in the...|img/people/10001.jpg|\n|10002|     Anthony Hopkins|Anthony Hopkins w...|img/people/10002.jpg|\n|10003|           Al Pacino|One of the greate...|img/people/10003.jpg|\n|10004|      Morgan Freeman|With an authorita...|img/people/10004.jpg|\n|10005|    James Gandolfini|James Gandolfini ...|img/people/10005.jpg|\n+-----+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Oct 17, 2015 11:38:47 AM",
      "dateStarted": "Nov 19, 2015 5:02:17 AM",
      "dateFinished": "Nov 19, 2015 5:02:31 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Convert \"bio\" column into Array[String]",
      "text": "import org.apache.spark.ml.feature.Tokenizer\n\nval tokenizerTransformer \u003d new Tokenizer().setInputCol(\"bio\").setOutputCol(\"wordsFeatureVectors\")\n\nval wordsFeatureVectorsDF \u003d tokenizerTransformer.transform(actressesAndActorsDF)\n\nwordsFeatureVectorsDF.select(\"name\", \"bio\", \"wordsFeatureVectors\").show()",
      "dateUpdated": "Nov 2, 2015 5:49:12 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445102998027_-1055707710",
      "id": "20151017-172958_1780692227",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.ml.feature.Tokenizer\ntokenizerTransformer: org.apache.spark.ml.feature.Tokenizer \u003d tok_3cffe7d91695\nwordsFeatureVectorsDF: org.apache.spark.sql.DataFrame \u003d [id: bigint, name: string, bio: string, img: string, wordsFeatureVectors: array\u003cstring\u003e]\n+--------------------+--------------------+--------------------+\n|                name|                 bio| wordsFeatureVectors|\n+--------------------+--------------------+--------------------+\n|         Linda Blair|From the age of f...|[from, the, age, ...|\n|      Shannon Whirry|Shannon Whirry is...|[shannon, whirry,...|\n|      Rosalind Allen|Rosalind Allen (b...|[rosalind, allen,...|\n|     Bobbie Phillips|Brains and beauty...|[brains, and, bea...|\n|Keshia Knight Pul...|Keshia Knight Pul...|[keshia, knight, ...|\n|         Tatyana Ali|On January 24, 19...|[on, january, 24,...|\n|      Angell Conwell|Born in the tiny ...|[born, in, the, t...|\n|  Shannah Laumeister|Shannah Laumeiste...|[shannah, laumeis...|\n|           Pam Grier|Pam Grier was bor...|[pam, grier, was,...|\n|    Tiffani Thiessen|Tiffani-Amber Thi...|[tiffani-amber, t...|\n|         Ashley Judd|Ashley Judd was b...|[ashley, judd, wa...|\n|         Stacey Dash|Stacey Dash was b...|[stacey, dash, wa...|\n|       Sofía Vergara|Sofía Margarita V...|[sofía, margarita...|\n|        Gail O\u0027Grady|Gail O\u0027Grady was ...|[gail, o\u0027grady, w...|\n|       Barbara Niven|Barbara Niven was...|[barbara, niven, ...|\n|   Leonardo DiCaprio|Few actors in the...|[few, actors, in,...|\n|     Anthony Hopkins|Anthony Hopkins w...|[anthony, hopkins...|\n|           Al Pacino|One of the greate...|[one, of, the, gr...|\n|      Morgan Freeman|With an authorita...|[with, an, author...|\n|    James Gandolfini|James Gandolfini ...|[james, gandolfin...|\n+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Oct 17, 2015 5:29:58 PM",
      "dateStarted": "Nov 2, 2015 5:49:13 PM",
      "dateFinished": "Nov 2, 2015 5:49:14 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Filter Out Stop Words",
      "text": "import org.apache.spark.ml.feature.StopWordsRemover\n\nval stopWordRemoverTransformer \u003d new StopWordsRemover().setInputCol(\"wordsFeatureVectors\").setOutputCol(\"filteredWordsFeatureVectors\")\n\nval filteredWordsFeatureVectorsDF \u003d stopWordRemoverTransformer.transform(wordsFeatureVectorsDF)\n\nfilteredWordsFeatureVectorsDF.select(\"name\", \"bio\", \"filteredWordsFeatureVectors\").show()",
      "dateUpdated": "Nov 2, 2015 5:49:12 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445104905188_1508787084",
      "id": "20151017-180145_1212516680",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.ml.feature.StopWordsRemover\nstopWordRemoverTransformer: org.apache.spark.ml.feature.StopWordsRemover \u003d stopWords_a9785ca16b53\nfilteredWordsFeatureVectorsDF: org.apache.spark.sql.DataFrame \u003d [id: bigint, name: string, bio: string, img: string, wordsFeatureVectors: array\u003cstring\u003e, filteredWordsFeatureVectors: array\u003cstring\u003e]\n+--------------------+--------------------+---------------------------+\n|                name|                 bio|filteredWordsFeatureVectors|\n+--------------------+--------------------+---------------------------+\n|         Linda Blair|From the age of f...|       [age, five,, lind...|\n|      Shannon Whirry|Shannon Whirry is...|       [shannon, whirry,...|\n|      Rosalind Allen|Rosalind Allen (b...|       [rosalind, allen,...|\n|     Bobbie Phillips|Brains and beauty...|       [brains, beauty, ...|\n|Keshia Knight Pul...|Keshia Knight Pul...|       [keshia, knight, ...|\n|         Tatyana Ali|On January 24, 19...|       [january, 24,, 19...|\n|      Angell Conwell|Born in the tiny ...|       [born, tiny, town...|\n|  Shannah Laumeister|Shannah Laumeiste...|       [shannah, laumeis...|\n|           Pam Grier|Pam Grier was bor...|       [pam, grier, born...|\n|    Tiffani Thiessen|Tiffani-Amber Thi...|       [tiffani-amber, t...|\n|         Ashley Judd|Ashley Judd was b...|       [ashley, judd, bo...|\n|         Stacey Dash|Stacey Dash was b...|       [stacey, dash, bo...|\n|       Sofía Vergara|Sofía Margarita V...|       [sofía, margarita...|\n|        Gail O\u0027Grady|Gail O\u0027Grady was ...|       [gail, o\u0027grady, b...|\n|       Barbara Niven|Barbara Niven was...|       [barbara, niven, ...|\n|   Leonardo DiCaprio|Few actors in the...|       [actors, world, c...|\n|     Anthony Hopkins|Anthony Hopkins w...|       [anthony, hopkins...|\n|           Al Pacino|One of the greate...|       [greatest, actors...|\n|      Morgan Freeman|With an authorita...|       [authoritative, v...|\n|    James Gandolfini|James Gandolfini ...|       [james, gandolfin...|\n+--------------------+--------------------+---------------------------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Oct 17, 2015 6:01:45 PM",
      "dateStarted": "Nov 2, 2015 5:49:14 PM",
      "dateFinished": "Nov 2, 2015 5:49:15 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "TF/IDF Featurizer",
      "text": "import org.apache.spark.ml.feature.{HashingTF, IDF, Tokenizer}\n\nval hashingTFTransformer \u003d new HashingTF().setInputCol(\"filteredWordsFeatureVectors\").setOutputCol(\"tfWordsFeatureVectors\").setNumFeatures(1000)\n\nval tfWordsFeatureVectorsDF \u003d hashingTFTransformer.transform(filteredWordsFeatureVectorsDF)\n\nval idfEstimator \u003d new IDF().setInputCol(\"tfWordsFeatureVectors\").setOutputCol(\"tfIdfWordsFeatureVectors\")\n\nval idfModelTransformer \u003d idfEstimator.fit(tfWordsFeatureVectorsDF)\n\nval tfIdfWordsFeatureVectorsDF \u003d idfModelTransformer.transform(tfWordsFeatureVectorsDF)\n\ntfIdfWordsFeatureVectorsDF.select(\"name\", \"bio\", \"tfIdfWordsFeatureVectors\").show()",
      "dateUpdated": "Nov 2, 2015 5:49:12 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445099320523_1491093045",
      "id": "20151017-162840_1956587375",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.ml.feature.{HashingTF, IDF, Tokenizer}\nhashingTFTransformer: org.apache.spark.ml.feature.HashingTF \u003d hashingTF_e682c66ed0e5\ntfWordsFeatureVectorsDF: org.apache.spark.sql.DataFrame \u003d [id: bigint, name: string, bio: string, img: string, wordsFeatureVectors: array\u003cstring\u003e, filteredWordsFeatureVectors: array\u003cstring\u003e, tfWordsFeatureVectors: vector]\nidfEstimator: org.apache.spark.ml.feature.IDF \u003d idf_450476b5b699\nidfModelTransformer: org.apache.spark.ml.feature.IDFModel \u003d idf_450476b5b699\ntfIdfWordsFeatureVectorsDF: org.apache.spark.sql.DataFrame \u003d [id: bigint, name: string, bio: string, img: string, wordsFeatureVectors: array\u003cstring\u003e, filteredWordsFeatureVectors: array\u003cstring\u003e, tfWordsFeatureVectors: vector, tfIdfWordsFeatureVectors: vector]\n+--------------------+--------------------+------------------------+\n|                name|                 bio|tfIdfWordsFeatureVectors|\n+--------------------+--------------------+------------------------+\n|         Linda Blair|From the age of f...|    (1000,[72,128,153...|\n|      Shannon Whirry|Shannon Whirry is...|    (1000,[43,63,80,9...|\n|      Rosalind Allen|Rosalind Allen (b...|    (1000,[38,45,104,...|\n|     Bobbie Phillips|Brains and beauty...|    (1000,[4,15,53,13...|\n|Keshia Knight Pul...|Keshia Knight Pul...|    (1000,[4,46,54,11...|\n|         Tatyana Ali|On January 24, 19...|    (1000,[57,77,114,...|\n|      Angell Conwell|Born in the tiny ...|    (1000,[6,23,49,53...|\n|  Shannah Laumeister|Shannah Laumeiste...|    (1000,[46,86,115,...|\n|           Pam Grier|Pam Grier was bor...|    (1000,[34,46,125,...|\n|    Tiffani Thiessen|Tiffani-Amber Thi...|    (1000,[7,50,67,11...|\n|         Ashley Judd|Ashley Judd was b...|    (1000,[46,99,117,...|\n|         Stacey Dash|Stacey Dash was b...|    (1000,[44,46,49,5...|\n|       Sofía Vergara|Sofía Margarita V...|    (1000,[74,181,182...|\n|        Gail O\u0027Grady|Gail O\u0027Grady was ...|    (1000,[32,34,53,7...|\n|       Barbara Niven|Barbara Niven was...|    (1000,[4,20,72,99...|\n|   Leonardo DiCaprio|Few actors in the...|    (1000,[6,22,43,18...|\n|     Anthony Hopkins|Anthony Hopkins w...|    (1000,[15,79,100,...|\n|           Al Pacino|One of the greate...|    (1000,[0,3,6,26,3...|\n|      Morgan Freeman|With an authorita...|    (1000,[13,30,32,6...|\n|    James Gandolfini|James Gandolfini ...|    (1000,[17,23,45,4...|\n+--------------------+--------------------+------------------------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Oct 17, 2015 4:28:40 PM",
      "dateStarted": "Nov 2, 2015 5:49:14 PM",
      "dateFinished": "Nov 2, 2015 5:49:17 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "TODO:  You\u0027ll want to normalize otherwise absolute value (magnitude) will affect outcome",
      "text": "",
      "dateUpdated": "Nov 2, 2015 5:49:12 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445949366628_2065789687",
      "id": "20151027-123606_45737102",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT"
      },
      "dateCreated": "Oct 27, 2015 12:36:06 PM",
      "dateStarted": "Nov 2, 2015 5:49:15 PM",
      "dateFinished": "Nov 2, 2015 5:49:17 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Word2Vec Featurizer",
      "text": "import org.apache.spark.ml.feature.Word2Vec\n\nval word2VecEstimator \u003d new Word2Vec()\n  .setInputCol(\"filteredWordsFeatureVectors\")\n  .setOutputCol(\"word2vecWordsFeatureVectors\")\n  .setMinCount(2)\n\nval word2VecModelTransformer \u003d word2VecEstimator.fit(filteredWordsFeatureVectorsDF)\n\nval word2VecWordFeatureVectorsDF \u003d word2VecModelTransformer.transform(filteredWordsFeatureVectorsDF)\n\nword2VecWordFeatureVectorsDF.select(\"name\", \"bio\", \"word2vecWordsFeatureVectors\").show()",
      "dateUpdated": "Nov 2, 2015 5:49:13 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445099681901_-853444159",
      "id": "20151017-163441_477395570",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.ml.feature.Word2Vec\nword2VecEstimator: org.apache.spark.ml.feature.Word2Vec \u003d w2v_ae9b2f6615af\nword2VecModelTransformer: org.apache.spark.ml.feature.Word2VecModel \u003d w2v_ae9b2f6615af\nword2VecWordFeatureVectorsDF: org.apache.spark.sql.DataFrame \u003d [id: bigint, name: string, bio: string, img: string, wordsFeatureVectors: array\u003cstring\u003e, filteredWordsFeatureVectors: array\u003cstring\u003e, word2vecWordsFeatureVectors: vector]\n+--------------------+--------------------+---------------------------+\n|                name|                 bio|word2vecWordsFeatureVectors|\n+--------------------+--------------------+---------------------------+\n|         Linda Blair|From the age of f...|       [-4.6090747566957...|\n|      Shannon Whirry|Shannon Whirry is...|       [-4.6550503586707...|\n|      Rosalind Allen|Rosalind Allen (b...|       [-1.0757597779194...|\n|     Bobbie Phillips|Brains and beauty...|       [-4.5989937994077...|\n|Keshia Knight Pul...|Keshia Knight Pul...|       [5.30538641297343...|\n|         Tatyana Ali|On January 24, 19...|       [-2.6405665812490...|\n|      Angell Conwell|Born in the tiny ...|       [-3.2908980287366...|\n|  Shannah Laumeister|Shannah Laumeiste...|       [-2.0148014882579...|\n|           Pam Grier|Pam Grier was bor...|       [-4.0055314644372...|\n|    Tiffani Thiessen|Tiffani-Amber Thi...|       [-5.2080940539863...|\n|         Ashley Judd|Ashley Judd was b...|       [-2.1748697273088...|\n|         Stacey Dash|Stacey Dash was b...|       [-4.5374684233331...|\n|       Sofía Vergara|Sofía Margarita V...|       [1.72133621727598...|\n|        Gail O\u0027Grady|Gail O\u0027Grady was ...|       [-2.7032762520276...|\n|       Barbara Niven|Barbara Niven was...|       [-6.9077954627573...|\n|   Leonardo DiCaprio|Few actors in the...|       [-2.5081590704050...|\n|     Anthony Hopkins|Anthony Hopkins w...|       [4.56674773689686...|\n|           Al Pacino|One of the greate...|       [8.58004599909431...|\n|      Morgan Freeman|With an authorita...|       [-3.3898770624514...|\n|    James Gandolfini|James Gandolfini ...|       [-2.2593710746150...|\n+--------------------+--------------------+---------------------------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Oct 17, 2015 4:34:41 PM",
      "dateStarted": "Nov 2, 2015 5:49:17 PM",
      "dateFinished": "Nov 2, 2015 5:49:18 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Count Featurizer - Words",
      "text": "import org.apache.spark.ml.feature.{CountVectorizer, CountVectorizerModel}\n\n// fit a CountVectorizerModel from the corpus\nval countWordsVectorizerEstimator \u003d new CountVectorizer()\n  .setInputCol(\"filteredWordsFeatureVectors\")\n  .setOutputCol(\"countWordsFeatureVectors\")\n  .setMinDF(2) // a term must appear in more or equal to 2 documents to be included in the vocabulary\n\nval countWordsVectorizerModelTransformer \u003d countWordsVectorizerEstimator.fit(filteredWordsFeatureVectorsDF)\n\nval countWordsFeatureVectorsDF \u003d countWordsVectorizerModelTransformer.transform(filteredWordsFeatureVectorsDF).select(\"name\", \"bio\", \"filteredWordsFeatureVectors\", \"countWordsFeatureVectors\")\n\ncountWordsFeatureVectorsDF.show()",
      "dateUpdated": "Nov 2, 2015 5:49:13 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445101913136_1473887137",
      "id": "20151017-171153_871858",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.ml.feature.{CountVectorizer, CountVectorizerModel}\ncountWordsVectorizerEstimator: org.apache.spark.ml.feature.CountVectorizer \u003d cntVec_40e0e3ea4c06\ncountWordsVectorizerModelTransformer: org.apache.spark.ml.feature.CountVectorizerModel \u003d cntVec_40e0e3ea4c06\ncountWordsFeatureVectorsDF: org.apache.spark.sql.DataFrame \u003d [name: string, bio: string, filteredWordsFeatureVectors: array\u003cstring\u003e, countWordsFeatureVectors: vector]\n+--------------------+--------------------+---------------------------+------------------------+\n|                name|                 bio|filteredWordsFeatureVectors|countWordsFeatureVectors|\n+--------------------+--------------------+---------------------------+------------------------+\n|         Linda Blair|From the age of f...|       [age, five,, lind...|    (87,[9,16,53,68,7...|\n|      Shannon Whirry|Shannon Whirry is...|       [shannon, whirry,...|    (87,[0,1,5,6,14,3...|\n|      Rosalind Allen|Rosalind Allen (b...|       [rosalind, allen,...|    (87,[1,15,22,26,4...|\n|     Bobbie Phillips|Brains and beauty...|       [brains, beauty, ...|    (87,[5,14,15,43,4...|\n|Keshia Knight Pul...|Keshia Knight Pul...|       [keshia, knight, ...|    (87,[0,1,2,17,20,...|\n|         Tatyana Ali|On January 24, 19...|       [january, 24,, 19...|    (87,[0,9,34,48,52...|\n|      Angell Conwell|Born in the tiny ...|       [born, tiny, town...|    (87,[0,1,9,13,16,...|\n|  Shannah Laumeister|Shannah Laumeiste...|       [shannah, laumeis...|    (87,[0,2,6,10,19,...|\n|           Pam Grier|Pam Grier was bor...|       [pam, grier, born...|    (87,[0,1,15,35,38...|\n|    Tiffani Thiessen|Tiffani-Amber Thi...|       [tiffani-amber, t...|    (87,[0,10,13,22,3...|\n|         Ashley Judd|Ashley Judd was b...|       [ashley, judd, bo...|    (87,[0,2,6,10,17,...|\n|         Stacey Dash|Stacey Dash was b...|       [stacey, dash, bo...|    (87,[0,1,9,26,29,...|\n|       Sofía Vergara|Sofía Margarita V...|       [sofía, margarita...|    (87,[0,11,23,24],...|\n|        Gail O\u0027Grady|Gail O\u0027Grady was ...|       [gail, o\u0027grady, b...|    (87,[0,2,3,6,8,19...|\n|       Barbara Niven|Barbara Niven was...|       [barbara, niven, ...|    (87,[0,2,6,32,40]...|\n|   Leonardo DiCaprio|Few actors in the...|       [actors, world, c...|    (87,[4,7,15,35,61...|\n|     Anthony Hopkins|Anthony Hopkins w...|       [anthony, hopkins...|    (87,[0,13,37,55,5...|\n|           Al Pacino|One of the greate...|       [greatest, actors...|    (87,[0,1,3,7,12,1...|\n|      Morgan Freeman|With an authorita...|       [authoritative, v...|    (87,[0,3,4,30,51,...|\n|    James Gandolfini|James Gandolfini ...|       [james, gandolfin...|    (87,[0,1,5,13,14,...|\n+--------------------+--------------------+---------------------------+------------------------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Oct 17, 2015 5:11:53 PM",
      "dateStarted": "Nov 2, 2015 5:49:17 PM",
      "dateFinished": "Nov 2, 2015 5:49:19 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "N-Gram Featurizer",
      "text": "import org.apache.spark.ml.feature.NGram\n\nval ngramTransformer \u003d new NGram().setN(2).setInputCol(\"filteredWordsFeatureVectors\").setOutputCol(\"ngramsFeatureVectors\")\n\nval ngramsFeatureVectorsDF \u003d ngramTransformer.transform(filteredWordsFeatureVectorsDF)\n\nngramsFeatureVectorsDF.select(\"name\", \"bio\", \"ngramsFeatureVectors\").show()",
      "dateUpdated": "Nov 2, 2015 5:49:13 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445102307362_-534718304",
      "id": "20151017-171827_540520315",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.ml.feature.NGram\nngramTransformer: org.apache.spark.ml.feature.NGram \u003d ngram_867019b662f4\nngramsFeatureVectorsDF: org.apache.spark.sql.DataFrame \u003d [id: bigint, name: string, bio: string, img: string, wordsFeatureVectors: array\u003cstring\u003e, filteredWordsFeatureVectors: array\u003cstring\u003e, ngramsFeatureVectors: array\u003cstring\u003e]\n+--------------------+--------------------+--------------------+\n|                name|                 bio|ngramsFeatureVectors|\n+--------------------+--------------------+--------------------+\n|         Linda Blair|From the age of f...|[age five,, five,...|\n|      Shannon Whirry|Shannon Whirry is...|[shannon whirry, ...|\n|      Rosalind Allen|Rosalind Allen (b...|[rosalind allen, ...|\n|     Bobbie Phillips|Brains and beauty...|[brains beauty, b...|\n|Keshia Knight Pul...|Keshia Knight Pul...|[keshia knight, k...|\n|         Tatyana Ali|On January 24, 19...|[january 24,, 24,...|\n|      Angell Conwell|Born in the tiny ...|[born tiny, tiny ...|\n|  Shannah Laumeister|Shannah Laumeiste...|[shannah laumeist...|\n|           Pam Grier|Pam Grier was bor...|[pam grier, grier...|\n|    Tiffani Thiessen|Tiffani-Amber Thi...|[tiffani-amber th...|\n|         Ashley Judd|Ashley Judd was b...|[ashley judd, jud...|\n|         Stacey Dash|Stacey Dash was b...|[stacey dash, das...|\n|       Sofía Vergara|Sofía Margarita V...|[sofía margarita,...|\n|        Gail O\u0027Grady|Gail O\u0027Grady was ...|[gail o\u0027grady, o\u0027...|\n|       Barbara Niven|Barbara Niven was...|[barbara niven, n...|\n|   Leonardo DiCaprio|Few actors in the...|[actors world, wo...|\n|     Anthony Hopkins|Anthony Hopkins w...|[anthony hopkins,...|\n|           Al Pacino|One of the greate...|[greatest actors,...|\n|      Morgan Freeman|With an authorita...|[authoritative vo...|\n|    James Gandolfini|James Gandolfini ...|[james gandolfini...|\n+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
      },
      "dateCreated": "Oct 17, 2015 5:18:27 PM",
      "dateStarted": "Nov 2, 2015 5:49:19 PM",
      "dateFinished": "Nov 2, 2015 5:49:20 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "TODO:  Add categorical Features (Genres?) and One Hot Encode",
      "dateUpdated": "Nov 2, 2015 5:49:14 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445210443739_1347878706",
      "id": "20151018-232043_2008195623",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT"
      },
      "dateCreated": "Oct 18, 2015 11:20:43 PM",
      "dateStarted": "Nov 2, 2015 5:49:21 PM",
      "dateFinished": "Nov 2, 2015 5:49:21 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "dateUpdated": "Nov 2, 2015 5:49:15 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445209878832_1660663714",
      "id": "20151018-231118_1458525638",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT"
      },
      "dateCreated": "Oct 18, 2015 11:11:18 PM",
      "dateStarted": "Nov 2, 2015 5:49:22 PM",
      "dateFinished": "Nov 2, 2015 5:49:22 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Profile NLP/01: Feature Engineering",
  "id": "2B2SHA7Y8",
  "angularObjects": {
    "2ARR8UZDJ": [],
    "2AS9P7JSA": [],
    "2AR33ZMZJ": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}