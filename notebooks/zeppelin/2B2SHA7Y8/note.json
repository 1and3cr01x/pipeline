{
  "paragraphs": [
    {
      "text": "%dep\nz.reset()\nz.addRepo(\"maven central\").url(\"search.maven.org\")\nz.load(\"com.datastax.spark:spark-cassandra-connector_2.10:1.4.0\")\nz.load(\"org.elasticsearch:elasticsearch-spark_2.10:2.1.0\")\nz.load(\"com.databricks:spark-csv_2.10:1.2.0\")\nz.load(\"org.apache.spark:spark-streaming-kafka-assembly_2.10:1.5.1\")\nz.load(\"/root/zeppelin-0.6.0-spark-1.5.1-hadoop-2.6.0-fluxcapacitor/lib/mysql-connector-java.jar\")\nz.load(\"/root/pipeline/myapps/datasource/target/scala-2.10/datasource_2.10-1.0.jar\")",
      "dateUpdated": "Oct 27, 2015 12:41:12 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445081890962_769572236",
      "id": "20151017-113810_697892520",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "Must be used before SparkInterpreter (%spark) initialized"
      },
      "dateCreated": "Oct 17, 2015 11:38:10 AM",
      "dateStarted": "Oct 27, 2015 12:41:12 PM",
      "dateFinished": "Oct 27, 2015 12:41:12 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Populate ActressesAndActorsDF Reference Data",
      "text": "val actressesAndActorsDF \u003d sqlContext.sql(\"SELECT id, name, bio, img FROM actresses_and_actors_perm\")\n\nactressesAndActorsDF.show()",
      "dateUpdated": "Oct 27, 2015 12:41:12 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445081927425_320383091",
      "id": "20151017-113847_1233175220",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "File name too long"
      },
      "dateCreated": "Oct 17, 2015 11:38:47 AM",
      "dateStarted": "Oct 27, 2015 12:41:12 PM",
      "dateFinished": "Oct 27, 2015 12:41:12 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Convert \"bio\" column into Array[String]",
      "text": "import org.apache.spark.ml.feature.Tokenizer\n\nval tokenizerTransformer \u003d new Tokenizer().setInputCol(\"bio\").setOutputCol(\"wordsFeatureVectors\")\n\nval wordsFeatureVectorsDF \u003d tokenizerTransformer.transform(actressesAndActorsDF)\n\nwordsFeatureVectorsDF.select(\"name\", \"bio\", \"wordsFeatureVectors\").show()",
      "dateUpdated": "Oct 27, 2015 12:41:12 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445102998027_-1055707710",
      "id": "20151017-172958_1780692227",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "File name too long"
      },
      "dateCreated": "Oct 17, 2015 5:29:58 PM",
      "dateStarted": "Oct 27, 2015 12:41:12 PM",
      "dateFinished": "Oct 27, 2015 12:41:12 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Filter Out Stop Words",
      "text": "import org.apache.spark.ml.feature.StopWordsRemover\n\nval stopWordRemoverTransformer \u003d new StopWordsRemover().setInputCol(\"wordsFeatureVectors\").setOutputCol(\"filteredWordsFeatureVectors\")\n\nval filteredWordsFeatureVectorsDF \u003d stopWordRemoverTransformer.transform(wordsFeatureVectorsDF)\n\nfilteredWordsFeatureVectorsDF.select(\"name\", \"bio\", \"filteredWordsFeatureVectors\").show()",
      "dateUpdated": "Oct 27, 2015 12:41:12 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445104905188_1508787084",
      "id": "20151017-180145_1212516680",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "File name too long"
      },
      "dateCreated": "Oct 17, 2015 6:01:45 PM",
      "dateStarted": "Oct 27, 2015 12:41:12 PM",
      "dateFinished": "Oct 27, 2015 12:41:13 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "TF/IDF Featurizer",
      "text": "import org.apache.spark.ml.feature.{HashingTF, IDF, Tokenizer}\n\nval hashingTFTransformer \u003d new HashingTF().setInputCol(\"filteredWordsFeatureVectors\").setOutputCol(\"tfWordsFeatureVectors\").setNumFeatures(1000)\n\nval tfWordsFeatureVectorsDF \u003d hashingTFTransformer.transform(filteredWordsFeatureVectorsDF)\n\nval idfEstimator \u003d new IDF().setInputCol(\"tfWordsFeatureVectors\").setOutputCol(\"tfIdfWordsFeatureVectors\")\n\nval idfModelTransformer \u003d idfEstimator.fit(tfWordsFeatureVectorsDF)\n\nval tfIdfWordsFeatureVectorsDF \u003d idfModelTransformer.transform(tfWordsFeatureVectorsDF)\n\ntfIdfWordsFeatureVectorsDF.select(\"name\", \"bio\", \"tfIdfWordsFeatureVectors\").show()",
      "dateUpdated": "Oct 27, 2015 12:41:12 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445099320523_1491093045",
      "id": "20151017-162840_1956587375",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "File name too long"
      },
      "dateCreated": "Oct 17, 2015 4:28:40 PM",
      "dateStarted": "Oct 27, 2015 12:41:13 PM",
      "dateFinished": "Oct 27, 2015 12:41:13 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "TODO:  You\u0027ll want to normalize otherwise absolute value (magnitude) will affect outcome",
      "text": "",
      "dateUpdated": "Oct 27, 2015 12:41:12 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445949366628_2065789687",
      "id": "20151027-123606_45737102",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT"
      },
      "dateCreated": "Oct 27, 2015 12:36:06 PM",
      "dateStarted": "Oct 27, 2015 12:41:13 PM",
      "dateFinished": "Oct 27, 2015 12:41:13 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Word2Vec Featurizer",
      "text": "import org.apache.spark.ml.feature.Word2Vec\n\nval word2VecEstimator \u003d new Word2Vec()\n  .setInputCol(\"filteredWordsFeatureVectors\")\n  .setOutputCol(\"word2vecWordsFeatureVectors\")\n  .setMinCount(2)\n\nval word2VecModelTransformer \u003d word2VecEstimator.fit(filteredWordsFeatureVectorsDF)\n\nval word2VecWordFeatureVectorsDF \u003d word2VecModelTransformer.transform(filteredWordsFeatureVectorsDF)\n\nword2VecWordFeatureVectorsDF.select(\"name\", \"bio\", \"word2vecWordsFeatureVectors\").show()",
      "dateUpdated": "Oct 27, 2015 12:41:12 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445099681901_-853444159",
      "id": "20151017-163441_477395570",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "File name too long"
      },
      "dateCreated": "Oct 17, 2015 4:34:41 PM",
      "dateStarted": "Oct 27, 2015 12:41:13 PM",
      "dateFinished": "Oct 27, 2015 12:41:13 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Count Featurizer - Words",
      "text": "import org.apache.spark.ml.feature.{CountVectorizer, CountVectorizerModel}\n\n// fit a CountVectorizerModel from the corpus\nval countWordsVectorizerEstimator \u003d new CountVectorizer()\n  .setInputCol(\"filteredWordsFeatureVectors\")\n  .setOutputCol(\"countWordsFeatureVectors\")\n  .setMinDF(2) // a term must appear in more or equal to 2 documents to be included in the vocabulary\n\nval countWordsVectorizerModelTransformer \u003d countWordsVectorizerEstimator.fit(filteredWordsFeatureVectorsDF)\n\nval countWordsFeatureVectorsDF \u003d countWordsVectorizerModelTransformer.transform(filteredWordsFeatureVectorsDF).select(\"name\", \"bio\", \"filteredWordsFeatureVectors\", \"countWordsFeatureVectors\")\n\ncountWordsFeatureVectorsDF.show()",
      "dateUpdated": "Oct 27, 2015 12:41:12 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445101913136_1473887137",
      "id": "20151017-171153_871858",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "File name too long"
      },
      "dateCreated": "Oct 17, 2015 5:11:53 PM",
      "dateStarted": "Oct 27, 2015 12:41:13 PM",
      "dateFinished": "Oct 27, 2015 12:41:13 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "N-Gram Featurizer",
      "text": "import org.apache.spark.ml.feature.NGram\n\nval ngramTransformer \u003d new NGram().setN(2).setInputCol(\"filteredWordsFeatureVectors\").setOutputCol(\"ngramsFeatureVectors\")\n\nval ngramsFeatureVectorsDF \u003d ngramTransformer.transform(filteredWordsFeatureVectorsDF)\n\nngramsFeatureVectorsDF.select(\"name\", \"bio\", \"ngramsFeatureVectors\").show()",
      "dateUpdated": "Oct 27, 2015 12:41:12 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445102307362_-534718304",
      "id": "20151017-171827_540520315",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "File name too long"
      },
      "dateCreated": "Oct 17, 2015 5:18:27 PM",
      "dateStarted": "Oct 27, 2015 12:41:13 PM",
      "dateFinished": "Oct 27, 2015 12:41:13 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Count Featurizer - N-Grams:  TODO:  Convert ArrayType(false) to ArrayType(true)",
      "text": "import org.apache.spark.ml.feature.{CountVectorizer, CountVectorizerModel}\n\n// fit a CountVectorizerModel from the corpus\nval countNGramsVectorizerEstimator \u003d new CountVectorizer()\n  .setInputCol(\"ngramsFeatureVectors\")\n  .setOutputCol(\"countNGramsFeatureVectors\")\n  .setMinDF(2) // a term must appear in more or equal to 2 documents to be included in the vocabulary\n\nval countNGramsVectorizerModelTransformer \u003d countNGramsVectorizerEstimator.fit(ngramsFeatureVectorsDF)\n\nval countNGramsFeatureVectorsDF \u003d countNGramsVectorizerModelTransformer.transform(ngramsFeatureVectorsDF).select(\"name\", \"bio\", \"countNGramsFeatureVectors\")\n\ncountNGramsFeatureVectorsDF.show()",
      "dateUpdated": "Oct 27, 2015 12:41:13 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445103941122_-1446492764",
      "id": "20151017-174541_1589950786",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "File name too long"
      },
      "dateCreated": "Oct 17, 2015 5:45:41 PM",
      "dateStarted": "Oct 27, 2015 12:41:13 PM",
      "dateFinished": "Oct 27, 2015 12:41:13 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "TODO:  Add categorical Features (Genres?) and One Hot Encode",
      "dateUpdated": "Oct 27, 2015 12:41:13 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445210443739_1347878706",
      "id": "20151018-232043_2008195623",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT"
      },
      "dateCreated": "Oct 18, 2015 11:20:43 PM",
      "dateStarted": "Oct 27, 2015 12:41:13 PM",
      "dateFinished": "Oct 27, 2015 12:41:13 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Featurize Extended Actresses and Actors Bios  (100 each)",
      "text": "// create the actresses_temp table from the input JSON\nval actresses100BiosDF \u003d sqlContext.read.format(\"json\").load(\"file:/root/pipeline/datasets/hollywood/actresses-100-bios.json\")\nactresses100BiosDF.registerTempTable(\"actresses_100_bios_temp\")\n\n// create the actors_temp table from the input JSON\nval actors100BiosDF \u003d sqlContext.read.format(\"json\").load(\"file:/root/pipeline/datasets/hollywood/actors-100-bios.json\")\nactors100BiosDF.registerTempTable(\"actors_100_bios_temp\")",
      "dateUpdated": "Oct 27, 2015 12:41:13 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445105724536_-1658776984",
      "id": "20151017-181524_33910338",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "File name too long"
      },
      "dateCreated": "Oct 17, 2015 6:15:24 PM",
      "dateStarted": "Oct 27, 2015 12:41:13 PM",
      "dateFinished": "Oct 27, 2015 12:41:13 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val actresses100BiosExplodedDF \u003d sqlContext.sql(\"SELECT (90000 + people.index) as id, people.name.text as name, people.bio.text as bio, people.hero.src as img FROM actresses_100_bios_temp LATERAL VIEW explode(results.people) p AS people\")\n\nval actors100BiosExplodedDF \u003d sqlContext.sql(\"SELECT (10000 + people.index) as id, people.name.text as name, people.bio.text as bio, people.hero.src as img FROM actors_100_bios_temp LATERAL VIEW explode(results.people) p AS people\")\n\nval actressesAndActors100BiosDF \u003d actresses100BiosExplodedDF.unionAll(actors100BiosExplodedDF).cache()\nactressesAndAcactressesAndActors100BiosDFtorsDF.show(30)",
      "dateUpdated": "Oct 27, 2015 12:41:13 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445209766355_1442759564",
      "id": "20151018-230926_166286914",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "File name too long"
      },
      "dateCreated": "Oct 18, 2015 11:09:26 PM",
      "dateStarted": "Oct 27, 2015 12:41:13 PM",
      "dateFinished": "Oct 27, 2015 12:41:14 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "dateUpdated": "Oct 27, 2015 12:41:13 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1445209878832_1660663714",
      "id": "20151018-231118_1458525638",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT"
      },
      "dateCreated": "Oct 18, 2015 11:11:18 PM",
      "dateStarted": "Oct 27, 2015 12:41:14 PM",
      "dateFinished": "Oct 27, 2015 12:41:14 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Profile NLP/01: Feature Engineering",
  "id": "2B2SHA7Y8",
  "angularObjects": {
    "2AR33ZMZJ": [],
    "2AS9P7JSA": [],
    "2ARR8UZDJ": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}