{
  "paragraphs": [
    {
      "title": "Collaborative Filtering:  Alternating Least Squares Matrix Factorization",
      "text": "%md ![Alternating Least Squares - Matrix Factorization](https://raw.githubusercontent.com/cfregly/spark-after-dark/master/img/ALS.png)",
      "dateUpdated": "Nov 26, 2015 5:08:08 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "editorHide": false,
        "editorMode": "ace/mode/markdown"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1435978153894_1534941045",
      "id": "20150704-024913_884517592",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cp\u003e\u003cimg src\u003d\"https://raw.githubusercontent.com/cfregly/spark-after-dark/master/img/ALS.png\" alt\u003d\"Alternating Least Squares - Matrix Factorization\" /\u003e\u003c/p\u003e\n"
      },
      "dateCreated": "Jul 4, 2015 2:49:13 AM",
      "dateStarted": "Nov 26, 2015 5:08:09 PM",
      "dateFinished": "Nov 26, 2015 5:08:09 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Train The Model Using The Historical Training Split Of The Historical Data",
      "text": "import org.apache.spark.mllib.recommendation.ALS\nimport org.apache.spark.mllib.recommendation.Rating\n\nval itemRatings \u003d itemRatingsDF.map(rating \u003d\u003e \n  Rating(rating(0).asInstanceOf[Int], rating(1).asInstanceOf[Int], 1)\n).cache()\n\nval rank \u003d 10\nval numIterations \u003d 20\nval convergenceThreshold \u003d 0.01\n\nval model \u003d ALS.train(itemRatings, rank, numIterations, convergenceThreshold)",
      "dateUpdated": "Dec 1, 2015 6:50:30 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "editorHide": false,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1435978256373_-160526409",
      "id": "20150704-025056_169923529",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.mllib.recommendation.ALS\nimport org.apache.spark.mllib.recommendation.Rating\nitemRatings: org.apache.spark.rdd.RDD[org.apache.spark.mllib.recommendation.Rating] \u003d MapPartitionsRDD[389] at map at \u003cconsole\u003e:76\nrank: Int \u003d 10\nnumIterations: Int \u003d 20\nconvergenceThreshold: Double \u003d 0.01\nmodel: org.apache.spark.mllib.recommendation.MatrixFactorizationModel \u003d org.apache.spark.mllib.recommendation.MatrixFactorizationModel@401726d1\n"
      },
      "dateCreated": "Jul 4, 2015 2:50:56 AM",
      "dateStarted": "Dec 1, 2015 6:50:30 AM",
      "dateFinished": "Dec 1, 2015 6:50:33 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Generate Personalized Recommendations For Each Distinct User",
      "text": "import org.apache.spark.sql.Row;\n\nval recommendationsDF \u003d model.recommendProductsForUsers(5).toDF(\"id\",\"recommendationItemIds\")\n\ncase class Recommendation(userId: Int, itemId: Int, confidence: Double)\n\nval enrichedRecommendationsDF \u003d \n  recommendationsDF.explode($\"recommendationItemIds\") { \n\tcase Row(recommendations: Seq[Row]) \u003d\u003e recommendations.map(recommendation \u003d\u003e \n      Recommendation(recommendation(0).asInstanceOf[Int], \n                     recommendation(1).asInstanceOf[Int], \n                     recommendation(2).asInstanceOf[Double])) \n  }.select($\"userId\", $\"itemId\", $\"confidence\").join(itemsDF, $\"itemId\" \u003d\u003d\u003d $\"id\").select($\"userId\", $\"itemId\", $\"title\", $\"description\", $\"tags\", $\"img\", $\"confidence\")",
      "dateUpdated": "Dec 1, 2015 6:50:52 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "title": true,
        "tableHide": false,
        "editorHide": false,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1435978292871_1625908707",
      "id": "20150704-025132_1487939440",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.apache.spark.sql.Row\nrecommendationsDF: org.apache.spark.sql.DataFrame \u003d [id: int, recommendationItemIds: array\u003cstruct\u003cuser:int,product:int,rating:double\u003e\u003e]\ndefined class Recommendation\n\u003cconsole\u003e:95: warning: non-variable type argument org.apache.spark.sql.Row in type pattern Seq[org.apache.spark.sql.Row] is unchecked since it is eliminated by erasure\n       \tcase Row(recommendations: Seq[Row]) \u003d\u003e recommendations.map(recommendation \u003d\u003e \n                                  ^\nenrichedRecommendationsDF: org.apache.spark.sql.DataFrame \u003d [userId: int, itemId: int, title: string, description: string, tags: string, img: string, confidence: double]\n"
      },
      "dateCreated": "Jul 4, 2015 2:51:32 AM",
      "dateStarted": "Dec 1, 2015 6:50:52 AM",
      "dateFinished": "Dec 1, 2015 6:50:53 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "enrichedRecommendationsDF.show(20)",
      "dateUpdated": "Dec 1, 2015 6:51:05 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1443377582412_2075344434",
      "id": "20150927-181302_1140885708",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "+------+------+-----------------+--------------------+--------------------+--------------------+------------------+\n|userId|itemId|            title|         description|                tags|                 img|        confidence|\n+------+------+-----------------+--------------------+--------------------+--------------------+------------------+\n| 67388| 10009| Chazz Palminteri|Bronx-born and ra...|Bronx, New York, ...|img/people/10009.jpg|0.9905920864315864|\n| 67388| 90004|  Bobbie Phillips|Brains and beauty...|Salisbury, North ...|img/people/90004.jpg|0.9905920864315864|\n| 67388| 10011|    John Travolta|John Travolta was...|Englewood, New Yo...|img/people/10011.jpg|0.9905920864315864|\n| 67388| 90002|   Shannon Whirry|Shannon Whirry is...|Green Lake, Wisco...|img/people/90002.jpg|0.9905920864315864|\n| 67388| 10001|Leonardo DiCaprio|Few actors in the...|Hollywood, Califo...|img/people/10001.jpg|0.9905920864315864|\n| 46166| 10009| Chazz Palminteri|Bronx-born and ra...|Bronx, New York, ...|img/people/10009.jpg|0.9905680163749142|\n| 46166| 90004|  Bobbie Phillips|Brains and beauty...|Salisbury, North ...|img/people/90004.jpg|0.9905680163749142|\n| 46166| 10011|    John Travolta|John Travolta was...|Englewood, New Yo...|img/people/10011.jpg|0.9905680163749142|\n| 46166| 90002|   Shannon Whirry|Shannon Whirry is...|Green Lake, Wisco...|img/people/90002.jpg|0.9905680163749142|\n| 46166| 10001|Leonardo DiCaprio|Few actors in the...|Hollywood, Califo...|img/people/10001.jpg|0.9905680163749142|\n+------+------+-----------------+--------------------+--------------------+--------------------+------------------+\n\n"
      },
      "dateCreated": "Sep 27, 2015 6:13:02 PM",
      "dateStarted": "Dec 1, 2015 6:51:05 AM",
      "dateFinished": "Dec 1, 2015 6:51:06 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import org.elasticsearch.spark.sql._ \nimport org.apache.spark.sql.SaveMode\n\nval esConfig \u003d Map(\"pushdown\" -\u003e \"true\", \"es.nodes\" -\u003e \"127.0.0.1\", \"es.port\" -\u003e \"9200\")\nenrichedRecommendationsDF.write.format(\"org.elasticsearch.spark.sql\").mode(SaveMode.Overwrite).options(esConfig).save(\"advancedspark/personalized-als\")",
      "dateUpdated": "Dec 1, 2015 6:51:10 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorHide": false,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1438113388648_-491234562",
      "id": "20150728-195628_1365871289",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "import org.elasticsearch.spark.sql._\nimport org.apache.spark.sql.SaveMode\nesConfig: scala.collection.immutable.Map[String,String] \u003d Map(pushdown -\u003e true, es.nodes -\u003e 127.0.0.1, es.port -\u003e 9200)\n"
      },
      "dateCreated": "Jul 28, 2015 7:56:28 PM",
      "dateStarted": "Dec 1, 2015 6:51:10 AM",
      "dateFinished": "Dec 1, 2015 6:51:11 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "dateUpdated": "Nov 26, 2015 5:08:16 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "editorHide": false,
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1435978459979_-187768604",
      "id": "20150704-025419_555917335",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT"
      },
      "dateCreated": "Jul 4, 2015 2:54:19 AM",
      "dateStarted": "Nov 26, 2015 5:08:19 PM",
      "dateFinished": "Nov 26, 2015 5:08:20 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Live Ratings/03:  Collaborative Filtering Recs (Matrix Factorization)",
  "id": "2AUYFSKXN",
  "angularObjects": {
    "2ARR8UZDJ": [],
    "2AS9P7JSA": [],
    "2AR33ZMZJ": []
  },
  "config": {
    "looknfeel": "default"
  },
  "info": {}
}