FROM fluxcapacitor/package-tensorflow-7a7fe93-4c0052d-cpu:master

WORKDIR /root

ENV \
  TF_CPP_MIN_LOG_LEVEL=0

RUN \
  mkdir -p /root/logs

ENV \
  LOGS_HOME=/root/logs

RUN \
  echo "deb https://dl.bintray.com/sbt/debian /" | tee -a /etc/apt/sources.list.d/sbt.list \
  && apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 2EE0EA64E40A89B84B2DF73499E82A75642AC823 \
  && apt-get update \
  && apt-get install -y sbt

RUN \
# Anaconda's libgfortran=3.0 is not co-operating, so we use apt-get
  apt-get install libgfortran3
RUN \
  conda install -c anaconda openblas

# We're installing (duplicate of base Docker image)
#   in order to force an error during the Docker build
#   if/when the base Docker image changes TF version.
# When the base Docker image changes TF version, be sure
#   to propagate this change to the following:
#     src/main/python/model/requirements_pio_model_server.txt
RUN \
  pip install /tmp/pip/tensorflow-1.2.0rc2-cp36-cp36m-linux_x86_64.whl \
  && pip uninstall -y /tmp/pip/tensorflow-1.2.0rc2-cp36-cp36m-linux_x86_64.whl

RUN \
  apt-get install -y nginx \
  && apt-get install -y tmux \
  && apt-get install -y screen

RUN \
  wget https://github.com/prometheus/prometheus/releases/download/v1.7.1/prometheus-1.7.1.linux-amd64.tar.gz \
  && tar xvfz prometheus-1.7.1.linux-amd64.tar.gz \
  && rm prometheus-1.7.1.linux-amd64.tar.gz

RUN \
  wget https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana_4.3.1_amd64.deb \
  && apt-get install -y adduser libfontconfig \
  && dpkg -i grafana_4.3.1_amd64.deb \
  && rm grafana_4.3.1_amd64.deb

#RUN \
#  mv /etc/grafana/grafana.ini /etc/grafana/grafana.ini.orig \
#  && cd /etc/grafana/ \
#  && ln -s /root/config/grafana/grafana.ini

RUN \
  apt-get install -y automake autotools-dev g++ git libcurl4-gnutls-dev libfuse-dev libssl-dev libxml2-dev make pkg-config

RUN \
  git clone https://github.com/s3fs-fuse/s3fs-fuse.git \
  && cd s3fs-fuse \
  && ./autogen.sh \
  && ./configure \
  && make \
  && make install

COPY lib/ lib/
RUN \
  cd ~/lib/jni \
  && ln -s ~/lib/jni/libtensorflow_jni-cpu.so libtensorflow_jni.so

COPY sysutils/ sysutils/

COPY jvm_src/ jvm_src/
COPY build.sbt build.sbt

RUN \
  sbt clean clean-files package 

COPY config/ config/

RUN \
  mv /root/prometheus-1.7.1.linux-amd64/prometheus.yml /root/prometheus-1.7.1.linux-amd64/prometheus.yml.orig \
  && cd /root/prometheus-1.7.1.linux-amd64/ \
  && ln -s /root/config/prometheus/prometheus.yml

ENV \
  PATH=/root/prometheus-1.7.1.linux-amd64/:$PATH
RUN \
  mv /etc/nginx/sites-available/default /etc/nginx/sites-available/default.orig \
  && cd /etc/nginx/sites-available/ \
  && ln -s /root/config/nginx/default \
  && cd /etc/nginx/sites-enabled/ \
  && rm default \
  && ln -s /etc/nginx/sites-available/default

COPY src/ src/

ENV \
  PIO_MODEL_SERVER_PATH=/root/src/main/python/model_server/

RUN \
  pip2 install -r /root/src/main/python/nvidia/requirements.txt

ENV \
  PIO_MODEL_SERVER_PORT=9876

ENV \
  PIO_MODEL_SERVER_PROMETHEUS_PORT=10254

ENV \
  PIO_MODEL_SERVER_TENSORFLOW_PORT=9877

ENV \
  PIO_MODEL_SERVER_TENSORFLOW_PROMETHEUS_PORT=10255

ENV \
  PIO_MODEL_SERVER_TENSORFLOW_SERVING_PORT=9000

ENV \
  PIO_MODEL_SERVER_TENSORFLOW_SERVING_REQUEST_BATCHING=true

ENV \
  PIO_MODEL_SERVER_ALLOW_UPLOAD=True

#RUN \
#  [ -s ${PIO_MODEL_SERVER_PATH}/requirements_conda_pio_model_server.txt ] \
#  && conda install --yes --file ${PIO_MODEL_SERVER_PATH}/requirements_conda_pio_model_server.txt \
#  && [ -s ${PIO_MODEL_SERVER_PATH}/requirements_pio_model_server.txt ] \
#  && pip install -r ${PIO_MODEL_SERVER_PATH}/requirements_pio_model_server.txt

COPY html/ /var/www/html/
COPY run run

ARG model_file_path 
RUN \
  echo $model_file_path 

ENV \
  PIO_MODEL_STORE_HOME=/root/model_store/
#  PIO_MODEL_STORE_HOME=$model_file_path

ARG model_s3_path
RUN \
  echo $model_s3_path

EXPOSE 6969 9876 9877 9000 9040 9090 3000 10254 10255 7070

CMD ["supervise", "."]
